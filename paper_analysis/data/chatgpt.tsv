	id	updated	published	title	summary	author	arxiv:comment	link	arxiv:primary_category	category
0	http://arxiv.org/abs/2301.07597v1	2023-01-18T15:23:25Z	2023-01-18T15:23:25Z	"How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation,
  and Detection"	"The introduction of ChatGPT has garnered widespread attention in both
academic and industrial communities. ChatGPT is able to respond effectively to
a wide range of human questions, providing fluent and comprehensive answers
that significantly surpass previous public chatbots in terms of security and
usefulness. On one hand, people are curious about how ChatGPT is able to
achieve such strength and how far it is from human experts. On the other hand,
people are starting to worry about the potential negative impacts that large
language models (LLMs) like ChatGPT could have on society, such as fake news,
plagiarism, and social security issues. In this work, we collected tens of
thousands of comparison responses from both human experts and ChatGPT, with
questions ranging from open-domain, financial, medical, legal, and
psychological areas. We call the collected dataset the Human ChatGPT Comparison
Corpus (HC3). Based on the HC3 dataset, we study the characteristics of
ChatGPT's responses, the differences and gaps from human experts, and future
directions for LLMs. We conducted comprehensive human evaluations and
linguistic analyses of ChatGPT-generated content compared with that of humans,
where many interesting results are revealed. After that, we conduct extensive
experiments on how to effectively detect whether a certain text is generated by
ChatGPT or humans. We build three different detection systems, explore several
key factors that influence their effectiveness, and evaluate them in different
scenarios. The dataset, code, and models are all publicly available at
https://github.com/Hello-SimpleAI/chatgpt-comparison-detection."	[{'name': 'Biyang Guo'}, {'name': 'Xin Zhang'}, {'name': 'Ziyuan Wang'}, {'name': 'Minqi Jiang'}, {'name': 'Jinran Nie'}, {'name': 'Yuxuan Ding'}, {'name': 'Jianwei Yue'}, {'name': 'Yupeng Wu'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'https://github.com/Hello-SimpleAI/chatgpt-comparison-detection'}	[{'@href': 'http://arxiv.org/abs/2301.07597v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.07597v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}
1	http://arxiv.org/abs/2301.08653v1	2023-01-20T16:01:47Z	2023-01-20T16:01:47Z	An Analysis of the Automatic Bug Fixing Performance of ChatGPT	"To support software developers in finding and fixing software bugs, several
automated program repair techniques have been introduced. Given a test suite,
standard methods usually either synthesize a repair, or navigate a search space
of software edits to find test-suite passing variants. Recent program repair
methods are based on deep learning approaches. One of these novel methods,
which is not primarily intended for automated program repair, but is still
suitable for it, is ChatGPT. The bug fixing performance of ChatGPT, however, is
so far unclear. Therefore, in this paper we evaluate ChatGPT on the standard
bug fixing benchmark set, QuixBugs, and compare the performance with the
results of several other approaches reported in the literature. We find that
ChatGPT's bug fixing performance is competitive to the common deep learning
approaches CoCoNut and Codex and notably better than the results reported for
the standard program repair approaches. In contrast to previous approaches,
ChatGPT offers a dialogue system through which further information, e.g., the
expected output for a certain input or an observed error message, can be
entered. By providing such hints to ChatGPT, its success rate can be further
increased, fixing 31 out of 40 bugs, outperforming state-of-the-art."	[{'name': 'Dominik Sobania'}, {'name': 'Martin Briesch'}, {'name': 'Carol Hanna'}, {'name': 'Justyna Petke'}]		[{'@href': 'http://arxiv.org/abs/2301.08653v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.08653v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.SE', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'cs.SE', '@scheme': 'http://arxiv.org/schemas/atom'}
2	http://arxiv.org/abs/2301.13852v1	2023-01-30T08:06:08Z	2023-01-30T08:06:08Z	"ChatGPT or Human? Detect and Explain. Explaining Decisions of Machine
  Learning Model for Detecting Short ChatGPT-generated Text"	"ChatGPT has the ability to generate grammatically flawless and
seemingly-human replies to different types of questions from various domains.
The number of its users and of its applications is growing at an unprecedented
rate. Unfortunately, use and abuse come hand in hand. In this paper, we study
whether a machine learning model can be effectively trained to accurately
distinguish between original human and seemingly human (that is,
ChatGPT-generated) text, especially when this text is short. Furthermore, we
employ an explainable artificial intelligence framework to gain insight into
the reasoning behind the model trained to differentiate between
ChatGPT-generated and human-generated text. The goal is to analyze model's
decisions and determine if any specific patterns or characteristics can be
identified. Our study focuses on short online reviews, conducting two
experiments comparing human-generated and ChatGPT-generated text. The first
experiment involves ChatGPT text generated from custom queries, while the
second experiment involves text generated by rephrasing original
human-generated reviews. We fine-tune a Transformer-based model and use it to
make predictions, which are then explained using SHAP. We compare our model
with a perplexity score-based approach and find that disambiguation between
human and ChatGPT-generated reviews is more challenging for the ML model when
using rephrased text. However, our proposed approach still achieves an accuracy
of 79%. Using explainability, we observe that ChatGPT's writing is polite,
without specific details, using fancy and atypical vocabulary, impersonal, and
typically it does not express feelings."	[{'name': 'Sandra Mitrović'}, {'name': 'Davide Andreoletti'}, {'name': 'Omran Ayoub'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '11 pages, 8 figures, 2 tables'}	[{'@href': 'http://arxiv.org/abs/2301.13852v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.13852v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}]
3	http://arxiv.org/abs/2212.09292v1	2022-12-19T08:15:16Z	2022-12-19T08:15:16Z	ChatGPT: The End of Online Exam Integrity?	"This study evaluated the ability of ChatGPT, a recently developed artificial
intelligence (AI) agent, to perform high-level cognitive tasks and produce text
that is indistinguishable from human-generated text. This capacity raises
concerns about the potential use of ChatGPT as a tool for academic misconduct
in online exams. The study found that ChatGPT is capable of exhibiting critical
thinking skills and generating highly realistic text with minimal input, making
it a potential threat to the integrity of online exams, particularly in
tertiary education settings where such exams are becoming more prevalent.
Returning to invigilated and oral exams could form part of the solution, while
using advanced proctoring techniques and AI-text output detectors may be
effective in addressing this issue, they are not likely to be foolproof
solutions. Further research is needed to fully understand the implications of
large language models like ChatGPT and to devise strategies for combating the
risk of cheating using these tools. It is crucial for educators and
institutions to be aware of the possibility of ChatGPT being used for cheating
and to investigate measures to address it in order to maintain the fairness and
validity of online exams for all students."	{'name': 'Teo Susnjak'}		[{'@href': 'http://arxiv.org/abs/2212.09292v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2212.09292v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}]
4	http://arxiv.org/abs/2212.14548v1	2022-12-30T05:03:15Z	2022-12-30T05:03:15Z	"How would Stance Detection Techniques Evolve after the Launch of
  ChatGPT?"	"Stance detection refers to the task of extracting the standpoint (Favor,
Against or Neither) towards a target in given texts. Such research gains
increasing attention with the proliferation of social media contents. The
conventional framework of handling stance detection is converting it into text
classification tasks. Deep learning models have already replaced rule-based
models and traditional machine learning models in solving such problems.
Current deep neural networks are facing two main challenges which are
insufficient labeled data and information in social media posts and the
unexplainable nature of deep learning models. A new pre-trained language model
chatGPT was launched on Nov 30, 2022. For the stance detection tasks, our
experiments show that ChatGPT can achieve SOTA or similar performance for
commonly used datasets including SemEval-2016 and P-Stance. At the same time,
ChatGPT can provide explanation for its own prediction, which is beyond the
capability of any existing model. The explanations for the cases it cannot
provide classification results are especially useful. ChatGPT has the potential
to be the best AI model for stance detection tasks in NLP, or at least change
the research paradigm of this field. ChatGPT also opens up the possibility of
building explanatory AI for stance detection."	[{'name': 'Bowen Zhang'}, {'name': 'Daijun Ding'}, {'name': 'Liwen Jing'}]		[{'@href': 'http://arxiv.org/abs/2212.14548v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2212.14548v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}
5	http://arxiv.org/abs/2301.01768v1	2023-01-05T07:13:13Z	2023-01-05T07:13:13Z	"The political ideology of conversational AI: Converging evidence on
  ChatGPT's pro-environmental, left-libertarian orientation"	"Conversational artificial intelligence (AI) disrupts how humans interact with
technology. Recently, OpenAI introduced ChatGPT, a state-of-the-art dialogue
model that can converse with its human counterparts with unprecedented
capabilities. ChatGPT has witnessed tremendous attention from the media,
academia, industry, and the general public, attracting more than a million
users within days of its release. However, its explosive adoption for
information search and as an automated decision aid underscores the importance
to understand its limitations and biases. This paper focuses on one of
democratic society's most important decision-making processes: political
elections. Prompting ChatGPT with 630 political statements from two leading
voting advice applications and the nation-agnostic political compass test in
three pre-registered experiments, we uncover ChatGPT's pro-environmental,
left-libertarian ideology. For example, ChatGPT would impose taxes on flights,
restrict rent increases, and legalize abortion. In the 2021 elections, it would
have voted most likely for the Greens both in Germany (B\""undnis 90/Die
Gr\""unen) and in the Netherlands (GroenLinks). Our findings are robust when
negating the prompts, reversing the order of the statements, varying prompt
formality, and across languages (English, German, Dutch, and Spanish). We
conclude by discussing the implications of politically biased conversational AI
on society."	[{'name': 'Jochen Hartmann'}, {'name': 'Jasper Schwenzow'}, {'name': 'Maximilian Witte'}]		[{'@href': 'http://arxiv.org/abs/2301.01768v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.01768v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.CY', '@scheme': 'http://arxiv.org/schemas/atom'}]
6	http://arxiv.org/abs/2301.08745v2	2023-01-31T16:39:51Z	2023-01-20T08:51:36Z	Is ChatGPT A Good Translator? A Preliminary Study	"This report provides a preliminary evaluation of ChatGPT for machine
translation, including translation prompt, multilingual translation, and
translation robustness. We adopt the prompts advised by ChatGPT to trigger its
translation ability and find that the candidate prompts generally work well and
show minor performance differences. By evaluating on a number of benchmark test
sets, we find that ChatGPT performs competitively with commercial translation
products (e.g., Google Translate) on high-resource European languages but lags
behind significantly on low-resource or distant languages. For distant
languages, we explore an interesting strategy named $\mathbf{pivot~prompting}$
that asks ChatGPT to translate the source sentence into a high-resource pivot
language before into the target language, which improves the translation
performance significantly. As for the translation robustness, ChatGPT does not
perform as well as the commercial systems on biomedical abstracts or Reddit
comments but is potentially a good translator for spoken language. Scripts and
data: https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator"	[{'name': 'Wenxiang Jiao'}, {'name': 'Wenxuan Wang'}, {'name': 'Jen-tse Huang'}, {'name': 'Xing Wang'}, {'name': 'Zhaopeng Tu'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '6 pages; added Pivot Prompting for distant languages; added\n  limitations'}	[{'@href': 'http://arxiv.org/abs/2301.08745v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.08745v2', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}
7	http://arxiv.org/abs/2301.13867v1	2023-01-31T18:59:03Z	2023-01-31T18:59:03Z	Mathematical Capabilities of ChatGPT	"We investigate the mathematical capabilities of ChatGPT by testing it on
publicly available datasets, as well as hand-crafted ones, and measuring its
performance against other models trained on a mathematical corpus, such as
Minerva. We also test whether ChatGPT can be a useful assistant to professional
mathematicians by emulating various use cases that come up in the daily
professional activities of mathematicians (question answering, theorem
searching). In contrast to formal mathematics, where large databases of formal
proofs are available (e.g., the Lean Mathematical Library), current datasets of
natural-language mathematics, used to benchmark language models, only cover
elementary mathematics. We address this issue by introducing a new dataset:
GHOSTS. It is the first natural-language dataset made and curated by working
researchers in mathematics that (1) aims to cover graduate-level mathematics
and (2) provides a holistic overview of the mathematical capabilities of
language models. We benchmark ChatGPT on GHOSTS and evaluate performance
against fine-grained criteria. We make this new dataset publicly available to
assist a community-driven comparison of ChatGPT with (future) large language
models in terms of advanced mathematical comprehension. We conclude that
contrary to many positive reports in the media (a potential case of selection
bias), ChatGPT's mathematical abilities are significantly below those of an
average mathematics graduate student. Our results show that ChatGPT often
understands the question but fails to provide correct solutions. Hence, if your
goal is to use it to pass a university exam, you would be better off copying
from your average peer!"	[{'name': 'Simon Frieder'}, {'name': 'Luca Pinchetti'}, {'name': 'Ryan-Rhys Griffiths'}, {'name': 'Tommaso Salvatori'}, {'name': 'Thomas Lukasiewicz'}, {'name': 'Philipp Christian Petersen'}, {'name': 'Alexis Chevalier'}, {'name': 'Julius Berner'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'The GHOSTS dataset will be available at\n  https://github.com/friederrr/science-GHOSTS'}	[{'@href': 'http://arxiv.org/abs/2301.13867v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.13867v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}]
8	http://arxiv.org/abs/2212.14882v1	2022-12-30T18:55:16Z	2022-12-30T18:55:16Z	"ChatGPT Makes Medicine Easy to Swallow: An Exploratory Case Study on
  Simplified Radiology Reports"	"The release of ChatGPT, a language model capable of generating text that
appears human-like and authentic, has gained significant attention beyond the
research community. We expect that the convincing performance of ChatGPT
incentivizes users to apply it to a variety of downstream tasks, including
prompting the model to simplify their own medical reports. To investigate this
phenomenon, we conducted an exploratory case study. In a questionnaire, we
asked 15 radiologists to assess the quality of radiology reports simplified by
ChatGPT. Most radiologists agreed that the simplified reports were factually
correct, complete, and not potentially harmful to the patient. Nevertheless,
instances of incorrect statements, missed key medical findings, and potentially
harmful passages were reported. While further studies are needed, the initial
insights of this study indicate a great potential in using large language
models like ChatGPT to improve patient-centered care in radiology and other
medical domains."	[{'name': 'Katharina Jeblick'}, {'name': 'Balthasar Schachtner'}, {'name': 'Jakob Dexl'}, {'name': 'Andreas Mittermeier'}, {'name': 'Anna Theresa Stüber'}, {'name': 'Johanna Topalis'}, {'name': 'Tobias Weber'}, {'name': 'Philipp Wesp'}, {'name': 'Bastian Sabel'}, {'name': 'Jens Ricke'}, {'name': 'Michael Ingrisch'}]		[{'@href': 'http://arxiv.org/abs/2212.14882v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2212.14882v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}]
9	http://arxiv.org/abs/2301.07098v1	2023-01-13T20:24:38Z	2023-01-13T20:24:38Z	The moral authority of ChatGPT	"ChatGPT is not only fun to chat with, but it also searches information,
answers questions, and gives advice. With consistent moral advice, it might
improve the moral judgment and decisions of users, who often hold contradictory
moral beliefs. Unfortunately, ChatGPT turns out highly inconsistent as a moral
advisor. Nonetheless, it influences users' moral judgment, we find in an
experiment, even if they know they are advised by a chatting bot, and they
underestimate how much they are influenced. Thus, ChatGPT threatens to corrupt
rather than improves users' judgment. These findings raise the question of how
to ensure the responsible use of ChatGPT and similar AI. Transparency is often
touted but seems ineffective. We propose training to improve digital literacy."	[{'name': 'Sebastian Krügel'}, {'name': 'Andreas Ostermaier'}, {'name': 'Matthias Uhl'}]		[{'@href': 'http://arxiv.org/abs/2301.07098v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.07098v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CY', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CY', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.HC', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}]
10	http://arxiv.org/abs/2302.02805v1	2023-01-27T12:05:44Z	2023-01-27T12:05:44Z	"Investigating the use of ChatGPT for the scheduling of construction
  projects"	"Large language models such as ChatGPT have the potential to revolutionize the
construction industry by automating repetitive and time-consuming tasks. This
paper presents a study in which ChatGPT was used to generate a construction
schedule for a simple construction project. The output from ChatGPT was
evaluated by a pool of participants that provided feedback regarding their
overall interaction experience and the quality of the output. The results show
that ChatGPT can generate a coherent schedule that follows a logical approach
to fulfill the requirements of the scope indicated. The participants had an
overall positive interaction experience and indicated the great potential of
such a tool to automate many preliminary and time-consuming tasks. However, the
technology still has limitations, and further development is needed before it
can be widely adopted in the industry. Overall, this study highlights the
potential of using large language models in the construction industry and the
need for further research."	[{'name': 'Samuel A. Prieto'}, {'name': 'Eyob T. Mengiste'}, {'name': 'Borja García de Soto'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '14 pages, 6 figures'}	[{'@href': 'http://arxiv.org/abs/2302.02805v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2302.02805v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.HC', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.HC', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'I.2.1; I.2.7', '@scheme': 'http://arxiv.org/schemas/atom'}]
11	http://arxiv.org/abs/2301.13819v2	2023-02-06T12:03:38Z	2023-01-24T19:23:38Z	"Causal-Discovery Performance of ChatGPT in the context of Neuropathic
  Pain Diagnosis"	"ChatGPT has demonstrated exceptional proficiency in natural language
conversation, e.g., it can answer a wide range of questions while no previous
large language models can. Thus, we would like to push its limit and explore
its ability to answer causal discovery questions by using a medical benchmark
(Tu et al. 2019) in causal discovery."	[{'name': 'Ruibo Tu'}, {'name': 'Chao Ma'}, {'name': 'Cheng Zhang'}]		[{'@href': 'http://arxiv.org/abs/2301.13819v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.13819v2', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}]
12	http://arxiv.org/abs/2302.03494v1	2023-02-06T04:21:59Z	2023-02-06T04:21:59Z	A Categorical Archive of ChatGPT Failures	"Large language models have been demonstrated to be valuable in different
fields. ChatGPT, developed by OpenAI, has been trained using massive amounts of
data and simulates human conversation by comprehending context and generating
appropriate responses. It has garnered significant attention due to its ability
to effectively answer a broad range of human inquiries, with fluent and
comprehensive answers surpassing prior public chatbots in both security and
usefulness. However, a comprehensive analysis of ChatGPT's failures is lacking,
which is the focus of this study. Ten categories of failures, including
reasoning, factual errors, math, coding, and bias, are presented and discussed.
The risks, limitations, and societal implications of ChatGPT are also
highlighted. The goal of this study is to assist researchers and developers in
enhancing future language models and chatbots."	{'name': 'Ali Borji'}		[{'@href': 'http://arxiv.org/abs/2302.03494v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2302.03494v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}]
13	http://arxiv.org/abs/2301.10035v1	2023-01-24T14:24:44Z	2023-01-24T14:24:44Z	Putting ChatGPT's Medical Advice to the (Turing) Test	"Objective: Assess the feasibility of using ChatGPT or a similar AI-based
chatbot for patient-provider communication. Participants: A US representative
sample of 430 study participants aged 18 and above. 53.2% of respondents
analyzed were women; their average age was 47.1. Exposure: Ten representative
non-administrative patient-provider interactions were extracted from the EHR.
Patients' questions were placed in ChatGPT with a request for the chatbot to
respond using approximately the same word count as the human provider's
response. In the survey, each patient's question was followed by a provider- or
ChatGPT-generated response. Participants were informed that five responses were
provider-generated and five were chatbot-generated. Participants were asked,
and incentivized financially, to correctly identify the response source.
Participants were also asked about their trust in chatbots' functions in
patient-provider communication, using a Likert scale of 1-5. Results: The
correct classification of responses ranged between 49.0% to 85.7% for different
questions. On average, chatbot responses were correctly identified 65.5% of the
time, and provider responses were correctly distinguished 65.1% of the time. On
average, responses toward patients' trust in chatbots' functions were weakly
positive (mean Likert score: 3.4), with lower trust as the health-related
complexity of the task in questions increased. Conclusions: ChatGPT responses
to patient questions were weakly distinguishable from provider responses.
Laypeople appear to trust the use of chatbots to answer lower risk health
questions."	[{'name': 'Oded Nov'}, {'name': 'Nina Singh'}, {'name': 'Devin Mann'}]		[{'@href': 'http://arxiv.org/abs/2301.10035v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.10035v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.HC', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'cs.HC', '@scheme': 'http://arxiv.org/schemas/atom'}
14	http://arxiv.org/abs/2301.12867v1	2023-01-30T13:20:48Z	2023-01-30T13:20:48Z	Exploring AI Ethics of ChatGPT: A Diagnostic Analysis	"Recent breakthroughs in natural language processing (NLP) have permitted the
synthesis and comprehension of coherent text in an open-ended way, therefore
translating the theoretical algorithms into practical applications. The large
language-model (LLM) has significantly impacted businesses such as report
summarization softwares and copywriters. Observations indicate, however, that
LLMs may exhibit social prejudice and toxicity, posing ethical and societal
dangers of consequences resulting from irresponsibility. Large-scale benchmarks
for accountable LLMs should consequently be developed. Although several
empirical investigations reveal the existence of a few ethical difficulties in
advanced LLMs, there is no systematic examination and user study of the ethics
of current LLMs use. To further educate future efforts on constructing ethical
LLMs responsibly, we perform a qualitative research method on OpenAI's ChatGPT
to better understand the practical features of ethical dangers in recent LLMs.
We analyze ChatGPT comprehensively from four perspectives: 1) \textit{Bias} 2)
\textit{Reliability} 3) \textit{Robustness} 4) \textit{Toxicity}. In accordance
with our stated viewpoints, we empirically benchmark ChatGPT on multiple sample
datasets. We find that a significant number of ethical risks cannot be
addressed by existing benchmarks, and hence illustrate them via additional case
studies. In addition, we examine the implications of our findings on the AI
ethics of ChatGPT, as well as future problems and practical design
considerations for LLMs. We believe that our findings may give light on future
efforts to determine and mitigate the ethical hazards posed by machines in LLM
applications."	[{'name': 'Terry Yue Zhuo'}, {'name': 'Yujin Huang'}, {'name': 'Chunyang Chen'}, {'name': 'Zhenchang Xing'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Technical Report'}	[{'@href': 'http://arxiv.org/abs/2301.12867v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.12867v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.SE', '@scheme': 'http://arxiv.org/schemas/atom'}]
15	http://arxiv.org/abs/2302.03495v1	2023-02-03T01:28:25Z	2023-02-03T01:28:25Z	"Can ChatGPT Write a Good Boolean Query for Systematic Review Literature
  Search?"	"Systematic reviews are comprehensive reviews of the literature for a highly
focused research question. These reviews are often treated as the highest form
of evidence in evidence-based medicine, and are the key strategy to answer
research questions in the medical field. To create a high-quality systematic
review, complex Boolean queries are often constructed to retrieve studies for
the review topic. However, it often takes a long time for systematic review
researchers to construct a high quality systematic review Boolean query, and
often the resulting queries are far from effective. Poor queries may lead to
biased or invalid reviews, because they missed to retrieve key evidence, or to
extensive increase in review costs, because they retrieved too many irrelevant
studies. Recent advances in Transformer-based generative models have shown
great potential to effectively follow instructions from users and generate
answers based on the instructions being made. In this paper, we investigate the
effectiveness of the latest of such models, ChatGPT, in generating effective
Boolean queries for systematic review literature search. Through a number of
extensive experiments on standard test collections for the task, we find that
ChatGPT is capable of generating queries that lead to high search precision,
although trading-off this for recall. Overall, our study demonstrates the
potential of ChatGPT in generating effective Boolean queries for systematic
review literature search. The ability of ChatGPT to follow complex instructions
and generate queries with high precision makes it a valuable tool for
researchers conducting systematic reviews, particularly for rapid reviews where
time is a constraint and often trading-off higher precision for lower recall is
acceptable."	[{'name': 'Shuai Wang'}, {'name': 'Harrisen Scells'}, {'name': 'Bevan Koopman'}, {'name': 'Guido Zuccon'}]		[{'@href': 'http://arxiv.org/abs/2302.03495v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2302.03495v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.IR', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.IR', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}]
16	http://arxiv.org/abs/2302.03287v1	2023-02-07T06:41:02Z	2023-02-07T06:41:02Z	ChatGPT and Software Testing Education: Promises & Perils	"Over the past decade, predictive language modeling for code has proven to be
a valuable tool for enabling new forms of automation for developers. More
recently, we have seen the advent of general purpose ""large language models"",
based on neural transformer architectures, that have been trained on massive
datasets of human written text spanning code and natural language. However,
despite the demonstrated representational power of such models, interacting
with them has historically been constrained to specific task settings, limiting
their general applicability. Many of these limitations were recently overcome
with the introduction of ChatGPT, a language model created by OpenAI and
trained to operate as a conversational agent, enabling it to answer questions
and respond to a wide variety of commands from end-users.
  The introduction of models, such as ChatGPT, has already spurred fervent
discussion from educators, ranging from fear that students could use these AI
tools to circumvent learning, to excitement about the new types of learning
opportunities that they might unlock. However, given the nascent nature of
these tools, we currently lack fundamental knowledge related to how well they
perform in different educational settings, and the potential promise (or
danger) that they might pose to traditional forms of instruction. As such, in
this poster, we examine how well ChatGPT performs when tasked with solving
common questions in a popular software testing curriculum. Our findings
indicate that ChatGPT can provide correct or partially correct answers in 44%
of cases, provide correct or partially correct explanations of answers in 57%
of cases, and that prompting the tool in a shared question context leads to a
marginally higher rate of correct answers. Based on these findings, we discuss
the potential promise, and dangers related to the use of ChatGPT by students
and instructors."	[{'name': 'Sajed Jalil'}, {'name': 'Suzzana Rafi'}, {'name': 'Thomas D. LaToza'}, {'name': 'Kevin Moran'}, {'name': 'Wing Lam'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '8 pages, 2 tables, 5 figures'}	[{'@href': 'http://arxiv.org/abs/2302.03287v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2302.03287v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.SE', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.SE', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.HC', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'D.2.5', '@scheme': 'http://arxiv.org/schemas/atom'}]
17	http://arxiv.org/abs/2301.08155v1	2023-01-10T16:57:16Z	2023-01-10T16:57:16Z	"AI Insights into Theoretical Physics and the Swampland Program: A
  Journey Through the Cosmos with ChatGPT"	"In this case study, we explore the capabilities and limitations of ChatGPT, a
natural language processing model developed by OpenAI, in the field of string
theoretical swampland conjectures. We find that it is effective at paraphrasing
and explaining concepts in a variety of styles, but not at genuinely connecting
concepts. It will provide false information with full confidence and make up
statements when necessary. However, its ingenious use of language can be
fruitful for identifying analogies and describing visual representations of
abstract concepts."	{'name': 'Kay Lehnert', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Department of Theoretical Physics, Maynooth University, Maynooth, Ireland'}}	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '10 pages, 2 figures'}	[{'@href': 'http://arxiv.org/abs/2301.08155v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.08155v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'physics.pop-ph', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'physics.pop-ph', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}]
18	http://arxiv.org/abs/2212.05856v1	2022-12-12T12:41:24Z	2022-12-12T12:41:24Z	"""I think this is the most disruptive technology"": Exploring Sentiments
  of ChatGPT Early Adopters using Twitter Data"	"Large language models have recently attracted significant attention due to
their impressive performance on a variety of tasks. ChatGPT developed by OpenAI
is one such implementation of a large, pre-trained language model that has
gained immense popularity among early adopters, where certain users go to the
extent of characterizing it as a disruptive technology in many domains.
Understanding such early adopters' sentiments is important because it can
provide insights into the potential success or failure of the technology, as
well as its strengths and weaknesses. In this paper, we conduct a mixed-method
study using 10,732 tweets from early ChatGPT users. We first use topic
modelling to identify the main topics and then perform an in-depth qualitative
sentiment analysis of each topic. Our results show that the majority of the
early adopters have expressed overwhelmingly positive sentiments related to
topics such as Disruptions to software development, Entertainment and
exercising creativity. Only a limited percentage of users expressed concerns
about issues such as the potential for misuse of ChatGPT, especially regarding
topics such as Impact on educational aspects. We discuss these findings by
providing specific examples for each topic and then detail implications related
to addressing these concerns for both researchers and users."	[{'name': 'Mubin Ul Haque'}, {'name': 'Isuru Dharmadasa'}, {'name': 'Zarrin Tasnim Sworna'}, {'name': 'Roshan Namal Rajapakse'}, {'name': 'Hussain Ahmad'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'This is an early version of this paper'}	[{'@href': 'http://arxiv.org/abs/2212.05856v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2212.05856v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}
19	http://arxiv.org/abs/2301.04655v1	2023-01-11T15:48:36Z	2023-01-11T15:48:36Z	"ChatGPT is not all you need. A State of the Art Review of large
  Generative AI models"	"During the last two years there has been a plethora of large generative
models such as ChatGPT or Stable Diffusion that have been published.
Concretely, these models are able to perform tasks such as being a general
question and answering system or automatically creating artistic images that
are revolutionizing several sectors. Consequently, the implications that these
generative models have in the industry and society are enormous, as several job
positions may be transformed. For example, Generative AI is capable of
transforming effectively and creatively texts to images, like the DALLE-2
model; text to 3D images, like the Dreamfusion model; images to text, like the
Flamingo model; texts to video, like the Phenaki model; texts to audio, like
the AudioLM model; texts to other texts, like ChatGPT; texts to code, like the
Codex model; texts to scientific texts, like the Galactica model or even create
algorithms like AlphaTensor. This work consists on an attempt to describe in a
concise way the main models are sectors that are affected by generative AI and
to provide a taxonomy of the main generative models published recently."	[{'name': 'Roberto Gozalo-Brizuela'}, {'name': 'Eduardo C. Garrido-Merchan'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '22 pages'}	[{'@href': 'http://arxiv.org/abs/2301.04655v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.04655v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}]
20	http://arxiv.org/abs/2302.02094v1	2023-02-04T05:19:31Z	2023-02-04T05:19:31Z	"Chat2VIS: Generating Data Visualisations via Natural Language using
  ChatGPT, Codex and GPT-3 Large Language Models"	"The field of data visualisation has long aimed to generate visualisations
from natural language text. Research in Natural Language Interfaces (NLIs) has
contributed towards the development of a solution which allow users to interact
with data using natural language queries. However, the implementation of NLIs
is challenging due to the inherent ambiguity of natural language and frequent
underspecification of user queries. This study proposes using large language
models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language
directly into visualisations. This paper presents a novel system, Chat2VIS,
which leverages LLMs and demonstrates how effective prompt engineering can be
conducted in order to extract from LLMs the desired code for visualisations.
Chat2VIS shows that the use of pre-trained LLMs together with the proposed
priming prompts, offers an accurate and reliable approach to generating
visualisations from natural language queries, even those that are highly
misspecified and underspecified. This approach demonstrates gains in efficiency
and cost reduction in the development of these systems, while attaining greater
visualisation inference abilities compared to traditional NLP approaches that
use hand-crafted grammar rules. The study compares the performance of two types
of GPT-3 models and ChatGPT, while demonstrating that the proposed approach is
secure, privacy-preserving, and generalisable to different datasets."	[{'name': 'Paula Maddigan'}, {'name': 'Teo Susnjak'}]		[{'@href': 'http://arxiv.org/abs/2302.02094v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2302.02094v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.HC', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'cs.HC', '@scheme': 'http://arxiv.org/schemas/atom'}
21	http://arxiv.org/abs/2208.14582v2	2023-01-31T22:20:41Z	2022-08-31T00:57:17Z	"A Prescriptive Learning Analytics Framework: Beyond Predictive Modelling
  and onto Explainable AI with Prescriptive Analytics and ChatGPT"	"A significant body of recent research in the field of Learning Analytics has
focused on leveraging machine learning approaches for predicting at-risk
students in order to initiate timely interventions and thereby elevate
retention and completion rates. The overarching feature of the majority of
these research studies has been on the science of prediction only. The
component of predictive analytics concerned with interpreting the internals of
the models and explaining their predictions for individual cases to
stakeholders has largely been neglected. Additionally, works that attempt to
employ data-driven prescriptive analytics to automatically generate
evidence-based remedial advice for at-risk learners are in their infancy.
  eXplainable AI is a field that has recently emerged providing cutting-edge
tools which support transparent predictive analytics and techniques for
generating tailored advice for at-risk students. This study proposes a novel
framework that unifies both transparent machine learning as well as techniques
for enabling prescriptive analytics, while integrating the latest advances in
large language models. This work practically demonstrates the proposed
framework using predictive models for identifying at-risk learners of programme
non-completion. The study then further demonstrates how predictive modelling
can be augmented with prescriptive analytics on two case studies in order to
generate human-readable prescriptive feedback for those who are at risk using
ChatGPT."	{'name': 'Teo Susnjak'}	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'revision of the original paper to include ChatGPT integration'}	[{'@href': 'http://arxiv.org/abs/2208.14582v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2208.14582v2', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.CY', '@scheme': 'http://arxiv.org/schemas/atom'}]
22	http://arxiv.org/abs/2212.09993v2	2023-01-05T03:48:04Z	2022-12-20T04:33:32Z	Are Deep Neural Networks SMARTer than Second Graders?	"Recent times have witnessed an increasing number of applications of deep
neural networks towards solving tasks that require superior cognitive
abilities, e.g., playing Go, generating art, question answering (such as
ChatGPT), etc. Such a dramatic progress raises the question: how generalizable
are neural networks in solving problems that demand broad skills? To answer
this question, we propose SMART: a Simple Multimodal Algorithmic Reasoning Task
and the associated SMART-101 dataset, for evaluating the abstraction,
deduction, and generalization abilities of neural networks in solving
visuo-linguistic puzzles designed specifically for children in the 6-8 age
group. Our dataset consists of 101 unique puzzles; each puzzle comprises a
picture and a question, and their solution needs a mix of several elementary
skills, including arithmetic, algebra, and spatial reasoning, among others. To
scale our dataset towards training deep neural networks, we programmatically
generate entirely new instances for each puzzle while retaining their solution
algorithm. To benchmark the performance on the SMART-101 dataset, we propose a
vision and language meta-learning model using varied state-of-the-art backbone
neural networks. Our experiments reveal that while powerful deep models offer
reasonable performances on puzzles that they are trained on, they are not
better than random accuracy when analyzed for generalization. We also evaluate
the recent ChatGPT large language model on a subset of our dataset and find
that while ChatGPT produces convincing reasoning abilities, the answers are
often incorrect."	[{'name': 'Anoop Cherian'}, {'name': 'Kuan-Chuan Peng'}, {'name': 'Suhas Lohit'}, {'name': 'Kevin Smith'}, {'name': 'Joshua B. Tenenbaum'}]		[{'@href': 'http://arxiv.org/abs/2212.09993v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2212.09993v2', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.CV', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}]
23	http://arxiv.org/abs/2302.02337v2	2023-02-07T14:50:31Z	2023-02-05T08:56:45Z	Regulating ChatGPT and other Large Generative AI Models	"Large generative AI models (LGAIMs), such as ChatGPT or Stable Diffusion, are
rapidly transforming the way we communicate, illustrate, and create. However,
AI regulation, in the EU and beyond, has primarily focused on conventional AI
models, not LGAIMs. This paper will situate these new generative models in the
current debate on trustworthy AI regulation, and ask how the law can be
tailored to their capabilities. After laying technical foundations, the legal
part of the paper proceeds in four steps, covering (1) direct regulation, (2)
data protection, (3) content moderation, and (4) policy proposals. It suggests
a novel terminology to capture the AI value chain in LGAIM settings by
differentiating between LGAIM developers, deployers, professional and
non-professional users, as well as recipients of LGAIM output. We tailor
regulatory duties to these different actors along the value chain and suggest
four strategies to ensure that LGAIMs are trustworthy and deployed for the
benefit of society at large. Rules in the AI Act and other direct regulation
must match the specificities of pre-trained models. In particular, regulation
should focus on concrete high-risk applications, and not the pre-trained model
itself, and should include (i) obligations regarding transparency and (ii) risk
management. Non-discrimination provisions (iii) may, however, apply to LGAIM
developers. Lastly, (iv) the core of the DSA content moderation rules should be
expanded to cover LGAIMs. This includes notice and action mechanisms, and
trusted flaggers. In all areas, regulators and lawmakers need to act fast to
keep track with the dynamics of ChatGPT et al."	[{'name': 'Philipp Hacker'}, {'name': 'Andreas Engel'}, {'name': 'Marco Mauer'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'under review'}	[{'@href': 'http://arxiv.org/abs/2302.02337v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2302.02337v2', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CY', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CY', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'I.2', '@scheme': 'http://arxiv.org/schemas/atom'}]
24	http://arxiv.org/abs/2212.06721v2	2022-12-23T21:41:36Z	2022-12-09T16:32:11Z	The Turing Deception	"This research revisits the classic Turing test and compares recent large
language models such as ChatGPT for their abilities to reproduce human-level
comprehension and compelling text generation. Two task challenges --
summarization, and question answering -- prompt ChatGPT to produce original
content (98-99%) from a single text entry and also sequential questions
originally posed by Turing in 1950. We score the original and generated content
against the OpenAI GPT-2 Output Detector from 2019, and establish multiple
cases where the generated content proves original and undetectable (98%). The
question of a machine fooling a human judge recedes in this work relative to
the question of ""how would one prove it?"" The original contribution of the work
presents a metric and simple grammatical set for understanding the writing
mechanics of chatbots in evaluating their readability and statistical clarity,
engagement, delivery, and overall quality. While Turing's original prose scores
at least 14% below the machine-generated output, the question of whether an
algorithm displays hints of Turing's truly original thoughts (the ""Lovelace
2.0"" test) remains unanswered and potentially unanswerable for now."	[{'name': 'David Noever'}, {'name': 'Matt Ciolino'}]		[{'@href': 'http://arxiv.org/abs/2212.06721v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2212.06721v2', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}]
25	http://arxiv.org/abs/2212.10522v1	2022-12-20T18:37:11Z	2022-12-20T18:37:11Z	"Transformers Go for the LOLs: Generating (Humourous) Titles from
  Scientific Abstracts End-to-End"	"We consider the end-to-end abstract-to-title generation problem, exploring
seven recent transformer based models (including ChatGPT) fine-tuned on more
than 30k abstract-title pairs from NLP and machine learning venues. As an
extension, we also consider the harder problem of generating humorous paper
titles. For the latter, we compile the first large-scale humor annotated
dataset for scientific papers in the NLP/ML domains, comprising almost 2.5k
titles. We evaluate all models using human and automatic metrics. Our human
evaluation suggests that our best end-to-end system performs similarly to human
authors (but arguably slightly worse). Generating funny titles is more
difficult, however, and our automatic systems clearly underperform relative to
humans and often learn dataset artefacts of humor. Finally, ChatGPT, without
any fine-tuning, performs on the level of our best fine-tuned system."	[{'name': 'Yanran Chen'}, {'name': 'Steffen Eger'}]		[{'@href': 'http://arxiv.org/abs/2212.10522v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2212.10522v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}
26	http://arxiv.org/abs/2212.11126v2	2022-12-22T17:20:36Z	2022-12-18T16:08:40Z	Chatbots in a Botnet World	"Question-and-answer formats provide a novel experimental platform for
investigating cybersecurity questions. Unlike previous chatbots, the latest
ChatGPT model from OpenAI supports an advanced understanding of complex coding
questions. The research demonstrates thirteen coding tasks that generally
qualify as stages in the MITRE ATT&CK framework, ranging from credential access
to defense evasion. With varying success, the experimental prompts generate
examples of keyloggers, logic bombs, obfuscated worms, and payment-fulfilled
ransomware. The empirical results illustrate cases that support the broad gain
of functionality, including self-replication and self-modification, evasion,
and strategic understanding of complex cybersecurity goals. One surprising
feature of ChatGPT as a language-only model centers on its ability to spawn
coding approaches that yield images that obfuscate or embed executable
programming steps or links."	[{'name': 'Forrest McKee'}, {'name': 'David Noever'}]		[{'@href': 'http://arxiv.org/abs/2212.11126v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2212.11126v2', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CR', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CR', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}]
27	http://arxiv.org/abs/2301.01743v1	2023-01-01T03:04:04Z	2023-01-01T03:04:04Z	"Chatbots as Problem Solvers: Playing Twenty Questions with Role
  Reversals"	"New chat AI applications like ChatGPT offer an advanced understanding of
question context and memory across multi-step tasks, such that experiments can
test its deductive reasoning. This paper proposes a multi-role and multi-step
challenge, where ChatGPT plays the classic twenty-questions game but
innovatively switches roles from the questioner to the answerer. The main
empirical result establishes that this generation of chat applications can
guess random object names in fewer than twenty questions (average, 12) and
correctly guess 94% of the time across sixteen different experimental setups.
The research introduces four novel cases where the chatbot fields the
questions, asks the questions, both question-answer roles, and finally tries to
guess appropriate contextual emotions. One task that humans typically fail but
trained chat applications complete involves playing bilingual games of twenty
questions (English answers to Spanish questions). Future variations address
direct problem-solving using a similar inquisitive format to arrive at novel
outcomes deductively, such as patentable inventions or combination thinking.
Featured applications of this dialogue format include complex protein designs,
neuroscience metadata, and child development educational materials."	[{'name': 'David Noever'}, {'name': 'Forrest McKee'}]		[{'@href': 'http://arxiv.org/abs/2301.01743v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.01743v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}]
28	http://arxiv.org/abs/2301.03771v1	2023-01-10T03:43:35Z	2023-01-10T03:43:35Z	Chatbots in a Honeypot World	"Question-and-answer agents like ChatGPT offer a novel tool for use as a
potential honeypot interface in cyber security. By imitating Linux, Mac, and
Windows terminal commands and providing an interface for TeamViewer, nmap, and
ping, it is possible to create a dynamic environment that can adapt to the
actions of attackers and provide insight into their tactics, techniques, and
procedures (TTPs). The paper illustrates ten diverse tasks that a
conversational agent or large language model might answer appropriately to the
effects of command-line attacker. The original result features feasibility
studies for ten model tasks meant for defensive teams to mimic expected
honeypot interfaces with minimal risks. Ultimately, the usefulness outside of
forensic activities stems from whether the dynamic honeypot can extend the
time-to-conquer or otherwise delay attacker timelines short of reaching key
network assets like databases or confidential information. While ongoing
maintenance and monitoring may be required, ChatGPT's ability to detect and
deflect malicious activity makes it a valuable option for organizations seeking
to enhance their cyber security posture. Future work will focus on
cybersecurity layers, including perimeter security, host virus detection, and
data security."	[{'name': 'Forrest McKee'}, {'name': 'David Noever'}]		[{'@href': 'http://arxiv.org/abs/2301.03771v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.03771v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CR', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CR', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.CY', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}]
29	http://arxiv.org/abs/2206.05442v5	2022-12-23T13:41:18Z	2022-06-11T06:38:06Z	Automatically Answering and Generating Machine Learning Final Exams	"Can a machine learn machine learning? We propose to answer this question
using the same criteria we use to answer a similar question: can a human learn
machine learning? We automatically answer final exams in MIT's, Harvard's and
Cornell's large machine learning courses and generate new questions at a human
level. Recently, program synthesis and few-shot learning solved
university-level problem set questions in mathematics and STEM courses at a
human level. In this work, we solve questions from final exams that differ from
problem sets in several ways: the questions are longer, have multiple parts,
are more complicated, and span a broader set of topics. We provide a new
dataset and benchmark of questions from machine learning final exams and code
for automatically answering these questions and generating new questions. To
make our dataset a reproducible benchmark, we use automatic checkers for
multiple choice questions, questions with numeric answers, and questions with
expression answers, and evaluate a large free language model, Meta's OPT, and
compare the results with Open AI's GPT-3, ChatGPT, and Codex. A student survey
comparing the quality, appropriateness, and difficulty of machine-generated
questions with human-written questions shows that across multiple aspects,
machine-generated questions are indistinguishable from human-generated
questions and are suitable for final exams. We perform ablation studies
comparing zero-shot learning with few-shot learning, chain-of-thought
prompting, GPT-3, ChatGPT, and OPT pre-trained on text and Codex fine-tuned on
code on a range of machine learning topics and find that few-shot learning
methods perform best. We make our data and code publicly available for the
machine learning community."	[{'name': 'Sarah Zhang'}, {'name': 'Reece Shuttleworth'}, {'name': 'Zad Chin'}, {'name': 'Pedro Lantigua'}, {'name': 'Saisamrit Surbehera'}, {'name': 'Gregory Hunter'}, {'name': 'Derek Austin'}, {'name': 'Yann Hicke'}, {'name': 'Leonard Tang'}, {'name': 'Sathwik Karnik'}, {'name': 'Darnell Granberry'}, {'name': 'Iddo Drori'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '17 pages'}	[{'@href': 'http://arxiv.org/abs/2206.05442v5', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2206.05442v5', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}
30	http://arxiv.org/abs/2212.06933v1	2022-12-13T23:06:20Z	2022-12-13T23:06:20Z	"Paraphrase Identification with Deep Learning: A Review of Datasets and
  Methods"	"The rapid advancement of AI technology has made text generation tools like
GPT-3 and ChatGPT increasingly accessible, scalable, and effective. This can
pose serious threat to the credibility of various forms of media if these
technologies are used for plagiarism, including scientific literature and news
sources. Despite the development of automated methods for paraphrase
identification, detecting this type of plagiarism remains a challenge due to
the disparate nature of the datasets on which these methods are trained. In
this study, we review traditional and current approaches to paraphrase
identification and propose a refined typology of paraphrases. We also
investigate how this typology is represented in popular datasets and how
under-representation of certain types of paraphrases impacts detection
capabilities. Finally, we outline new directions for future research and
datasets in the pursuit of more effective paraphrase detection using AI."	[{'name': 'Chao Zhou', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Department of Computer Science, Syracuse University'}}, {'name': 'Cheng Qiu', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'School of Arts and Science, Vanderbilt University'}}, {'name': 'Daniel E. Acuna', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Department of Computer Science, University of Colorado at Boulder'}}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '36 pages, 2 figures, 6 tables, 173 references'}	[{'@href': 'http://arxiv.org/abs/2212.06933v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2212.06933v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.IR', '@scheme': 'http://arxiv.org/schemas/atom'}]
31	http://arxiv.org/abs/2212.10474v1	2022-12-20T17:49:49Z	2022-12-20T17:49:49Z	"ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free
  Language Models"	"State-of-the-art poetry generation systems are often complex. They either
consist of task-specific model pipelines, incorporate prior knowledge in the
form of manually created constraints or both. In contrast, end-to-end models
would not suffer from the overhead of having to model prior knowledge and could
learn the nuances of poetry from data alone, reducing the degree of human
supervision required. In this work, we investigate end-to-end poetry generation
conditioned on styles such as rhyme, meter, and alliteration. We identify and
address lack of training data and mismatching tokenization algorithms as
possible limitations of past attempts. In particular, we successfully pre-train
and release ByGPT5, a new token-free decoder-only language model, and fine-tune
it on a large custom corpus of English and German quatrains annotated with our
styles. We show that ByGPT5 outperforms other models such as mT5, ByT5, GPT-2
and ChatGPT, while also being more parameter efficient and performing favorably
compared to humans. In addition, we analyze its runtime performance and
introspect the model's understanding of style conditions. We make our code,
models, and datasets publicly available."	[{'name': 'Jonas Belouadi'}, {'name': 'Steffen Eger'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Preprint'}	[{'@href': 'http://arxiv.org/abs/2212.10474v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2212.10474v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}
32	http://arxiv.org/abs/2212.11661v1	2022-12-22T13:05:17Z	2022-12-22T13:05:17Z	The Death of the Short-Form Physics Essay in the Coming AI Revolution	"The latest AI language modules can produce original, high quality full
short-form ($300$-word) Physics essays within seconds. These technologies such
as ChatGPT and davinci-003 are freely available to anyone with an internet
connection. In this work, we present evidence of AI generated short-form essays
achieving first-class grades on an essay writing assessment from an accredited,
current university Physics module. The assessment requires students answer five
open-ended questions with a short, $300$-word essay each. Fifty AI answers were
generated to create ten submissions that were independently marked by five
separate markers. The AI generated submissions achieved an average mark of $71
\pm 2 \%$, in strong agreement with the current module average of $71 \pm 5 %$.
A typical AI submission would therefore most-likely be awarded a First Class,
the highest classification available at UK universities. Plagiarism detection
software returned a plagiarism score between $2 \pm 1$% (Grammarly) and $7 \pm
2$% (TurnitIn). We argue that these results indicate that current AI MLPs
represent a significant threat to the fidelity of short-form essays as an
assessment method in Physics courses."	[{'name': 'Will Yeadon'}, {'name': 'Oto-Obong Inyang'}, {'name': 'Arin Mizouri'}, {'name': 'Alex Peach'}, {'name': 'Craig Testrow'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '14 pages, 2 figures'}	[{'@href': 'http://arxiv.org/abs/2212.11661v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2212.11661v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'physics.ed-ph', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'physics.ed-ph', '@scheme': 'http://arxiv.org/schemas/atom'}
33	http://arxiv.org/abs/2301.11596v1	2023-01-27T08:45:53Z	2023-01-27T08:45:53Z	ThoughtSource: A central hub for large language model reasoning data	"Large language models (LLMs) such as GPT-3 and ChatGPT have recently
demonstrated impressive results across a wide range of tasks. LLMs are still
limited, however, in that they frequently fail at complex reasoning, their
reasoning processes are opaque, they are prone to 'hallucinate' facts, and
there are concerns about their underlying biases. Letting models verbalize
reasoning steps as natural language, a technique known as chain-of-thought
prompting, has recently been proposed as a way to address some of these issues.
Here we present the first release of ThoughtSource, a meta-dataset and software
library for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to
improve future artificial intelligence systems by facilitating qualitative
understanding of CoTs, enabling empirical evaluations, and providing training
data. This first release of ThoughtSource integrates six scientific/medical,
three general-domain and five math word question answering datasets."	[{'name': 'Simon Ott'}, {'name': 'Konstantin Hebenstreit'}, {'name': 'Valentin Liévin'}, {'name': 'Christoffer Egeberg Hother'}, {'name': 'Milad Moradi'}, {'name': 'Maximilian Mayrhauser'}, {'name': 'Robert Praas'}, {'name': 'Ole Winther'}, {'name': 'Matthias Samwald'}]		[{'@href': 'http://arxiv.org/abs/2301.11596v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.11596v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}]
34	http://arxiv.org/abs/2301.12066v1	2023-01-28T02:47:50Z	2023-01-28T02:47:50Z	Truth Machines: Synthesizing Veracity in AI Language Models	"As AI technologies are rolled out into healthcare, academia, human resources,
law, and a multitude of other domains, they become de-facto arbiters of truth.
But truth is highly contested, with many different definitions and approaches.
This article discusses the struggle for truth in AI systems and the general
responses to date. It then investigates the production of truth in InstructGPT,
a large language model, highlighting how data harvesting, model architectures,
and social feedback mechanisms weave together disparate understandings of
veracity. It conceptualizes this performance as an operationalization of truth,
where distinct, often conflicting claims are smoothly synthesized and
confidently presented into truth-statements. We argue that these same logics
and inconsistencies play out in Instruct's successor, ChatGPT, reiterating
truth as a non-trivial problem. We suggest that enriching sociality and
thickening ""reality"" are two promising vectors for enhancing the
truth-evaluating capacities of future language models. We conclude, however, by
stepping back to consider AI truth-telling as a social practice: what kind of
""truth"" do we as listeners desire?"	[{'name': 'Luke Munn'}, {'name': 'Liam Magee'}, {'name': 'Vanicka Arora'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '20 pages, 3 figures'}	[{'@href': 'http://arxiv.org/abs/2301.12066v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.12066v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CY', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CY', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}]
35	http://arxiv.org/abs/2301.12127v2	2023-02-01T17:22:16Z	2023-01-28T08:45:30Z	"Could an Artificial-Intelligence agent pass an introductory physics
  course?"	"Massive pre-trained language models have garnered attention and controversy
due to their ability to generate human-like responses: attention due to their
frequent indistinguishability from human-generated phraseology and narratives,
and controversy due to the fact that their convincingly presented arguments and
facts are frequently simply false. Just how human-like are these responses when
it comes to dialogues about physics, in particular about the standard content
of introductory physics courses? This study explores that question by having
ChatGTP, the pre-eminent language model in 2023, work through representative
assessment content of an actual calculus-based physics course and grading the
responses in the same way human responses would be graded. As it turns out,
ChatGPT would narrowly pass this course while exhibiting many of the
preconceptions and errors of a beginning learner."	{'name': 'Gerd Kortemeyer'}		[{'@href': 'http://arxiv.org/abs/2301.12127v2', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.12127v2', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'physics.ed-ph', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'physics.ed-ph', '@scheme': 'http://arxiv.org/schemas/atom'}
36	http://arxiv.org/abs/2301.12169v1	2023-01-28T11:47:03Z	2023-01-28T11:47:03Z	"Navigating Complexity in Software Engineering: A Prototype for Comparing
  GPT-n Solutions"	"Navigating the diverse solution spaces of non-trivial software engineering
tasks requires a combination of technical knowledge, problem-solving skills,
and creativity. With multiple possible solutions available, each with its own
set of trade-offs, it is essential for programmers to evaluate the various
options and select the one that best suits the specific requirements and
constraints of a project. Whether it is choosing from a range of libraries,
weighing the pros and cons of different architecture and design solutions, or
finding unique ways to fulfill user requirements, the ability to think
creatively is crucial for making informed decisions that will result in
efficient and effective software. However, the interfaces of current chatbot
tools for programmers, such as OpenAI's ChatGPT or GitHub Copilot, are
optimized for presenting a single solution, even for complex queries. While
other solutions can be requested, they are not displayed by default and are not
intuitive to access. In this paper, we present our work-in-progress prototype
""GPTCompare"", which allows programmers to visually compare multiple source code
solutions generated by GPT-n models for the same programming-related query by
highlighting their similarities and differences."	{'name': 'Christoph Treude'}		[{'@href': 'http://arxiv.org/abs/2301.12169v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.12169v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.SE', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.SE', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.HC', '@scheme': 'http://arxiv.org/schemas/atom'}]
37	http://arxiv.org/abs/2301.13246v1	2023-01-30T19:22:36Z	2023-01-30T19:22:36Z	Conversational Automated Program Repair	"Automated Program Repair (APR) can help developers automatically generate
patches for bugs. Due to the impressive performance obtained using Large
Pre-Trained Language Models (LLMs) on many code related tasks, researchers have
started to directly use LLMs for APR. However, prior approaches simply
repeatedly sample the LLM given the same constructed input/prompt created from
the original buggy code, which not only leads to generating the same incorrect
patches repeatedly but also miss the critical information in testcases. To
address these limitations, we propose conversational APR, a new paradigm for
program repair that alternates between patch generation and validation in a
conversational manner. In conversational APR, we iteratively build the input to
the model by combining previously generated patches with validation feedback.
As such, we leverage the long-term context window of LLMs to not only avoid
generating previously incorrect patches but also incorporate validation
feedback to help the model understand the semantic meaning of the program under
test. We evaluate 10 different LLM including the newly developed ChatGPT model
to demonstrate the improvement of conversational APR over the prior LLM for APR
approach."	[{'name': 'Chunqiu Steven Xia'}, {'name': 'Lingming Zhang'}]		[{'@href': 'http://arxiv.org/abs/2301.13246v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.13246v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.SE', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.SE', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}]
38	http://arxiv.org/abs/2301.13382v1	2023-01-31T03:14:57Z	2023-01-31T03:14:57Z	"Numeracy from Literacy: Data Science as an Emergent Skill from Large
  Language Models"	"Large language models (LLM) such as OpenAI's ChatGPT and GPT-3 offer unique
testbeds for exploring the translation challenges of turning literacy into
numeracy. Previous publicly-available transformer models from eighteen months
prior and 1000 times smaller failed to provide basic arithmetic. The
statistical analysis of four complex datasets described here combines
arithmetic manipulations that cannot be memorized or encoded by simple rules.
The work examines whether next-token prediction succeeds from sentence
completion into the realm of actual numerical understanding. For example, the
work highlights cases for descriptive statistics on in-memory datasets that the
LLM initially loads from memory or generates randomly using python libraries.
The resulting exploratory data analysis showcases the model's capabilities to
group by or pivot categorical sums, infer feature importance, derive
correlations, and predict unseen test cases using linear regression. To extend
the model's testable range, the research deletes and appends random rows such
that recall alone cannot explain emergent numeracy."	[{'name': 'David Noever'}, {'name': 'Forrest McKee'}]		[{'@href': 'http://arxiv.org/abs/2301.13382v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.13382v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}
39	http://arxiv.org/abs/2211.06869v3	2022-12-19T03:18:36Z	2022-11-13T10:16:39Z	What would Harry say? Building Dialogue Agents for Characters in a Story	"We have a Christmas gift for Harry Potter fans all over the world. In this
paper, we present Harry Potter Dialogue (HPD), a dataset that helps train Harry
Potter-like dialogue agents. Such a task is typically viewed as a variant of
personalized dialogue agents, but they differ significantly in three respects:
1) Harry lived in a virtual world of wizards, thus, real-world commonsense may
not apply to Harry's conversations; 2) Harry's behavior is strongly linked to
background information in conversations: the scene, its attributes and its
relationship to other speakers; and 3) Such backgrounds are dynamically altered
as the storyline goes on. The HPD dataset, as the first dataset to facilitate
the study of dialogue agent construction for characters within a story,
provides rich contextual information about each dialogue session such as
scenes, character attributes, and relations. More importantly, all the
background information will change over the course of the story. In addition,
HPD could support both dialogue generation and retrieval tasks. We evaluate
baselines such as Dialog-GPT and BOB to determine the extent to which they can
generate Harry Potter-like responses. The experimental results disappoint us in
that although the generated responses are fluent, they still seem out of
character for Harry. Besides, we validate the current most robust dialogue
agent, ChatGPT, which also can't generate plausible Harry-Potter-like responses
in some cases, either. Our results suggest that there is much scope for future
research."	[{'name': 'Nuo Chen'}, {'name': 'Yan Wang'}, {'name': 'Haiyun Jiang'}, {'name': 'Deng Cai'}, {'name': 'Ziyang Chen'}, {'name': 'Longyue Wang'}, {'name': 'Jia Li'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '14 pages'}	[{'@href': 'http://arxiv.org/abs/2211.06869v3', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2211.06869v3', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}]
40	http://arxiv.org/abs/2212.08104v1	2022-12-08T23:23:39Z	2022-12-08T23:23:39Z	"The Role of AI in Drug Discovery: Challenges, Opportunities, and
  Strategies"	"Artificial intelligence (AI) has the potential to revolutionize the drug
discovery process, offering improved efficiency, accuracy, and speed. However,
the successful application of AI is dependent on the availability of
high-quality data, the addressing of ethical concerns, and the recognition of
the limitations of AI-based approaches. In this article, the benefits,
challenges and drawbacks of AI in this field are reviewed, and possible
strategies and approaches for overcoming the present obstacles are proposed.
The use of data augmentation, explainable AI, and the integration of AI with
traditional experimental methods, as well as the potential advantages of AI in
pharmaceutical research are also discussed. Overall, this review highlights the
potential of AI in drug discovery and provides insights into the challenges and
opportunities for realizing its potential in this field.
  Note from the human-authors: This article was created to test the ability of
ChatGPT, a chatbot based on the GPT-3.5 language model, to assist human authors
in writing review articles. The text generated by the AI following our
instructions (see Supporting Information) was used as a starting point, and its
ability to automatically generate content was evaluated. After conducting a
thorough review, human authors practically rewrote the manuscript, striving to
maintain a balance between the original proposal and scientific criteria. The
advantages and limitations of using AI for this purpose are discussed in the
last section."	[{'name': 'Alexandre Blanco-Gonzalez'}, {'name': 'Alfonso Cabezon'}, {'name': 'Alejandro Seco-Gonzalez'}, {'name': 'Daniel Conde-Torres'}, {'name': 'Paula Antelo-Riveiro'}, {'name': 'Angel Pineiro'}, {'name': 'Rebeca Garcia-Fandino'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': '11 pages, 1 figure'}	[{'@href': 'http://arxiv.org/abs/2212.08104v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2212.08104v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.CY', '@scheme': 'http://arxiv.org/schemas/atom'}]
41	http://arxiv.org/abs/2301.03462v1	2023-01-01T22:50:08Z	2023-01-01T22:50:08Z	Modeling Label Semantics Improves Activity Recognition	"Human activity recognition (HAR) aims to classify sensory time series into
different activities, with wide applications in activity tracking, healthcare,
human computer interaction, etc. Existing HAR works improve recognition
performance by designing more complicated feature extraction methods, but they
neglect the label semantics by simply treating labels as integer IDs. We find
that many activities in the current HAR datasets have shared label names, e.g.,
""open door"" and ""open fridge"", ""walk upstairs"" and ""walk downstairs"". Through
some exploratory analysis, we find that such shared structure in activity names
also maps to similarity in the input features. To this end, we design a
sequence-to-sequence framework to decode the label name semantics rather than
classifying labels as integer IDs. Our proposed method decomposes learning
activities into learning shared tokens (""open"", ""walk""), which is easier than
learning the joint distribution (""open fridge"", ""walk upstairs"") and helps
transfer learning to activities with insufficient data samples. For datasets
originally without shared tokens in label names, we also offer an automated
method, using OpenAI's ChatGPT, to generate shared actions and objects.
Extensive experiments on seven HAR benchmark datasets demonstrate the
state-of-the-art performance of our method. We also show better performance in
the long-tail activity distribution settings and few-shot settings."	[{'name': 'Xiyuan Zhang'}, {'name': 'Ranak Roy Chowdhury'}, {'name': 'Dezhi Hong'}, {'name': 'Rajesh K. Gupta'}, {'name': 'Jingbo Shang'}]		[{'@href': 'http://arxiv.org/abs/2301.03462v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2301.03462v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'eess.SP', '@scheme': 'http://arxiv.org/schemas/atom'}]
42	http://arxiv.org/abs/2302.02676v1	2023-02-06T10:28:16Z	2023-02-06T10:28:16Z	Languages are Rewards: Hindsight Finetuning using Human Feedback	"Learning from human preferences is important for language models to be
helpful and useful for humans, and to align with human and social values.
Existing works focus on supervised finetuning of pretrained models, based on
curated model generations that are preferred by human labelers. Such works have
achieved remarkable successes in understanding and following instructions
(e.g., InstructGPT, ChatGPT, etc). However, to date, a key limitation of
supervised finetuning is that it cannot learn from negative ratings; models are
only trained on positive-rated data, which makes it data inefficient. Because
collecting human feedback data is both time consuming and expensive, it is
vital for the model to learn from all feedback, akin to the remarkable ability
of humans to learn from diverse feedback. In this work, we propose a novel
technique called Hindsight Finetuning for making language models learn from
diverse human feedback. In fact, our idea is motivated by how humans learn from
hindsight experience. We condition the model on a sequence of model generations
paired with hindsight feedback, and finetune the model to predict the most
preferred output. By doing so, models can learn to identify and correct
negative attributes or errors. Applying the method to GPT-J, we observe that it
significantly improves results on summarization and dialogue tasks using the
same amount of human feedback."	[{'name': 'Hao Liu'}, {'name': 'Carmelo Sferrazza'}, {'name': 'Pieter Abbeel'}]		[{'@href': 'http://arxiv.org/abs/2302.02676v1', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2302.02676v1', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.CL', '@scheme': 'http://arxiv.org/schemas/atom'}]
43	http://arxiv.org/abs/2211.13960v5	2023-01-23T11:57:41Z	2022-11-25T09:08:11Z	"The European AI Liability Directives -- Critique of a Half-Hearted
  Approach and Lessons for the Future"	"As ChatGPT et al. conquer the world, the optimal liability framework for AI
systems remains an unsolved problem across the globe. In a much-anticipated
move, the European Commission advanced two proposals outlining the European
approach to AI liability in September 2022: a novel AI Liability Directive and
a revision of the Product Liability Directive. They constitute the final
cornerstone of EU AI regulation. Crucially, the liability proposals and the EU
AI Act are inherently intertwined: the latter does not contain any individual
rights of affected persons, and the former lack specific, substantive rules on
AI development and deployment. Taken together, these acts may well trigger a
Brussels Effect in AI regulation, with significant consequences for the US and
beyond.
  This paper makes three novel contributions. First, it examines in detail the
Commission proposals and shows that, while making steps in the right direction,
they ultimately represent a half-hearted approach: if enacted as foreseen, AI
liability in the EU will primarily rest on disclosure of evidence mechanisms
and a set of narrowly defined presumptions concerning fault, defectiveness and
causality. Hence, second, the article suggests amendments, which are collected
in an Annex at the end of the paper. Third, based on an analysis of the key
risks AI poses, the final part of the paper maps out a road for the future of
AI liability and regulation, in the EU and beyond. This includes: a
comprehensive framework for AI liability; provisions to support innovation; an
extension to non-discrimination/algorithmic fairness, as well as explainable
AI; and sustainability. I propose to jump-start sustainable AI regulation via
sustainability impact assessments in the AI Act and sustainable design defects
in the liability regime. In this way, the law may help spur not only fair AI
and XAI, but potentially also sustainable AI (SAI)."	{'name': 'Philipp Hacker'}	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'under peer-review; contains 3 Tables'}	[{'@href': 'http://arxiv.org/abs/2211.13960v5', '@rel': 'alternate', '@type': 'text/html'}, {'@title': 'pdf', '@href': 'http://arxiv.org/pdf/2211.13960v5', '@rel': 'related', '@type': 'application/pdf'}]	{'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '@term': 'cs.CY', '@scheme': 'http://arxiv.org/schemas/atom'}	[{'@term': 'cs.CY', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.AI', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'cs.LG', '@scheme': 'http://arxiv.org/schemas/atom'}, {'@term': 'I.2', '@scheme': 'http://arxiv.org/schemas/atom'}]
