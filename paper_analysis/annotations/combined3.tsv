Annotator	Venue	Authors	Title	Abstract	Performance Sentiment	Topic1	Topic2	Social Sentiment	Real Abstract?		
Annotator1	Afro-Egyptian Journal of Infectious and Endemic Diseases	[{'authorId': '2204181382', 'name': 'Chris Zielinski'}, {'authorId': '2204229179', 'name': 'Margaret Winker'}, {'authorId': '2204060826', 'name': 'Rakesh Aggarwal'}, {'authorId': '2204139714', 'name': 'Lorraine Ferris'}, {'authorId': '2204088680', 'name': 'Markus Heinemann'}, {'authorId': None, 'name': 'Jose Florencio LapeÃ±a, Jr'}, {'authorId': '2204241478', 'name': 'Sanjay Pai'}, {'authorId': '2204225725', 'name': 'Edsel Ing'}, {'authorId': '2204240490', 'name': 'Leslie Citrome'}]	Chatbots, ChatGPT, and Scholarly Manuscripts WAME Recommendations on ChatGPT and Chatbots in Relation to Scholarly Publications	Journals have begun to publish papers in which chatbots such as ChatGPT are shown as co-authors. The following WAME recommendations are intended to inform editors and help them develop policies regarding chatbots for their journals, to help authors understand how use of chatbots might be attributed in their work, and address the need for all journal editors to have access manuscript screening tools. In this rapidly evolving field, we expect these recommendations to evolve as well.	0	ETHICS	Regulations	Threat			
Annotator1	Annals of Biomedical Engineering	[{'authorId': '152378504', 'name': 'Michael R King'}]	The Future of AI in Medicine: A Perspective from a Chatbot	Like many other technology users and enthusiasts, I have been captivated by the capabilities of ChatGPT, the new natural language chatbot utility developed by OpenAI and recently released for research testing. Testing ChatGPT and encouraging it to produce both useful, and humorous, responses that are remarkably well-written and human-like prompted me to wonder… have we reached the point in the evolution of technology where an AI-driven chatbot could write, or cowrite, a perspective article on the very topic of the Future of AI in Medicine? How meta! Interestingly, while asked to write a journal cover letter for this manuscript (included at the end), ChatGPT come up with the final article title you see above. Have we reached the age of chatbots as a legitimate voice in scientific publishing? See for yourself…  	4	MEDICAL		Opportunity			
Annotator1	Arthroscopy: The Journal of Arthroscopy And Related	[{'authorId': '2175437221', 'name': 'James H. Lubowitz'}]	ChatGPT, An Artificial Intelligence Chatbot, Is Impacting Medical Literature	As is evident in a Letter to the Editor from Gilat and Cole, “How Will Artificial Intelligence Affect Scientific Writing, Reviewing and Editing? The Future is Here…”,1 ChatGPT is now impacting the medical literature. As ChatGPT was used to write part of the letter, we can say with certainty that ChatGPT is now published in Arthroscopy. ChatGPT is an artificial intelligence (AI) chatbot tool. In other words, ChatGPT is a machine, a program, a robot, or technically, a large language model trained on enormous amounts of information from the Internet. It is able to respond to user prompts by answering questions; writing essays, poems, love letters, computer code, or business plans; solving problems including math or physics; and more.2,  3,  4 “The bot doesn’t just search and summarize information that already exists. It creates new content, tailored to your request.”5 ChatGPT has been used to write parts of newspaper and magazine articles, testing readers ability to determine whether the writing was by the chatbot or a human,4 so it is no surprise that Editorial Board Member Ron Gilat and Journal Board of Trustees Member and AANA Past President Brian Cole have now used the bot to write part of their letter.1	4	MEDICAL		Opportunity			
Annotator1	bioRxiv	[{'authorId': '2149285611', 'name': 'Catherine A. Gao'}, {'authorId': '1737779229', 'name': 'Frederick M. Howard'}, {'authorId': '1411115878', 'name': 'N. Markov'}, {'authorId': '2186065223', 'name': 'E. Dyer'}, {'authorId': '144972037', 'name': 'S. Ramesh'}, {'authorId': '1683396', 'name': 'Yuan Luo'}, {'authorId': '2198493546', 'name': 'Alexander T. Pearson'}]	Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers	Background Large language models such as ChatGPT can produce increasingly realistic text, with unknown information on the accuracy and integrity of using these models in scientific writing. Methods We gathered ten research abstracts from five high impact factor medical journals (n=50) and asked ChatGPT to generate research abstracts based on their titles and journals. We evaluated the abstracts using an artificial intelligence (AI) output detector, plagiarism detector, and had blinded human reviewers try to distinguish whether abstracts were original or generated. Results All ChatGPT-generated abstracts were written clearly but only 8% correctly followed the specific journalâ€™s formatting requirements. Most generated abstracts were detected using the AI output detector, with scores (higher meaning more likely to be generated) of median [interquartile range] of 99.98% [12.73, 99.98] compared with very low probability of AI-generated output in the original abstracts of 0.02% [0.02, 0.09]. The AUROC of the AI output detector was 0.94. Generated abstracts scored very high on originality using the plagiarism detector (100% [100, 100] originality). Generated abstracts had a similar patient cohort size as original abstracts, though the exact numbers were fabricated. When given a mixture of original and general abstracts, blinded human reviewers correctly identified 68% of generated abstracts as being generated by ChatGPT, but incorrectly identified 14% of original abstracts as being generated. Reviewers indicated that it was surprisingly difficult to differentiate between the two, but that the generated abstracts were vaguer and had a formulaic feel to the writing. Conclusion ChatGPT writes believable scientific abstracts, though with completely generated data. These are original without any plagiarism detected but are often identifiable using an AI output detector and skeptical human reviewers. Abstract evaluation for journals and medical conferences must adapt policy and practice to maintain rigorous scientific standards; we suggest inclusion of AI output detectors in the editorial process and clear disclosure if these technologies are used. The boundaries of ethical and acceptable use of large language models to help scientific writing remain to be determined.	4	EVALUATION		Mixed			
Annotator1	BMJ	[{'authorId': '1620851794', 'name': 'Mun-Keat Looi'}]	Sixty seconds on . . . ChatGPT	A new dating app for GPs? No, but it could probably do that. ChatGPT1 is the latest artificial intelligence (AI) chatbot to cause a stir. It can respond to queries and requests with prose of surprising quality, almost indistinguishable from that of a human writer. It’s so seemingly authentic and easy to use that academics and medics are both in wonder and worry over how it might shake up the system.  How so? Education is one thing. Some students have already used the bot to generate essays that pass …	0	REST		Mixed			
Annotator1	British Dental Journal	[{'authorId': '51027918', 'name': 'A. Kaushik'}]	HPV training	Sir, the world of technology is buzzing with a new word – ChatGPT, a new artificial intelligence (AI) chatbot which is trained to follow instructions in a prompt and provide a detailed response.1,2 Users can simply feed in their queries, and the chatbot will reply to them. Unlike other AI chatbots, ChatGPT can answer follow-up questions, admit their mistakes, challenge incorrect premises, and reject inappropriate requests. As an example, Figure 1 shows text that was generated within three seconds when ChatGPT was instructed to ‘write a letter to the editor about artificial intelligence in dentistry in 300 words’. ChatGPT was launched on 30 November 2022, by San Francisco-based OpenAI. It was co-founded by its current CEO, Sam Altman, and Elon Musk in 2015 and is presently funded by Microsoft and others. By 4 December 2022, OpenAI estimated ChatGPT already had over one million users. At its core, ChatGPT is a large language model and is an AI-powered conversational chatbot, which uses algorithms to analyse a massive corpus of text, often scraped from the internet, to respond to user requests in language that can sound surprisingly human.3 It is not free from errors or limitations. On its website, OpenAI admits that ChatGPT sometimes writes plausiblesounding but incorrect or nonsensical answers.4 While there is immense scope for AI in dentistry, academic and scientific journals will have serious issues to confront, as soon they will also need AI to detect whether the text was generated by AI or human intelligence.5 N. Kurian, J. M. Cherian, N. A. Sudharson, K. G. Varghese, S. Wadhwa, Ludhiana, India  	0	MEDICAL		Mixed			
Annotator1	Cellular and Molecular Bioengineering	[{'authorId': '152378504', 'name': 'Michael R King'}, {'authorId': '2196932745', 'name': 'chatGPT'}]	A Conversation on Artificial Intelligence, Chatbots, and Plagiarism in Higher Education	The history of AI and chatbots can be traced back to the 1950s when scientists first began exploring the concept of artificial intelligence. Early developments included the creation of the first AI program called ELIZA, which was designed to mimic human conversation. In the decades that followed, AI technology continued to advance, leading to the development of more sophisticated chatbots with the ability to understand and respond to complex requests. Today, AI and chatbots are used in a wide range of industries, from customer service to healthcare, and are continuing to evolve as technology advances.  	4	OTHER		NAN			
Annotator1	ChemViews	[{'authorId': '2075937681', 'name': 'Vera Koester'}, {'authorId': '12374747', 'name': 'Catharina Goedecke'}]	Chatting With ChatGPT	Everyone is talking about it and trying it out right now, so we also experimented with ChatGPT and asked questions about science communication, AI in chemistry, publication ethics, and the purpose of life. It’s great fun, the answers almost always come up lightning fast … see for yourself what came out of this experiment.	4	OTHER		NAN			
Annotator1	Cureus	[{'authorId': None, 'name': 'Haris M Akhter'}, {'authorId': '47511413', 'name': 'J. Cooper'}]	Acute Pulmonary Edema After Hyperbaric Oxygen Treatment: A Case Report Written With ChatGPT Assistance	Acute pulmonary edema is a rare but severe complication of hyperbaric oxygen therapy. While patients with known cardiovascular problems may be able to withstand this therapy, rapid decompensation can still occur. Here, we present a case of a patient with known low ejection fraction and severe mitral regurgitation who developed acute pulmonary edema during the first hyperbaric treatment for a foot ulcer. This case highlights the importance of identifying patients that are high risk, such as those with moderate-to-severe cardiac disease, and pursuing other treatment options to avoid this complication.  	4	MEDICAL		Opportunity			
Annotator1	Education in the Knowledge Society (EKS)	[{'authorId': None, 'name': 'Francisco JosÃ© GarcÃ­a-PeÃ±alvo'}]	La percepciÃ³n de la Inteligencia Artificial en contextos educativos tras el lanzamiento de ChatGPT: disrupciÃ³n o pÃ¡nico	El aÃ±o 2022 ha finalizado con una de esas innovaciones tecnolÃ³gicas que tienen un comportamiento difÃ­cil de predecir, un cisne negro, acaparando la atenciÃ³n en los medios de comunicaciÃ³n tradicionales y los medios digitales. Efectivamente, se trata de ChatGPT. Si bien la inteligencia artificial ya venÃ­a ocupando un lugar destacado en diversas noticias, aunque muchas veces enmascarada bajo otras diversas acepciones, el fenÃ³meno ChatGPT ha vuelto a poner en primera plana esta disciplina, asÃ­ como sus efectos, tanto positivos como negativos, en nuestra sociedad. Las reacciones a su lanzamiento, sobre todo influidas por su facilidad de acceso y uso, estÃ¡n siendo de lo mÃ¡s variadas, yendo del entusiasmo de los innovadores y adoptadores tempranos hasta el terror casi apocalÃ­ptico propio de la pelÃ­cula Terminator. De las mÃºltiples aplicaciones de esta herramienta, el mayor debate estÃ¡ centrÃ¡ndose en sus implicaciones en la EducaciÃ³n y en la Academia, por su tremenda potencia para generar textos que perfectamente podrÃ­an pasar por creaciones humanas. Estamos en los albores de una tecnologÃ­a que ha pasado de ser una herramienta de juguete a presentar su candidatura a convertirse en una innovaciÃ³n disruptiva. Que lo consiga o no dependerÃ¡ de muchos factores, pero si no es esta serÃ¡ otra similar. Negarlo o prohibirlo no servirÃ¡ absolutamente de nada para parar el efecto tsunami que ya ha comenzado. Por todo ello, primero hay que entender estas tecnologÃ­as basadas en modelos de lenguaje y conocer tanto sus beneficios como sus puntos dÃ©biles, ademÃ¡s de lo que realmente suponen para un sector de actividad especÃ­fico, como puede ser la EducaciÃ³n. DespuÃ©s de conocer la tecnologÃ­a y la herramienta, se estarÃ­a en condiciones de utilizar (o no) su potencial y de prevenir o detectar sus posibles efectos perniciosos, seguramente cambiando y adaptando procesos que probablemente se tengan muy arraigados y que, por tanto, obliguen a salir de la zona de confort, lo que siempre es causa de resistencia al cambio y de reacciones extremas que, normalmente, no van a parar el camino de una tecnologÃ­a hacia su meseta de productividad cuando esta llegue a ser parte cotidiana de una mayorÃ­a suficiente de usuarios, mÃ¡xime cuando ademÃ¡s se trata de herramientas transversales que van a contagiar sus patrones de uso entre los diferentes dominios de aplicaciÃ³n.	0	OTHER		Mixed			
Annotator1	medRxiv	[{'authorId': '2051250388', 'name': 'T. Kung'}, {'authorId': '2045482362', 'name': 'M. Cheatham'}, {'authorId': '2196935808', 'name': 'A. Medinilla'}, {'authorId': '2196932745', 'name': 'chatGPT'}, {'authorId': '2196932743', 'name': 'C. Sillos'}, {'authorId': '2194457777', 'name': 'L. D. De Leon'}, {'authorId': '2196937260', 'name': 'C. Elepano'}, {'authorId': '2101601654', 'name': 'M. Madriaga'}, {'authorId': '117973505', 'name': 'R. Aggabao'}, {'authorId': '2196935806', 'name': 'G. Diaz-Candido'}, {'authorId': '7262505', 'name': 'J. Maningo'}, {'authorId': '2196932802', 'name': 'V. Tseng'}]	Performance of ChatGPT on USMLE: Potential for AI-Assisted Medical Education Using Large Language Models	We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, even clinical decision-making.	5	MEDICAL	EDUCATION	Opportunity	y		
Annotator1	medRxiv	[{'authorId': '2107029904', 'name': 'A. Gilson'}, {'authorId': '40902199', 'name': 'C. Safranek'}, {'authorId': '2181652492', 'name': 'T. Huang'}, {'authorId': '11035690', 'name': 'V. Socrates'}, {'authorId': '2087060121', 'name': 'L. Chi'}, {'authorId': '143794498', 'name': 'R. A. Taylor'}, {'authorId': '3181480', 'name': 'David Chartash'}]	How Well Does ChatGPT Do When Taking the Medical Licensing Exams? The Implications of Large Language Models for Medical Education and Knowledge Assessment	Background: ChatGPT is a 175 billion parameter natural language processing model which can generate conversation style responses to user input. Objective: To evaluate the performance of ChatGPT on questions within the scope of United States Medical Licensing Examination (USMLE) Step 1 and Step 2 exams, as well as analyze responses for user interpretability. Methods: We used two novel sets of multiple choice questions to evaluate ChatGPT's performance, each with questions pertaining to Step 1 and Step 2. The first was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the userbase. The second, was the National Board of Medical Examiners (NBME) Free 120-question exams. After prompting ChatGPT with each question, ChatGPT's selected answer was recorded, and the text output evaluated across three qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question. Results: On the four datasets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBME-Free- Step2, ChatGPT achieved accuracies of 44%, 42%, 64.4%, and 57.8%. The model demonstrated a significant decrease in performance as question difficulty increased (P=.012) within the AMBOSS- Step1 dataset. We found logical justification for ChatGPT's answer selection was present in 100% of outputs. Internal information to the question was present in >90% of all questions. The presence of information external to the question was respectively 54.5% and 27% lower for incorrect relative to correct answers on the NBME-Free-Step1 and NBME-Free-Step2 datasets (P<=.001). Conclusion: ChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at greater than 60% threshold on the NBME-Free- Step-1 dataset we show that the model is comparable to a third year medical student. Additionally, due to the dialogic nature of the response to questions, we demonstrate ChatGPT's ability to provide reasoning and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as a medical education tool.	5	MEDICAL	EDUCATION	Opportunity	y		
Annotator1	medRxiv	[{'authorId': '103525980', 'name': 'J. Kim'}]	Search for Medical Information and Treatment Options for Musculoskeletal Disorders through an Artificial Intelligence Chatbot: Focusing on Shoulder Impingement Syndrome	Background: The ChatGPT is an artificial intelligence chatbot that processes natural language text learned through reinforcement learning based on the GPT-3.5 architecture, a large-scale language model. Natural language processing models are being used in various fields and are gradually expanding their use in the medical field. Purpose: This study aimed to investigate the medical information or treatment options that ChatGPT can provide for SIS. Method: Using ChatGPT, which is provided as a free beta test, messages related to SIS were entered, and responses to medical information and treatment options were received and analyzed. Result: ChatGPT not only provided answers to the definition, prevalence, and risk factors of SIS, but also symptoms, diseases with similar symptoms, and orthopedic tests according to the messages input. Additionally, a list of treatment options and exercises were provided. Conclusion: ChatGPT will be able to provide overall useful medical information and treatment options to patients unfamiliar with SIS. However, caution is required as it contains content that may be biased or inappropriate information for patients with SIS. Nevertheless, if natural language processing technology develops further, it is expected to be able to express more detailed medical information and treatment options.	4	MEDICAL	APPLICATION	Opportunity	y		
Annotator1	Mesopotamian Journal of Cyber Security	[{'authorId': '1447250772', 'name': 'Mohammad Aljanabi'}, {'authorId': '2196932745', 'name': 'chatGPT'}]	ChatGPT: Future Directions and Open possibilities	ChatGPT, the cutting-edge language model developed by OpenAI, is one of the most exciting advancements in the field of artificial intelligence. With its ability to generate human-like text and respond to complex questions, ChatGPT has already made a significant impact and is poised to continue its rapid progression in the coming years. As we look to the future of ChatGPT and large language models, there are many exciting possibilities and open opportunities for this technology to enhance our lives and change the way we interact with technology	5	REST	APPLICATION	Opportunity	n		
Annotator1	Nature	[{'authorId': '82335473', 'name': 'Flora Graham'}]	Daily briefing: Will ChatGPT kill the essay assignment?	Academics worry about students using artificial intelligence tools to write their homework. Plus, why strep A infections are surging and the historic Artemis mission is home safe.	0	EDUCATION		THREAT	n		
Annotator1	Nature	[{'authorId': '1413934873', 'name': 'Chris Stokel-Walker'}]	ChatGPT listed as author on research papers: many scientists disapprove	At least four articles credit the AI tool as a co-author, as publishers scramble to regulate its use.	3	ETHICS/REGULATIONS	APPLICATION	NAN	n		
Annotator1	Science	[{'authorId': '2003404994', 'name': 'H. Thorp'}]	ChatGPT is fun, but not an author	In less than 2 months, the artificial intelligence (AI) program ChatGPT has become a cultural sensation. It is freely accessible through a web portal created by the toolâ€™s developer, OpenAI. The programâ€”which automatically creates text based on written promptsâ€”is so popular that itâ€™s likely to be â€œat capacity right nowâ€ if you attempt to use it. When you do get through, ChatGPT provides endless entertainment. I asked it to rewrite the first scene of the classic American play Death of a Salesman, but to feature Princess Elsa from the animated movie Frozen as the main character instead of Willy Loman. The output was an amusing conversation in which Elsaâ€”who has come home from a tough day of sellingâ€”is told by her son Happy, â€œCome on, Mom. Youâ€™re Elsa from Frozen. You have ice powers and youâ€™re a queen. Youâ€™re unstoppable.â€ Mash-ups like this are certainly fun, but there are serious implications for generative AI programs like ChatGPT in science and academia.	3	EDUCATION	APPLICATION	THREAT	n		
Annotator1	Seeds of Science	[{'authorId': '2073872541', 'name': 'S. Buck'}]	Why Proposal Review Should Be More Like Meteorology	The process of evaluating research proposals for funding is often based on subjective assessments of the "goodness" or "badness" of a proposal. However, this method of evaluation is not precise and does not provide a common language for reviewers to communicate with each other. In this paper, we propose that science funding agencies ask reviewers to assign quantitative probabilities to the likelihood of a proposal reaching a particular milestone or achieving technical goals. This approach would encourage reviewers to be more precise in their evaluations and could improve both agency-wide and individual reviewer calibration over time. Additionally, this method would allow funding agencies to identify skilled reviewers and allow reviewers to improve their own performance through consistent feedback. While this method may not be suitable for all types of research, it has the potential to enhance proposal review in a variety of fields. [abstract generated by ChatGPT]	0	APPLICATION		NAN	y		
Annotator1	SSRN Electronic Journal	[{'authorId': '46308962', 'name': 'Jonathan H. Choi'}, {'authorId': '98900189', 'name': 'Kristin E. Hickman'}, {'authorId': '16166682', 'name': 'Amy B. Monahan'}, {'authorId': '83686718', 'name': 'D. Schwarcz'}]	ChatGPT Goes to Law School	How well can AI models write law school exams without human assistance? To find out, we used the widely publicized AI model ChatGPT to generate answers on four real exams at the University of Minnesota Law School. We then blindly graded these exams as part of our regular grading processes for each class. Over 95 multiple choice questions and 12 essay questions, ChatGPT performed on average at the level of a C+ student, achieving a low but passing grade in all four courses. After detailing these results, we discuss their implications for legal education and lawyering. We also provide example prompts and advice on how ChatGPT can assist with legal writing.	4	EDUCATION		NAN	y		
Annotator1	The Pediatric Infectious Disease Journal	[{'authorId': '143739014', 'name': 'N. Curtis'}]	To ChatGPT or not to ChatGPT? The Impact of Artificial Intelligence on Academic Publishing.		0	EDUCATION	REGULATIONS	NAN	Paywall		
Annotator2	Afro-Egyptian Journal of Infectious and Endemic Diseases	[{'authorId': '2204181382', 'name': 'Chris Zielinski'}, {'authorId': '2204229179', 'name': 'Margaret Winker'}, {'authorId': '2204060826', 'name': 'Rakesh Aggarwal'}, {'authorId': '2204139714', 'name': 'Lorraine Ferris'}, {'authorId': '2204088680', 'name': 'Markus Heinemann'}, {'authorId': None, 'name': 'Jose Florencio LapeÃ±a, Jr'}, {'authorId': '2204241478', 'name': 'Sanjay Pai'}, {'authorId': '2204225725', 'name': 'Edsel Ing'}, {'authorId': '2204240490', 'name': 'Leslie Citrome'}]	Chatbots, ChatGPT, and Scholarly Manuscripts WAME Recommendations on ChatGPT and Chatbots in Relation to Scholarly Publications	Journals have begun to publish papers in which chatbots such as ChatGPT are shown as co-authors. The following WAME recommendations are intended to inform editors and help them develop policies regarding chatbots for their journals, to help authors understand how use of chatbots might be attributed in their work, and address the need for all journal editors to have access manuscript screening tools. In this rapidly evolving field, we expect these recommendations to evolve as well.	0	REST		NAN			
Annotator2	Annals of Biomedical Engineering	[{'authorId': '152378504', 'name': 'Michael R King'}]	The Future of AI in Medicine: A Perspective from a Chatbot	Like many other technology users and enthusiasts, I have been captivated by the capabilities of ChatGPT, the new natural language chatbot utility developed by OpenAI and recently released for research testing. Testing ChatGPT and encouraging it to produce both useful, and humorous, responses that are remarkably well-written and human-like prompted me to wonder… have we reached the point in the evolution of technology where an AI-driven chatbot could write, or cowrite, a perspective article on the very topic of the Future of AI in Medicine? How meta! Interestingly, while asked to write a journal cover letter for this manuscript (included at the end), ChatGPT come up with the final article title you see above. Have we reached the age of chatbots as a legitimate voice in scientific publishing? See for yourself…  	4	APPLICATION	WRITING, MEDICAL	Opportunity			
Annotator2	Arthroscopy: The Journal of Arthroscopy And Related	[{'authorId': '2175437221', 'name': 'James H. Lubowitz'}]	ChatGPT, An Artificial Intelligence Chatbot, Is Impacting Medical Literature	As is evident in a Letter to the Editor from Gilat and Cole, “How Will Artificial Intelligence Affect Scientific Writing, Reviewing and Editing? The Future is Here…”,1 ChatGPT is now impacting the medical literature. As ChatGPT was used to write part of the letter, we can say with certainty that ChatGPT is now published in Arthroscopy. ChatGPT is an artificial intelligence (AI) chatbot tool. In other words, ChatGPT is a machine, a program, a robot, or technically, a large language model trained on enormous amounts of information from the Internet. It is able to respond to user prompts by answering questions; writing essays, poems, love letters, computer code, or business plans; solving problems including math or physics; and more.2,  3,  4 “The bot doesn’t just search and summarize information that already exists. It creates new content, tailored to your request.”5 ChatGPT has been used to write parts of newspaper and magazine articles, testing readers ability to determine whether the writing was by the chatbot or a human,4 so it is no surprise that Editorial Board Member Ron Gilat and Journal Board of Trustees Member and AANA Past President Brian Cole have now used the bot to write part of their letter.1	4	APPLICATION	WRITING	Opportunity			
Annotator2	bioRxiv	[{'authorId': '2149285611', 'name': 'Catherine A. Gao'}, {'authorId': '1737779229', 'name': 'Frederick M. Howard'}, {'authorId': '1411115878', 'name': 'N. Markov'}, {'authorId': '2186065223', 'name': 'E. Dyer'}, {'authorId': '144972037', 'name': 'S. Ramesh'}, {'authorId': '1683396', 'name': 'Yuan Luo'}, {'authorId': '2198493546', 'name': 'Alexander T. Pearson'}]	Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers	Background Large language models such as ChatGPT can produce increasingly realistic text, with unknown information on the accuracy and integrity of using these models in scientific writing. Methods We gathered ten research abstracts from five high impact factor medical journals (n=50) and asked ChatGPT to generate research abstracts based on their titles and journals. We evaluated the abstracts using an artificial intelligence (AI) output detector, plagiarism detector, and had blinded human reviewers try to distinguish whether abstracts were original or generated. Results All ChatGPT-generated abstracts were written clearly but only 8% correctly followed the specific journalâ€™s formatting requirements. Most generated abstracts were detected using the AI output detector, with scores (higher meaning more likely to be generated) of median [interquartile range] of 99.98% [12.73, 99.98] compared with very low probability of AI-generated output in the original abstracts of 0.02% [0.02, 0.09]. The AUROC of the AI output detector was 0.94. Generated abstracts scored very high on originality using the plagiarism detector (100% [100, 100] originality). Generated abstracts had a similar patient cohort size as original abstracts, though the exact numbers were fabricated. When given a mixture of original and general abstracts, blinded human reviewers correctly identified 68% of generated abstracts as being generated by ChatGPT, but incorrectly identified 14% of original abstracts as being generated. Reviewers indicated that it was surprisingly difficult to differentiate between the two, but that the generated abstracts were vaguer and had a formulaic feel to the writing. Conclusion ChatGPT writes believable scientific abstracts, though with completely generated data. These are original without any plagiarism detected but are often identifiable using an AI output detector and skeptical human reviewers. Abstract evaluation for journals and medical conferences must adapt policy and practice to maintain rigorous scientific standards; we suggest inclusion of AI output detectors in the editorial process and clear disclosure if these technologies are used. The boundaries of ethical and acceptable use of large language models to help scientific writing remain to be determined.	4	APPLICATION	WRITING	Mixed			
Annotator2	BMJ	[{'authorId': '1620851794', 'name': 'Mun-Keat Looi'}]	Sixty seconds on . . . ChatGPT	A new dating app for GPs? No, but it could probably do that. ChatGPT1 is the latest artificial intelligence (AI) chatbot to cause a stir. It can respond to queries and requests with prose of surprising quality, almost indistinguishable from that of a human writer. It’s so seemingly authentic and easy to use that academics and medics are both in wonder and worry over how it might shake up the system.  How so? Education is one thing. Some students have already used the bot to generate essays that pass …	4	REST		Opportunity			
Annotator2	British Dental Journal	[{'authorId': '51027918', 'name': 'A. Kaushik'}]	HPV training	Sir, the world of technology is buzzing with a new word – ChatGPT, a new artificial intelligence (AI) chatbot which is trained to follow instructions in a prompt and provide a detailed response.1,2 Users can simply feed in their queries, and the chatbot will reply to them. Unlike other AI chatbots, ChatGPT can answer follow-up questions, admit their mistakes, challenge incorrect premises, and reject inappropriate requests. As an example, Figure 1 shows text that was generated within three seconds when ChatGPT was instructed to ‘write a letter to the editor about artificial intelligence in dentistry in 300 words’. ChatGPT was launched on 30 November 2022, by San Francisco-based OpenAI. It was co-founded by its current CEO, Sam Altman, and Elon Musk in 2015 and is presently funded by Microsoft and others. By 4 December 2022, OpenAI estimated ChatGPT already had over one million users. At its core, ChatGPT is a large language model and is an AI-powered conversational chatbot, which uses algorithms to analyse a massive corpus of text, often scraped from the internet, to respond to user requests in language that can sound surprisingly human.3 It is not free from errors or limitations. On its website, OpenAI admits that ChatGPT sometimes writes plausiblesounding but incorrect or nonsensical answers.4 While there is immense scope for AI in dentistry, academic and scientific journals will have serious issues to confront, as soon they will also need AI to detect whether the text was generated by AI or human intelligence.5 N. Kurian, J. M. Cherian, N. A. Sudharson, K. G. Varghese, S. Wadhwa, Ludhiana, India  	4	APPLICATION	WRITING	Mixed			
Annotator2	Cellular and Molecular Bioengineering	[{'authorId': '152378504', 'name': 'Michael R King'}, {'authorId': '2196932745', 'name': 'chatGPT'}]	A Conversation on Artificial Intelligence, Chatbots, and Plagiarism in Higher Education	The history of AI and chatbots can be traced back to the 1950s when scientists first began exploring the concept of artificial intelligence. Early developments included the creation of the first AI program called ELIZA, which was designed to mimic human conversation. In the decades that followed, AI technology continued to advance, leading to the development of more sophisticated chatbots with the ability to understand and respond to complex requests. Today, AI and chatbots are used in a wide range of industries, from customer service to healthcare, and are continuing to evolve as technology advances.  	0	REST		NAN			
Annotator2	ChemViews	[{'authorId': '2075937681', 'name': 'Vera Koester'}, {'authorId': '12374747', 'name': 'Catharina Goedecke'}]	Chatting With ChatGPT	Everyone is talking about it and trying it out right now, so we also experimented with ChatGPT and asked questions about science communication, AI in chemistry, publication ethics, and the purpose of life. It’s great fun, the answers almost always come up lightning fast … see for yourself what came out of this experiment.	4	APPLICATION	WRITING	Opportunity			
Annotator2	Cureus	[{'authorId': None, 'name': 'Haris M Akhter'}, {'authorId': '47511413', 'name': 'J. Cooper'}]	Acute Pulmonary Edema After Hyperbaric Oxygen Treatment: A Case Report Written With ChatGPT Assistance	Acute pulmonary edema is a rare but severe complication of hyperbaric oxygen therapy. While patients with known cardiovascular problems may be able to withstand this therapy, rapid decompensation can still occur. Here, we present a case of a patient with known low ejection fraction and severe mitral regurgitation who developed acute pulmonary edema during the first hyperbaric treatment for a foot ulcer. This case highlights the importance of identifying patients that are high risk, such as those with moderate-to-severe cardiac disease, and pursuing other treatment options to avoid this complication.  	0	REST		NAN			
Annotator2	Education in the Knowledge Society (EKS)	[{'authorId': None, 'name': 'Francisco JosÃ© GarcÃ­a-PeÃ±alvo'}]	La percepciÃ³n de la Inteligencia Artificial en contextos educativos tras el lanzamiento de ChatGPT: disrupciÃ³n o pÃ¡nico	The year 2022 has ended with one of those technological innovations that  have a hard-to-predict behaviour, a black swan, hogging the limelight  in traditional media and digital media. Indeed, it is ChatGPT. Although  artificial intelligence had already been in the news and often masked  under various other meanings, the ChatGPT phenomenon has once again  brought this discipline and its positive and negative effects on our  society to the forefront. Reactions to its launch, influenced mainly by  its ease of access and use, have been varied, ranging from the  enthusiasm of innovators and early adopters to the almost apocalyptic  terror of the Terminator movie. Of the multiple applications of this  tool, the most significant debate focuses on its implications in  Education and Academia due to its tremendous power to generate texts  that could very well pass for human creations. We are at the dawn of a  technology that has gone from being a toy tool to bidding to become a  disruptive innovation. Whether it succeeds or not will depend on many  factors, but if it does not, it will be another one like it. Denying it  or banning it will do absolutely nothing to stop the tsunami effect that  has already begun. For all these reasons, we must first understand  these technologies based on large language models and know their  benefits and weaknesses, as well as what they really mean for a specific  sector of activity, such as Education. After getting to know the  technology and the tool, one would be in a position to use (or not) its  potential and to prevent or detect its possible pernicious effects,  presumably by changing and adapting processes that are probably  profoundly rooted and that, therefore, forced to leave the comfort zone,  which is always the cause of resistance to change and extreme  reactions. These responses usually will not stop technology from  reaching its productivity plateau when it becomes part of the daily life  of a sufficient majority of users. This is always the cause of  resistance to change and extreme reactions that will not usually stop  technology from reaching its productivity plateau when it becomes part  of the daily lives of a sufficient majority of users, especially when it  is also a question of transversal tools that will spread their usage  patterns among the different application domains.	4	EDUCATION		Mixed			
Annotator2	medRxiv	[{'authorId': '2051250388', 'name': 'T. Kung'}, {'authorId': '2045482362', 'name': 'M. Cheatham'}, {'authorId': '2196935808', 'name': 'A. Medinilla'}, {'authorId': '2196932745', 'name': 'chatGPT'}, {'authorId': '2196932743', 'name': 'C. Sillos'}, {'authorId': '2194457777', 'name': 'L. D. De Leon'}, {'authorId': '2196937260', 'name': 'C. Elepano'}, {'authorId': '2101601654', 'name': 'M. Madriaga'}, {'authorId': '117973505', 'name': 'R. Aggabao'}, {'authorId': '2196935806', 'name': 'G. Diaz-Candido'}, {'authorId': '7262505', 'name': 'J. Maningo'}, {'authorId': '2196932802', 'name': 'V. Tseng'}]	Performance of ChatGPT on USMLE: Potential for AI-Assisted Medical Education Using Large Language Models	We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, even clinical decision-making.	5	MEDICAL	EDUCATION	Opportunity	Yes		
Annotator2	medRxiv	[{'authorId': '2107029904', 'name': 'A. Gilson'}, {'authorId': '40902199', 'name': 'C. Safranek'}, {'authorId': '2181652492', 'name': 'T. Huang'}, {'authorId': '11035690', 'name': 'V. Socrates'}, {'authorId': '2087060121', 'name': 'L. Chi'}, {'authorId': '143794498', 'name': 'R. A. Taylor'}, {'authorId': '3181480', 'name': 'David Chartash'}]	How Well Does ChatGPT Do When Taking the Medical Licensing Exams? The Implications of Large Language Models for Medical Education and Knowledge Assessment	Background: ChatGPT is a 175 billion parameter natural language processing model which can generate conversation style responses to user input. Objective: To evaluate the performance of ChatGPT on questions within the scope of United States Medical Licensing Examination (USMLE) Step 1 and Step 2 exams, as well as analyze responses for user interpretability. Methods: We used two novel sets of multiple choice questions to evaluate ChatGPT's performance, each with questions pertaining to Step 1 and Step 2. The first was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the userbase. The second, was the National Board of Medical Examiners (NBME) Free 120-question exams. After prompting ChatGPT with each question, ChatGPT's selected answer was recorded, and the text output evaluated across three qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question. Results: On the four datasets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBME-Free- Step2, ChatGPT achieved accuracies of 44%, 42%, 64.4%, and 57.8%. The model demonstrated a significant decrease in performance as question difficulty increased (P=.012) within the AMBOSS- Step1 dataset. We found logical justification for ChatGPT's answer selection was present in 100% of outputs. Internal information to the question was present in >90% of all questions. The presence of information external to the question was respectively 54.5% and 27% lower for incorrect relative to correct answers on the NBME-Free-Step1 and NBME-Free-Step2 datasets (P<=.001). Conclusion: ChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at greater than 60% threshold on the NBME-Free- Step-1 dataset we show that the model is comparable to a third year medical student. Additionally, due to the dialogic nature of the response to questions, we demonstrate ChatGPT's ability to provide reasoning and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as a medical education tool.	4	MEDICAL	EDUCATION	Opportunity	Yes		
Annotator2	medRxiv	[{'authorId': '103525980', 'name': 'J. Kim'}]	Search for Medical Information and Treatment Options for Musculoskeletal Disorders through an Artificial Intelligence Chatbot: Focusing on Shoulder Impingement Syndrome	Background: The ChatGPT is an artificial intelligence chatbot that processes natural language text learned through reinforcement learning based on the GPT-3.5 architecture, a large-scale language model. Natural language processing models are being used in various fields and are gradually expanding their use in the medical field. Purpose: This study aimed to investigate the medical information or treatment options that ChatGPT can provide for SIS. Method: Using ChatGPT, which is provided as a free beta test, messages related to SIS were entered, and responses to medical information and treatment options were received and analyzed. Result: ChatGPT not only provided answers to the definition, prevalence, and risk factors of SIS, but also symptoms, diseases with similar symptoms, and orthopedic tests according to the messages input. Additionally, a list of treatment options and exercises were provided. Conclusion: ChatGPT will be able to provide overall useful medical information and treatment options to patients unfamiliar with SIS. However, caution is required as it contains content that may be biased or inappropriate information for patients with SIS. Nevertheless, if natural language processing technology develops further, it is expected to be able to express more detailed medical information and treatment options.	4	MEDICAL	DIAGNOSIS/DIALOGUE	Opportunity	Yes		
Annotator2	Mesopotamian Journal of Cyber Security	[{'authorId': '1447250772', 'name': 'Mohammad Aljanabi'}, {'authorId': '2196932745', 'name': 'chatGPT'}]	ChatGPT: Future Directions and Open possibilities	ChatGPT, the cutting-edge language model developed by OpenAI, is one of the most exciting advancements in the field of artificial intelligence. With its ability to generate human-like text and respond to complex questions, ChatGPT has already made a significant impact and is poised to continue its rapid progression in the coming years. As we look to the future of ChatGPT and large language models, there are many exciting possibilities and open opportunities for this technology to enhance our lives and change the way we interact with technology	5	ETHICS	SECURITY	Opportunity	Yes		
Annotator2	Nature	[{'authorId': '82335473', 'name': 'Flora Graham'}]	Daily briefing: Will ChatGPT kill the essay assignment?		0	EDUCATION		NAN	No		
Annotator2	Nature	[{'authorId': '1413934873', 'name': 'Chris Stokel-Walker'}]	ChatGPT listed as author on research papers: many scientists disapprove		0	ETHICS		NAN	No		
Annotator2	Science	[{'authorId': '2003404994', 'name': 'H. Thorp'}]	ChatGPT is fun, but not an author	In less than 2 months, the artificial intelligence (AI) program ChatGPT has become a cultural sensation. It is freely accessible through a web portal created by the toolâ€™s developer, OpenAI. The programâ€”which automatically creates text based on written promptsâ€”is so popular that itâ€™s likely to be â€œat capacity right nowâ€ if you attempt to use it. When you do get through, ChatGPT provides endless entertainment. I asked it to rewrite the first scene of the classic American play Death of a Salesman, but to feature Princess Elsa from the animated movie Frozen as the main character instead of Willy Loman. The output was an amusing conversation in which Elsaâ€”who has come home from a tough day of sellingâ€”is told by her son Happy, â€œCome on, Mom. Youâ€™re Elsa from Frozen. You have ice powers and youâ€™re a queen. Youâ€™re unstoppable.â€ Mash-ups like this are certainly fun, but there are serious implications for generative AI programs like ChatGPT in science and academia.	4	APPLICATION	WRITING	Threat	No		
Annotator2	Seeds of Science	[{'authorId': '2073872541', 'name': 'S. Buck'}]	Why Proposal Review Should Be More Like Meteorology	The process of evaluating research proposals for funding is often based on subjective assessments of the "goodness" or "badness" of a proposal. However, this method of evaluation is not precise and does not provide a common language for reviewers to communicate with each other. In this paper, we propose that science funding agencies ask reviewers to assign quantitative probabilities to the likelihood of a proposal reaching a particular milestone or achieving technical goals. This approach would encourage reviewers to be more precise in their evaluations and could improve both agency-wide and individual reviewer calibration over time. Additionally, this method would allow funding agencies to identify skilled reviewers and allow reviewers to improve their own performance through consistent feedback. While this method may not be suitable for all types of research, it has the potential to enhance proposal review in a variety of fields. [abstract generated by ChatGPT]	0	REST		NAN	Yes		
Annotator2	SSRN Electronic Journal	[{'authorId': '46308962', 'name': 'Jonathan H. Choi'}, {'authorId': '98900189', 'name': 'Kristin E. Hickman'}, {'authorId': '16166682', 'name': 'Amy B. Monahan'}, {'authorId': '83686718', 'name': 'D. Schwarcz'}]	ChatGPT Goes to Law School	How well can AI models write law school exams without human assistance? To find out, we used  the widely publicized AI model ChatGPT to generate answers on four real exams at the University  of Minnesota Law School. We then blindly graded these exams as part of our regular grading processes  for each class. Over 95 multiple choice questions and 12 essay questions, ChatGPT performed on average  at the level of a C+ student, achieving a low but passing grade in all four courses. After detailing these results,  we discuss their implications for legal education and lawyering. We also provide example prompts and advice  on how ChatGPT can assist with legal writing.	4	EDUCATION		NAN	Yes		
Annotator2	The Pediatric Infectious Disease Journal	[{'authorId': '143739014', 'name': 'N. Curtis'}]	To ChatGPT or not to ChatGPT? The Impact of Artificial Intelligence on Academic Publishing.		0	MEDICAL	APPLICATION	NAN	No		
Annotator3	Afro-Egyptian Journal of Infectious and Endemic Diseases	[{'authorId': '2204181382', 'name': 'Chris Zielinski'}, {'authorId': '2204229179', 'name': 'Margaret Winker'}, {'authorId': '2204060826', 'name': 'Rakesh Aggarwal'}, {'authorId': '2204139714', 'name': 'Lorraine Ferris'}, {'authorId': '2204088680', 'name': 'Markus Heinemann'}, {'authorId': None, 'name': 'Jose Florencio LapeÃ±a, Jr'}, {'authorId': '2204241478', 'name': 'Sanjay Pai'}, {'authorId': '2204225725', 'name': 'Edsel Ing'}, {'authorId': '2204240490', 'name': 'Leslie Citrome'}]	Chatbots, ChatGPT, and Scholarly Manuscripts WAME Recommendations on ChatGPT and Chatbots in Relation to Scholarly Publications	Journals have begun to publish papers in which chatbots such as ChatGPT are shown as co-authors. The following WAME recommendations are intended to inform editors and help them develop policies regarding chatbots for their journals, to help authors understand how use of chatbots might be attributed in their work, and address the need for all journal editors to have access manuscript screening tools. In this rapidly evolving field, we expect these recommendations to evolve as well.	3	APPLICATION, EDUCATION		Mixed			
Annotator3	Annals of Biomedical Engineering	[{'authorId': '152378504', 'name': 'Michael R King'}]	The Future of AI in Medicine: A Perspective from a Chatbot	Like many other technology users and enthusiasts, I have been captivated by the capabilities of ChatGPT, the new natural language chatbot utility developed by OpenAI and recently released for research testing. Testing ChatGPT and encouraging it to produce both useful, and humorous, responses that are remarkably well-written and human-like prompted me to wonder… have we reached the point in the evolution of technology where an AI-driven chatbot could write, or cowrite, a perspective article on the very topic of the Future of AI in Medicine? How meta! Interestingly, while asked to write a journal cover letter for this manuscript (included at the end), ChatGPT come up with the final article title you see above. Have we reached the age of chatbots as a legitimate voice in scientific publishing? See for yourself…  	5	APPLICATION, EDUCATION		Opportunity			
Annotator3	Arthroscopy: The Journal of Arthroscopy And Related	[{'authorId': '2175437221', 'name': 'James H. Lubowitz'}]	ChatGPT, An Artificial Intelligence Chatbot, Is Impacting Medical Literature	As is evident in a Letter to the Editor from Gilat and Cole, “How Will Artificial Intelligence Affect Scientific Writing, Reviewing and Editing? The Future is Here…”,1 ChatGPT is now impacting the medical literature. As ChatGPT was used to write part of the letter, we can say with certainty that ChatGPT is now published in Arthroscopy. ChatGPT is an artificial intelligence (AI) chatbot tool. In other words, ChatGPT is a machine, a program, a robot, or technically, a large language model trained on enormous amounts of information from the Internet. It is able to respond to user prompts by answering questions; writing essays, poems, love letters, computer code, or business plans; solving problems including math or physics; and more.2,  3,  4 “The bot doesn’t just search and summarize information that already exists. It creates new content, tailored to your request.”5 ChatGPT has been used to write parts of newspaper and magazine articles, testing readers ability to determine whether the writing was by the chatbot or a human,4 so it is no surprise that Editorial Board Member Ron Gilat and Journal Board of Trustees Member and AANA Past President Brian Cole have now used the bot to write part of their letter.1	5	APPLICATION		Opportunity			
Annotator3	bioRxiv	[{'authorId': '2149285611', 'name': 'Catherine A. Gao'}, {'authorId': '1737779229', 'name': 'Frederick M. Howard'}, {'authorId': '1411115878', 'name': 'N. Markov'}, {'authorId': '2186065223', 'name': 'E. Dyer'}, {'authorId': '144972037', 'name': 'S. Ramesh'}, {'authorId': '1683396', 'name': 'Yuan Luo'}, {'authorId': '2198493546', 'name': 'Alexander T. Pearson'}]	Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers	Background Large language models such as ChatGPT can produce increasingly realistic text, with unknown information on the accuracy and integrity of using these models in scientific writing. Methods We gathered ten research abstracts from five high impact factor medical journals (n=50) and asked ChatGPT to generate research abstracts based on their titles and journals. We evaluated the abstracts using an artificial intelligence (AI) output detector, plagiarism detector, and had blinded human reviewers try to distinguish whether abstracts were original or generated. Results All ChatGPT-generated abstracts were written clearly but only 8% correctly followed the specific journalâ€™s formatting requirements. Most generated abstracts were detected using the AI output detector, with scores (higher meaning more likely to be generated) of median [interquartile range] of 99.98% [12.73, 99.98] compared with very low probability of AI-generated output in the original abstracts of 0.02% [0.02, 0.09]. The AUROC of the AI output detector was 0.94. Generated abstracts scored very high on originality using the plagiarism detector (100% [100, 100] originality). Generated abstracts had a similar patient cohort size as original abstracts, though the exact numbers were fabricated. When given a mixture of original and general abstracts, blinded human reviewers correctly identified 68% of generated abstracts as being generated by ChatGPT, but incorrectly identified 14% of original abstracts as being generated. Reviewers indicated that it was surprisingly difficult to differentiate between the two, but that the generated abstracts were vaguer and had a formulaic feel to the writing. Conclusion ChatGPT writes believable scientific abstracts, though with completely generated data. These are original without any plagiarism detected but are often identifiable using an AI output detector and skeptical human reviewers. Abstract evaluation for journals and medical conferences must adapt policy and practice to maintain rigorous scientific standards; we suggest inclusion of AI output detectors in the editorial process and clear disclosure if these technologies are used. The boundaries of ethical and acceptable use of large language models to help scientific writing remain to be determined.	3	MEDICAL, APPLICATION		Mixed			
Annotator3	BMJ	[{'authorId': '1620851794', 'name': 'Mun-Keat Looi'}]	Sixty seconds on . . . ChatGPT	A new dating app for GPs? No, but it could probably do that. ChatGPT1 is the latest artificial intelligence (AI) chatbot to cause a stir. It can respond to queries and requests with prose of surprising quality, almost indistinguishable from that of a human writer. It’s so seemingly authentic and easy to use that academics and medics are both in wonder and worry over how it might shake up the system.  How so? Education is one thing. Some students have already used the bot to generate essays that pass …	4	EDUCATION		Threat			
Annotator3	British Dental Journal	[{'authorId': '51027918', 'name': 'A. Kaushik'}]	HPV training	Sir, the world of technology is buzzing with a new word – ChatGPT, a new artificial intelligence (AI) chatbot which is trained to follow instructions in a prompt and provide a detailed response.1,2 Users can simply feed in their queries, and the chatbot will reply to them. Unlike other AI chatbots, ChatGPT can answer follow-up questions, admit their mistakes, challenge incorrect premises, and reject inappropriate requests. As an example, Figure 1 shows text that was generated within three seconds when ChatGPT was instructed to ‘write a letter to the editor about artificial intelligence in dentistry in 300 words’. ChatGPT was launched on 30 November 2022, by San Francisco-based OpenAI. It was co-founded by its current CEO, Sam Altman, and Elon Musk in 2015 and is presently funded by Microsoft and others. By 4 December 2022, OpenAI estimated ChatGPT already had over one million users. At its core, ChatGPT is a large language model and is an AI-powered conversational chatbot, which uses algorithms to analyse a massive corpus of text, often scraped from the internet, to respond to user requests in language that can sound surprisingly human.3 It is not free from errors or limitations. On its website, OpenAI admits that ChatGPT sometimes writes plausiblesounding but incorrect or nonsensical answers.4 While there is immense scope for AI in dentistry, academic and scientific journals will have serious issues to confront, as soon they will also need AI to detect whether the text was generated by AI or human intelligence.5 N. Kurian, J. M. Cherian, N. A. Sudharson, K. G. Varghese, S. Wadhwa, Ludhiana, India  	3	MEDICAL		Mixed			
Annotator3	Cellular and Molecular Bioengineering	[{'authorId': '152378504', 'name': 'Michael R King'}, {'authorId': '2196932745', 'name': 'chatGPT'}]	A Conversation on Artificial Intelligence, Chatbots, and Plagiarism in Higher Education	The history of AI and chatbots can be traced back to the 1950s when scientists first began exploring the concept of artificial intelligence. Early developments included the creation of the first AI program called ELIZA, which was designed to mimic human conversation. In the decades that followed, AI technology continued to advance, leading to the development of more sophisticated chatbots with the ability to understand and respond to complex requests. Today, AI and chatbots are used in a wide range of industries, from customer service to healthcare, and are continuing to evolve as technology advances.  	4	EDUCATION		Threat			
Annotator3	ChemViews	[{'authorId': '2075937681', 'name': 'Vera Koester'}, {'authorId': '12374747', 'name': 'Catharina Goedecke'}]	Chatting With ChatGPT	Everyone is talking about it and trying it out right now, so we also experimented with ChatGPT and asked questions about science communication, AI in chemistry, publication ethics, and the purpose of life. It’s great fun, the answers almost always come up lightning fast … see for yourself what came out of this experiment.	5	APPLICATION		Opportunity			
Annotator3	Cureus	[{'authorId': None, 'name': 'Haris M Akhter'}, {'authorId': '47511413', 'name': 'J. Cooper'}]	Acute Pulmonary Edema After Hyperbaric Oxygen Treatment: A Case Report Written With ChatGPT Assistance	Acute pulmonary edema is a rare but severe complication of hyperbaric oxygen therapy. While patients with known cardiovascular problems may be able to withstand this therapy, rapid decompensation can still occur. Here, we present a case of a patient with known low ejection fraction and severe mitral regurgitation who developed acute pulmonary edema during the first hyperbaric treatment for a foot ulcer. This case highlights the importance of identifying patients that are high risk, such as those with moderate-to-severe cardiac disease, and pursuing other treatment options to avoid this complication.  	3	MEDICAL		Opportunity			
Annotator3	Education in the Knowledge Society (EKS)	[{'authorId': None, 'name': 'Francisco JosÃ© GarcÃ­a-PeÃ±alvo'}]	La percepciÃ³n de la Inteligencia Artificial en contextos educativos tras el lanzamiento de ChatGPT: disrupciÃ³n o pÃ¡nico	"The year 2022 has ended with one of those technological innovations that  have a hard-to-predict behaviour, a black swan, hogging the limelight  in traditional media and digital media. Indeed, it is ChatGPT. Although  artificial intelligence had already been in the news and often masked  under various other meanings, the ChatGPT phenomenon has once again  brought this discipline and its positive and negative effects on our  society to the forefront. Reactions to its launch, influenced mainly by  its ease of access and use, have been varied, ranging from the  enthusiasm of innovators and early adopters to the almost apocalyptic  terror of the Terminator movie. Of the multiple applications of this  tool, the most significant debate focuses on its implications in  Education and Academia due to its tremendous power to generate texts  that could very well pass for human creations. We are at the dawn of a  technology that has gone from being a toy tool to bidding to become a  disruptive innovation. Whether it succeeds or not will depend on many  factors, but if it does not, it will be another one like it. Denying it  or banning it will do absolutely nothing to stop the tsunami effect that  has already begun. For all these reasons, we must first understand  these technologies based on large language models and know their  benefits and weaknesses, as well as what they really mean for a specific  sector of activity, such as Education. After getting to know the  technology and the tool, one would be in a position to use (or not) its  potential and to prevent or detect its possible pernicious effects,  presumably by changing and adapting processes that are probably  profoundly rooted and that, therefore, forced to leave the comfort zone,  which is always the cause of resistance to change and extreme  reactions. These responses usually will not stop technology from  reaching its productivity plateau when it becomes part of the daily life  of a sufficient majority of users. This is always the cause of  resistance to change and extreme reactions that will not usually stop  technology from reaching its productivity plateau when it becomes part  of the daily lives of a sufficient majority of users, especially when it  is also a question of transversal tools that will spread their usage  patterns among the different application domains."	4	ETHICS, EDUCATION		Opportunity			
Annotator3	medRxiv	[{'authorId': '2051250388', 'name': 'T. Kung'}, {'authorId': '2045482362', 'name': 'M. Cheatham'}, {'authorId': '2196935808', 'name': 'A. Medinilla'}, {'authorId': '2196932745', 'name': 'chatGPT'}, {'authorId': '2196932743', 'name': 'C. Sillos'}, {'authorId': '2194457777', 'name': 'L. D. De Leon'}, {'authorId': '2196937260', 'name': 'C. Elepano'}, {'authorId': '2101601654', 'name': 'M. Madriaga'}, {'authorId': '117973505', 'name': 'R. Aggabao'}, {'authorId': '2196935806', 'name': 'G. Diaz-Candido'}, {'authorId': '7262505', 'name': 'J. Maningo'}, {'authorId': '2196932802', 'name': 'V. Tseng'}]	Performance of ChatGPT on USMLE: Potential for AI-Assisted Medical Education Using Large Language Models	We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, even clinical decision-making.	4	Medical		Opportunity	TRUE		
Annotator3	medRxiv	[{'authorId': '2107029904', 'name': 'A. Gilson'}, {'authorId': '40902199', 'name': 'C. Safranek'}, {'authorId': '2181652492', 'name': 'T. Huang'}, {'authorId': '11035690', 'name': 'V. Socrates'}, {'authorId': '2087060121', 'name': 'L. Chi'}, {'authorId': '143794498', 'name': 'R. A. Taylor'}, {'authorId': '3181480', 'name': 'David Chartash'}]	How Well Does ChatGPT Do When Taking the Medical Licensing Exams? The Implications of Large Language Models for Medical Education and Knowledge Assessment	Background: ChatGPT is a 175 billion parameter natural language processing model which can generate conversation style responses to user input. Objective: To evaluate the performance of ChatGPT on questions within the scope of United States Medical Licensing Examination (USMLE) Step 1 and Step 2 exams, as well as analyze responses for user interpretability. Methods: We used two novel sets of multiple choice questions to evaluate ChatGPT's performance, each with questions pertaining to Step 1 and Step 2. The first was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the userbase. The second, was the National Board of Medical Examiners (NBME) Free 120-question exams. After prompting ChatGPT with each question, ChatGPT's selected answer was recorded, and the text output evaluated across three qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question. Results: On the four datasets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBME-Free- Step2, ChatGPT achieved accuracies of 44%, 42%, 64.4%, and 57.8%. The model demonstrated a significant decrease in performance as question difficulty increased (P=.012) within the AMBOSS- Step1 dataset. We found logical justification for ChatGPT's answer selection was present in 100% of outputs. Internal information to the question was present in >90% of all questions. The presence of information external to the question was respectively 54.5% and 27% lower for incorrect relative to correct answers on the NBME-Free-Step1 and NBME-Free-Step2 datasets (P<=.001). Conclusion: ChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at greater than 60% threshold on the NBME-Free- Step-1 dataset we show that the model is comparable to a third year medical student. Additionally, due to the dialogic nature of the response to questions, we demonstrate ChatGPT's ability to provide reasoning and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as a medical education tool.	4	Medical	Education	Opportunity	TRUE		
Annotator3	medRxiv	[{'authorId': '103525980', 'name': 'J. Kim'}]	Search for Medical Information and Treatment Options for Musculoskeletal Disorders through an Artificial Intelligence Chatbot: Focusing on Shoulder Impingement Syndrome	Background: The ChatGPT is an artificial intelligence chatbot that processes natural language text learned through reinforcement learning based on the GPT-3.5 architecture, a large-scale language model. Natural language processing models are being used in various fields and are gradually expanding their use in the medical field. Purpose: This study aimed to investigate the medical information or treatment options that ChatGPT can provide for SIS. Method: Using ChatGPT, which is provided as a free beta test, messages related to SIS were entered, and responses to medical information and treatment options were received and analyzed. Result: ChatGPT not only provided answers to the definition, prevalence, and risk factors of SIS, but also symptoms, diseases with similar symptoms, and orthopedic tests according to the messages input. Additionally, a list of treatment options and exercises were provided. Conclusion: ChatGPT will be able to provide overall useful medical information and treatment options to patients unfamiliar with SIS. However, caution is required as it contains content that may be biased or inappropriate information for patients with SIS. Nevertheless, if natural language processing technology develops further, it is expected to be able to express more detailed medical information and treatment options.	4	Medical		Opportunity	TRUE		
Annotator3	Mesopotamian Journal of Cyber Security	[{'authorId': '1447250772', 'name': 'Mohammad Aljanabi'}, {'authorId': '2196932745', 'name': 'chatGPT'}]	ChatGPT: Future Directions and Open possibilities	ChatGPT, the cutting-edge language model developed by OpenAI, is one of the most exciting advancements in the field of artificial intelligence. With its ability to generate human-like text and respond to complex questions, ChatGPT has already made a significant impact and is poised to continue its rapid progression in the coming years. As we look to the future of ChatGPT and large language models, there are many exciting possibilities and open opportunities for this technology to enhance our lives and change the way we interact with technology	5	Rest		Opportunity	FALSE		
Annotator3	Nature	[{'authorId': '82335473', 'name': 'Flora Graham'}]	Daily briefing: Will ChatGPT kill the essay assignment?		0	Education		Threat	NaN		
Annotator3	Nature	[{'authorId': '1413934873', 'name': 'Chris Stokel-Walker'}]	ChatGPT listed as author on research papers: many scientists disapprove		0	Ethics		NaN	NaN		
Annotator3	Science	[{'authorId': '2003404994', 'name': 'H. Thorp'}]	ChatGPT is fun, but not an author	In less than 2 months, the artificial intelligence (AI) program ChatGPT has become a cultural sensation. It is freely accessible through a web portal created by the toolâ€™s developer, OpenAI. The programâ€”which automatically creates text based on written promptsâ€”is so popular that itâ€™s likely to be â€œat capacity right nowâ€ if you attempt to use it. When you do get through, ChatGPT provides endless entertainment. I asked it to rewrite the first scene of the classic American play Death of a Salesman, but to feature Princess Elsa from the animated movie Frozen as the main character instead of Willy Loman. The output was an amusing conversation in which Elsaâ€”who has come home from a tough day of sellingâ€”is told by her son Happy, â€œCome on, Mom. Youâ€™re Elsa from Frozen. You have ice powers and youâ€™re a queen. Youâ€™re unstoppable.â€ Mash-ups like this are certainly fun, but there are serious implications for generative AI programs like ChatGPT in science and academia.	5	Evaluation		Threat	FALSE		
Annotator3	Seeds of Science	[{'authorId': '2073872541', 'name': 'S. Buck'}]	Why Proposal Review Should Be More Like Meteorology	The process of evaluating research proposals for funding is often based on subjective assessments of the "goodness" or "badness" of a proposal. However, this method of evaluation is not precise and does not provide a common language for reviewers to communicate with each other. In this paper, we propose that science funding agencies ask reviewers to assign quantitative probabilities to the likelihood of a proposal reaching a particular milestone or achieving technical goals. This approach would encourage reviewers to be more precise in their evaluations and could improve both agency-wide and individual reviewer calibration over time. Additionally, this method would allow funding agencies to identify skilled reviewers and allow reviewers to improve their own performance through consistent feedback. While this method may not be suitable for all types of research, it has the potential to enhance proposal review in a variety of fields. [abstract generated by ChatGPT]	0	Application	Writing	NaN	TRUE		
Annotator3	SSRN Electronic Journal	[{'authorId': '46308962', 'name': 'Jonathan H. Choi'}, {'authorId': '98900189', 'name': 'Kristin E. Hickman'}, {'authorId': '16166682', 'name': 'Amy B. Monahan'}, {'authorId': '83686718', 'name': 'D. Schwarcz'}]	ChatGPT Goes to Law School	How well can AI models write law school exams without human assistance? To find out, we used the widely publicized AI model ChatGPT to generate answers on four real exams at the University of Minnesota Law School. We then blindly graded these exams as part of our regular grading processes for each class. Over 95 multiple choice questions and 12 essay questions, ChatGPT performed on average at the level of a C+ student, achieving a low but passing grade in all four courses. After detailing these results, we discuss their implications for legal education and lawyering. We also provide example prompts and advice on how ChatGPT can assist with legal writing.	4	Education	Application	Opportunity	WAHR		
Annotator3	The Pediatric Infectious Disease Journal	[{'authorId': '143739014', 'name': 'N. Curtis'}]	To ChatGPT or not to ChatGPT? The Impact of Artificial Intelligence on Academic Publishing.		0	Ethics		NaN	NaN		
Annotator4	Afro-Egyptian Journal of Infectious and Endemic Diseases	[{'authorId': '2204181382', 'name': 'Chris Zielinski'}, {'authorId': '2204229179', 'name': 'Margaret Winker'}, {'authorId': '2204060826', 'name': 'Rakesh Aggarwal'}, {'authorId': '2204139714', 'name': 'Lorraine Ferris'}, {'authorId': '2204088680', 'name': 'Markus Heinemann'}, {'authorId': None, 'name': 'Jose Florencio LapeÃ±a, Jr'}, {'authorId': '2204241478', 'name': 'Sanjay Pai'}, {'authorId': '2204225725', 'name': 'Edsel Ing'}, {'authorId': '2204240490', 'name': 'Leslie Citrome'}]	Chatbots, ChatGPT, and Scholarly Manuscripts WAME Recommendations on ChatGPT and Chatbots in Relation to Scholarly Publications	Journals have begun to publish papers in which chatbots such as ChatGPT are shown as co-authors. The following WAME recommendations are intended to inform editors and help them develop policies regarding chatbots for their journals, to help authors understand how use of chatbots might be attributed in their work, and address the need for all journal editors to have access manuscript screening tools. In this rapidly evolving field, we expect these recommendations to evolve as well.	2	APPLICATION	Threat				
Annotator4	Annals of Biomedical Engineering	[{'authorId': '152378504', 'name': 'Michael R King'}]	The Future of AI in Medicine: A Perspective from a Chatbot	Like many other technology users and enthusiasts, I have been captivated by the capabilities of ChatGPT, the new natural language chatbot utility developed by OpenAI and recently released for research testing. Testing ChatGPT and encouraging it to produce both useful, and humorous, responses that are remarkably well-written and human-like prompted me to wonder… have we reached the point in the evolution of technology where an AI-driven chatbot could write, or cowrite, a perspective article on the very topic of the Future of AI in Medicine? How meta! Interestingly, while asked to write a journal cover letter for this manuscript (included at the end), ChatGPT come up with the final article title you see above. Have we reached the age of chatbots as a legitimate voice in scientific publishing? See for yourself…  	4	MEDICAL	Opportunity				
Annotator4	Arthroscopy: The Journal of Arthroscopy And Related	[{'authorId': '2175437221', 'name': 'James H. Lubowitz'}]	ChatGPT, An Artificial Intelligence Chatbot, Is Impacting Medical Literature	As is evident in a Letter to the Editor from Gilat and Cole, “How Will Artificial Intelligence Affect Scientific Writing, Reviewing and Editing? The Future is Here…”,1 ChatGPT is now impacting the medical literature. As ChatGPT was used to write part of the letter, we can say with certainty that ChatGPT is now published in Arthroscopy. ChatGPT is an artificial intelligence (AI) chatbot tool. In other words, ChatGPT is a machine, a program, a robot, or technically, a large language model trained on enormous amounts of information from the Internet. It is able to respond to user prompts by answering questions; writing essays, poems, love letters, computer code, or business plans; solving problems including math or physics; and more.2,  3,  4 “The bot doesn’t just search and summarize information that already exists. It creates new content, tailored to your request.”5 ChatGPT has been used to write parts of newspaper and magazine articles, testing readers ability to determine whether the writing was by the chatbot or a human,4 so it is no surprise that Editorial Board Member Ron Gilat and Journal Board of Trustees Member and AANA Past President Brian Cole have now used the bot to write part of their letter.1	3	MEDICAL	Threat				
Annotator4	bioRxiv	[{'authorId': '2149285611', 'name': 'Catherine A. Gao'}, {'authorId': '1737779229', 'name': 'Frederick M. Howard'}, {'authorId': '1411115878', 'name': 'N. Markov'}, {'authorId': '2186065223', 'name': 'E. Dyer'}, {'authorId': '144972037', 'name': 'S. Ramesh'}, {'authorId': '1683396', 'name': 'Yuan Luo'}, {'authorId': '2198493546', 'name': 'Alexander T. Pearson'}]	Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers	Background Large language models such as ChatGPT can produce increasingly realistic text, with unknown information on the accuracy and integrity of using these models in scientific writing. Methods We gathered ten research abstracts from five high impact factor medical journals (n=50) and asked ChatGPT to generate research abstracts based on their titles and journals. We evaluated the abstracts using an artificial intelligence (AI) output detector, plagiarism detector, and had blinded human reviewers try to distinguish whether abstracts were original or generated. Results All ChatGPT-generated abstracts were written clearly but only 8% correctly followed the specific journalâ€™s formatting requirements. Most generated abstracts were detected using the AI output detector, with scores (higher meaning more likely to be generated) of median [interquartile range] of 99.98% [12.73, 99.98] compared with very low probability of AI-generated output in the original abstracts of 0.02% [0.02, 0.09]. The AUROC of the AI output detector was 0.94. Generated abstracts scored very high on originality using the plagiarism detector (100% [100, 100] originality). Generated abstracts had a similar patient cohort size as original abstracts, though the exact numbers were fabricated. When given a mixture of original and general abstracts, blinded human reviewers correctly identified 68% of generated abstracts as being generated by ChatGPT, but incorrectly identified 14% of original abstracts as being generated. Reviewers indicated that it was surprisingly difficult to differentiate between the two, but that the generated abstracts were vaguer and had a formulaic feel to the writing. Conclusion ChatGPT writes believable scientific abstracts, though with completely generated data. These are original without any plagiarism detected but are often identifiable using an AI output detector and skeptical human reviewers. Abstract evaluation for journals and medical conferences must adapt policy and practice to maintain rigorous scientific standards; we suggest inclusion of AI output detectors in the editorial process and clear disclosure if these technologies are used. The boundaries of ethical and acceptable use of large language models to help scientific writing remain to be determined.	2	MEDICAL	Mixed				
Annotator4	BMJ	[{'authorId': '1620851794', 'name': 'Mun-Keat Looi'}]	Sixty seconds on . . . ChatGPT	A new dating app for GPs? No, but it could probably do that. ChatGPT1 is the latest artificial intelligence (AI) chatbot to cause a stir. It can respond to queries and requests with prose of surprising quality, almost indistinguishable from that of a human writer. It’s so seemingly authentic and easy to use that academics and medics are both in wonder and worry over how it might shake up the system.  How so? Education is one thing. Some students have already used the bot to generate essays that pass …	2	MEDICAL	Mixed				
Annotator4	British Dental Journal	N. Kurian, J. M. Cherian, N. A. Sudharson, K. G. Varghese, S. Wadhwa	AI is now everywhere	Sir, the world of technology is buzzing with a new word – ChatGPT, a new artificial intelligence (AI) chatbot which is trained to follow instructions in a prompt and provide a detailed response.1,2 Users can simply feed in their queries, and the chatbot will reply to them. Unlike other AI chatbots, ChatGPT can answer follow-up questions, admit their mistakes, challenge incorrect premises, and reject inappropriate requests. As an example, Figure 1 shows text that was generated within three seconds when ChatGPT was instructed to ‘write a letter to the editor about artificial intelligence in dentistry in 300 words’. ChatGPT was launched on 30 November 2022, by San Francisco-based OpenAI. It was co-founded by its current CEO, Sam Altman, and Elon Musk in 2015 and is presently funded by Microsoft and others. By 4 December 2022, OpenAI estimated ChatGPT already had over one million users. At its core, ChatGPT is a large language model and is an AI-powered conversational chatbot, which uses algorithms to analyse a massive corpus of text, often scraped from the internet, to respond to user requests in language that can sound surprisingly human.3 It is not free from errors or limitations. On its website, OpenAI admits that ChatGPT sometimes writes plausiblesounding but incorrect or nonsensical answers.4 While there is immense scope for AI in dentistry, academic and scientific journals will have serious issues to confront, as soon they will also need AI to detect whether the text was generated by AI or human intelligence.5 N. Kurian, J. M. Cherian, N. A. Sudharson, K. G. Varghese, S. Wadhwa, Ludhiana, India  	4	MEDICAL	MIxed				
Annotator4	Cellular and Molecular Bioengineering	[{'authorId': '152378504', 'name': 'Michael R King'}, {'authorId': '2196932745', 'name': 'chatGPT'}]	A Conversation on Artificial Intelligence, Chatbots, and Plagiarism in Higher Education	The history of AI and chatbots can be traced back to the 1950s when scientists first began exploring the concept of artificial intelligence. Early developments included the creation of the first AI program called ELIZA, which was designed to mimic human conversation. In the decades that followed, AI technology continued to advance, leading to the development of more sophisticated chatbots with the ability to understand and respond to complex requests. Today, AI and chatbots are used in a wide range of industries, from customer service to healthcare, and are continuing to evolve as technology advances.  	0	EDUCATION	MIxed				
Annotator4	ChemViews	[{'authorId': '2075937681', 'name': 'Vera Koester'}, {'authorId': '12374747', 'name': 'Catharina Goedecke'}]	Chatting With ChatGPT	Everyone is talking about it and trying it out right now, so we also experimented with ChatGPT and asked questions about science communication, AI in chemistry, publication ethics, and the purpose of life. It’s great fun, the answers almost always come up lightning fast … see for yourself what came out of this experiment.	0	APPLICATION	NAN				
Annotator4	Cureus	[{'authorId': None, 'name': 'Haris M Akhter'}, {'authorId': '47511413', 'name': 'J. Cooper'}]	Acute Pulmonary Edema After Hyperbaric Oxygen Treatment: A Case Report Written With ChatGPT Assistance	Acute pulmonary edema is a rare but severe complication of hyperbaric oxygen therapy. While patients with known cardiovascular problems may be able to withstand this therapy, rapid decompensation can still occur. Here, we present a case of a patient with known low ejection fraction and severe mitral regurgitation who developed acute pulmonary edema during the first hyperbaric treatment for a foot ulcer. This case highlights the importance of identifying patients that are high risk, such as those with moderate-to-severe cardiac disease, and pursuing other treatment options to avoid this complication. 	4	MEDICAL	Opportunity				
Annotator4	Education in the Knowledge Society (EKS)	[{'authorId': None, 'name': 'Francisco JosÃ© GarcÃ­a-PeÃ±alvo'}]	La percepciÃ³n de la Inteligencia Artificial en contextos educativos tras el lanzamiento de ChatGPT: disrupciÃ³n o pÃ¡nico	The year 2022 has ended with one of those technological innovations that have a hard-to-predict behaviour, a black swan, hogging the limelight in traditional media and digital media. Indeed, it is ChatGPT. Although artificial intelligence had already been in the news and often masked under various other meanings, the ChatGPT phenomenon has once again brought this discipline and its positive and negative effects on our society to the forefront. Reactions to its launch, influenced mainly by its ease of access and use, have been varied, ranging from the enthusiasm of innova-tors and early adopters to the almost apocalyptic terror of the Terminator movie. Of the multiple applications of this tool, the most significant debate focuses on its implications in Education and Academia due to its tremendous power to generate texts that could very well pass for human creations. We are at the dawn of a technology that has gone from being a toy tool to bidding to become a disruptive innovation. Whether it succeeds or not will depend on many factors, but if it does not, it will be another one like it. Denying it or banning it will do absolutely nothing to stop the tsunami effect that has already begun. For all these reasons, we must first understand these technologies based on large language models and know their benefits and weaknesses, as well as what they really mean for a specific sector of activity, such as Education. After getting to know the technology and the tool, one would be in a position to use (or not) its potential and to prevent or detect its possible pernicious effects, presumably by changing and adapting processes that are probably profoundly rooted and that, therefore, forced to leave the comfort zone, which is always the cause of resistance to change and extreme reactions. These responses usually will not stop technology from reaching its productivity plateau when it becomes part of the daily life of a suffi-cient majority of users. This is always the cause of resistance to change and extreme reactions that will not usually stop technology from reaching its productivity plateau when it becomes part of the daily lives of a sufficient majority of users, especially when it is also a question of transversal tools that will spread their usage patterns among the different application domains.	0	EDUCATION	MIxed				
Annotator4	medRxiv	[{'authorId': '2051250388', 'name': 'T. Kung'}, {'authorId': '2045482362', 'name': 'M. Cheatham'}, {'authorId': '2196935808', 'name': 'A. Medinilla'}, {'authorId': '2196932745', 'name': 'chatGPT'}, {'authorId': '2196932743', 'name': 'C. Sillos'}, {'authorId': '2194457777', 'name': 'L. D. De Leon'}, {'authorId': '2196937260', 'name': 'C. Elepano'}, {'authorId': '2101601654', 'name': 'M. Madriaga'}, {'authorId': '117973505', 'name': 'R. Aggabao'}, {'authorId': '2196935806', 'name': 'G. Diaz-Candido'}, {'authorId': '7262505', 'name': 'J. Maningo'}, {'authorId': '2196932802', 'name': 'V. Tseng'}]	Performance of ChatGPT on USMLE: Potential for AI-Assisted Medical Education Using Large Language Models	We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, even clinical decision-making.	4	MEDICAL	EDUCATION	Opportunity	y		
Annotator4	medRxiv	[{'authorId': '2107029904', 'name': 'A. Gilson'}, {'authorId': '40902199', 'name': 'C. Safranek'}, {'authorId': '2181652492', 'name': 'T. Huang'}, {'authorId': '11035690', 'name': 'V. Socrates'}, {'authorId': '2087060121', 'name': 'L. Chi'}, {'authorId': '143794498', 'name': 'R. A. Taylor'}, {'authorId': '3181480', 'name': 'David Chartash'}]	How Well Does ChatGPT Do When Taking the Medical Licensing Exams? The Implications of Large Language Models for Medical Education and Knowledge Assessment	Background: ChatGPT is a 175 billion parameter natural language processing model which can generate conversation style responses to user input. Objective: To evaluate the performance of ChatGPT on questions within the scope of United States Medical Licensing Examination (USMLE) Step 1 and Step 2 exams, as well as analyze responses for user interpretability. Methods: We used two novel sets of multiple choice questions to evaluate ChatGPT's performance, each with questions pertaining to Step 1 and Step 2. The first was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the userbase. The second, was the National Board of Medical Examiners (NBME) Free 120-question exams. After prompting ChatGPT with each question, ChatGPT's selected answer was recorded, and the text output evaluated across three qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question. Results: On the four datasets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBME-Free- Step2, ChatGPT achieved accuracies of 44%, 42%, 64.4%, and 57.8%. The model demonstrated a significant decrease in performance as question difficulty increased (P=.012) within the AMBOSS- Step1 dataset. We found logical justification for ChatGPT's answer selection was present in 100% of outputs. Internal information to the question was present in >90% of all questions. The presence of information external to the question was respectively 54.5% and 27% lower for incorrect relative to correct answers on the NBME-Free-Step1 and NBME-Free-Step2 datasets (P<=.001). Conclusion: ChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at greater than 60% threshold on the NBME-Free- Step-1 dataset we show that the model is comparable to a third year medical student. Additionally, due to the dialogic nature of the response to questions, we demonstrate ChatGPT's ability to provide reasoning and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as a medical education tool.	4	MEDICAL	EDUCATION	Opportunity	y		
Annotator4	medRxiv	[{'authorId': '103525980', 'name': 'J. Kim'}]	Search for Medical Information and Treatment Options for Musculoskeletal Disorders through an Artificial Intelligence Chatbot: Focusing on Shoulder Impingement Syndrome	Background: The ChatGPT is an artificial intelligence chatbot that processes natural language text learned through reinforcement learning based on the GPT-3.5 architecture, a large-scale language model. Natural language processing models are being used in various fields and are gradually expanding their use in the medical field. Purpose: This study aimed to investigate the medical information or treatment options that ChatGPT can provide for SIS. Method: Using ChatGPT, which is provided as a free beta test, messages related to SIS were entered, and responses to medical information and treatment options were received and analyzed. Result: ChatGPT not only provided answers to the definition, prevalence, and risk factors of SIS, but also symptoms, diseases with similar symptoms, and orthopedic tests according to the messages input. Additionally, a list of treatment options and exercises were provided. Conclusion: ChatGPT will be able to provide overall useful medical information and treatment options to patients unfamiliar with SIS. However, caution is required as it contains content that may be biased or inappropriate information for patients with SIS. Nevertheless, if natural language processing technology develops further, it is expected to be able to express more detailed medical information and treatment options.	5	MEDICAL	APPLICATION	Opportunity	y		
Annotator4	Mesopotamian Journal of Cyber Security	[{'authorId': '1447250772', 'name': 'Mohammad Aljanabi'}, {'authorId': '2196932745', 'name': 'chatGPT'}]	ChatGPT: Future Directions and Open possibilities	ChatGPT, the cutting-edge language model developed by OpenAI, is one of the most exciting advancements in the field of artificial intelligence. With its ability to generate human-like text and respond to complex questions, ChatGPT has already made a significant impact and is poised to continue its rapid progression in the coming years. As we look to the future of ChatGPT and large language models, there are many exciting possibilities and open opportunities for this technology to enhance our lives and change the way we interact with technology	0	REST		Opportunity	n		
Annotator4	Nature	[{'authorId': '82335473', 'name': 'Flora Graham'}]	Daily briefing: Will ChatGPT kill the essay assignment?		0	EDUCATION	ETHICS	Threat	n		
Annotator4	Nature	[{'authorId': '1413934873', 'name': 'Chris Stokel-Walker'}]	ChatGPT listed as author on research papers: many scientists disapprove		0	ETHICS		Threat	n		
Annotator4	Science	[{'authorId': '2003404994', 'name': 'H. Thorp'}]	ChatGPT is fun, but not an author	In less than 2 months, the artificial intelligence (AI) program ChatGPT has become a cultural sensation. It is freely accessible through a web portal created by the toolâ€™s developer, OpenAI. The programâ€”which automatically creates text based on written promptsâ€”is so popular that itâ€™s likely to be â€œat capacity right nowâ€ if you attempt to use it. When you do get through, ChatGPT provides endless entertainment. I asked it to rewrite the first scene of the classic American play Death of a Salesman, but to feature Princess Elsa from the animated movie Frozen as the main character instead of Willy Loman. The output was an amusing conversation in which Elsaâ€”who has come home from a tough day of sellingâ€”is told by her son Happy, â€œCome on, Mom. Youâ€™re Elsa from Frozen. You have ice powers and youâ€™re a queen. Youâ€™re unstoppable.â€ Mash-ups like this are certainly fun, but there are serious implications for generative AI programs like ChatGPT in science and academia.	5	EDUCATION	ETHICS	Mixed	n		
Annotator4	Seeds of Science	[{'authorId': '2073872541', 'name': 'S. Buck'}]	Why Proposal Review Should Be More Like Meteorology	The process of evaluating research proposals for funding is often based on subjective assessments of the "goodness" or "badness" of a proposal. However, this method of evaluation is not precise and does not provide a common language for reviewers to communicate with each other. In this paper, we propose that science funding agencies ask reviewers to assign quantitative probabilities to the likelihood of a proposal reaching a particular milestone or achieving technical goals. This approach would encourage reviewers to be more precise in their evaluations and could improve both agency-wide and individual reviewer calibration over time. Additionally, this method would allow funding agencies to identify skilled reviewers and allow reviewers to improve their own performance through consistent feedback. While this method may not be suitable for all types of research, it has the potential to enhance proposal review in a variety of fields. [abstract generated by ChatGPT]	0	REST		NAN	y		
Annotator4	SSRN Electronic Journal	[{'authorId': '46308962', 'name': 'Jonathan H. Choi'}, {'authorId': '98900189', 'name': 'Kristin E. Hickman'}, {'authorId': '16166682', 'name': 'Amy B. Monahan'}, {'authorId': '83686718', 'name': 'D. Schwarcz'}]	ChatGPT Goes to Law School	How well can AI models write law school exams without human assistance? To find out, we used the widely publicized AI model ChatGPT to generate answers on four real exams at the University of Minnesota Law School. We then blindly graded these exams as part of our regular grading processes for each class. Over 95 multiple choice questions and 12 essay questions, ChatGPT performed on average at the level of a C+ student, achieving a low but passing grade in all four courses. After detailing these results, we discuss their implications for legal education and lawyering. We also provide example prompts and advice on how ChatGPT can assist with legal writing.	4	EDUCATION	APPLICATION	NAN	y		
Annotator4	The Pediatric Infectious Disease Journal	[{'authorId': '143739014', 'name': 'N. Curtis'}]	To ChatGPT or not to ChatGPT? The Impact of Artificial Intelligence on Academic Publishing.		0	ETHICS	APPLICATION	NAN	n		
Mixed_Annotators	Education sciences	[{'authorId': '9043564', 'name': 'Andrej Thurzo'}, {'authorId': '117988403', 'name': 'M. Strunga'}, {'authorId': '48479577', 'name': 'R. Urban'}, {'authorId': '2187955838', 'name': 'Jana SurovkovÃ¡'}, {'authorId': '2142706255', 'name': 'K. Afrashtehfar'}]	Impact of Artificial Intelligence on Dental Education: A Review and Guide for Curriculum Update	In this intellectual work, the clinical and educational aspects of dentistry were confronted with practical applications of artificial intelligence (AI). The aim was to provide an up-to-date overview of the upcoming changes and a brief analysis of the influential advancements in the use of AI in dental education since 2020. In addition, this review provides a guide for a dental curriculum update for undergraduate and postgraduate education in the context of advances in AI applications and their impact on dentistry. Unsurprisingly, most dental educators have limited knowledge and skills to assess AI applications, as they were not trained to do so. Also, AI technology has evolved exponentially in recent years. Factual reliability and opportunities with OpenAI Inc.â€™s ChatGPT are considered critical inflection points in the era of generative AI. Updating curricula at dental institutions is inevitable as advanced deep-learning approaches take over the clinical areas of dentistry and reshape diagnostics, treatment planning, management, and telemedicine screening. With recent advances in AI language models, communication with patients will change, and the foundations of dental education, including essay, thesis, or scientific paper writing, will need to adapt. However, there is a growing concern about its ethical and legal implications, and further consensus is needed for the safe and responsible implementation of AI in dental education.	4	MEDICAL	EDUCATION	Mixed			
Mixed_Annotators	Frontiers in Computing and Intelligent Systems	[{'authorId': '2200923644', 'name': 'Jianyang Deng'}, {'authorId': '2201012875', 'name': 'Yijia Lin'}]	The Benefits and Challenges of ChatGPT: An Overview	This paper provides an overview of ChatGPT, a natural language processing (NLP) system developed by Open AI. It discusses the features of ChatGPT, its benefits, and its challenges. The paper also provides an analysis of the potential applications of ChatGPT and its limitations. The paper concludes that ChatGPT is a powerful NLP system that can generate human-like conversations, but it has some challenges that must be addressed.	4	EVALUATION	REST	Mixed			
Mixed_Annotators	Indian Journal of Computer Science	[{'authorId': '65991448', 'name': 'Subhabaha Pal'}]	Performing Effective Research Using ChatGPT	OpenAI created ChatGPT, an Artificial Intelligence based Chatbot that responds conversationally to lengthy, complicated enquiries. The present paper is a guide to how the potential of ChatGPT can be used fully to perform effective research studies in the shortest possible time.	5	APPLICATION		NAN	PAYWALL		
Mixed_Annotators	Iraqi Journal for Computer Science and Mathematics	Mohammad Aljanabi1,3 *, Mohanad Ghazi1 , Ahmed Hussein Ali1,3 , Saad Abas Abed1 , ChatGpt2	ChatGpt: Open Possibilities	ChatGPT-3 is a powerful language model developed by OpenAI that has the potential to revolutionize the way we interact with technology. This model has been trained on a massive amount of data, allowing it to understand and generate human-like text with remarkable accuracy. One of the most exciting possibilities of ChatGPT-3 is its potential to improve natural language processing (NLP) and natural language understanding (NLU) in a wide range of applications. In particular, ChatGPT-3 can be used to power chatbots, virtual assistants, and other conversational interfaces. These types of systems are becoming increasingly important as more and more people use voice and text to interact with technology, we list ChatGpt role in each of the follwoing sections[1].	5	REST	EVALUATION	Opportunity			n
Mixed_Annotators	Iraqi Journal for Computer Science and Mathematics	[{'authorId': '1394846990', 'name': 'Maad M. Mijwil'}]	Towards Artificial Intelligence-Based Cybersecurity: The Practices and ChatGPT Generated Ways to Combat Cybercrime	Today, cybersecurity is considered one of the most noteworthy topics that are circulated frequently among companies in order to protect their data from hacking operations. The emergence of cyberspace contributed to the growth of electronic systems. It is a virtual digital space through which interconnection is established between computers and smartphones connected within the Internet of Things environment. This space is critical in building a safe digital environment free of threats and cybercrime. It is only possible to make a digital environment with the presence of cyberspace, which contains modern technologies that make this environment safe and far from unauthorized individuals. Cybersecurity has a wide range of challenges and obstacles in performance, and it is difficult for companies to face them. In this report, the most significant practices, sound, and good strategies will be studied to stop cybercrime and make a digital environment that guarantees data transfers between electronic devices safely and without the presence of malicious software. This report concluded that the procedures provided by cybersecurity are required and must be taken care of and developed.	0	 ETHIC		NAN			
Mixed_Annotators	JMIR Medical Education	[{'authorId': '2088656028', 'name': 'Aidan Gilson'}, {'authorId': None, 'name': 'Conrad W Safranek'}, {'authorId': '2204771151', 'name': 'Thomas Huang'}, {'authorId': None, 'name': 'Vimig Socrates'}, {'authorId': '2204872037', 'name': 'Ling Chi'}, {'authorId': '2110665673', 'name': 'R. Taylor'}, {'authorId': '3181480', 'name': 'David Chartash'}]	How Does ChatGPT Perform on the United States Medical Licensing Examination? The Implications of Large Language Models for Medical Education and Knowledge Assessment.	BACKGROUND Chat Generative Pre-trained Transformer (ChatGPT) is a 175-billion-parameter natural language processing model that can generate conversation-style responses to user input.   OBJECTIVE This study aimed to evaluate the performance of ChatGPT on questions within the scope of the United States Medical Licensing Examination Step 1 and Step 2 exams, as well as to analyze responses for user interpretability.   METHODS We used 2 sets of multiple-choice questions to evaluate ChatGPT's performance, each with questions pertaining to Step 1 and Step 2. The first set was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the user base. The second set was the National Board of Medical Examiners (NBME) free 120 questions. ChatGPT's performance was compared to 2 other large language models, GPT-3 and InstructGPT. The text output of each ChatGPT response was evaluated across 3 qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question.   RESULTS Of the 4 data sets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBME-Free-Step2, ChatGPT achieved accuracies of 44% (44/100), 42% (42/100), 64.4% (56/87), and 57.8% (59/102), respectively. ChatGPT outperformed InstructGPT by 8.15% on average across all data sets, and GPT-3 performed similarly to random chance. The model demonstrated a significant decrease in performance as question difficulty increased (P=.01) within the AMBOSS-Step1 data set. We found that logical justification for ChatGPT's answer selection was present in 100% of outputs of the NBME data sets. Internal information to the question was present in 96.8% (183/189) of all questions. The presence of information external to the question was 44.5% and 27% lower for incorrect answers relative to correct answers on the NBME-Free-Step1 (P<.001) and NBME-Free-Step2 (P=.001) data sets, respectively.   CONCLUSIONS ChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at a greater than 60% threshold on the NBME-Free-Step-1 data set, we show that the model achieves the equivalent of a passing score for a third-year medical student. Additionally, we highlight ChatGPT's capacity to provide logic and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as an interactive medical education tool to support learning.	5	MEDICAL	EDUCATION	Opportunity			
Mixed_Annotators	Journal of Educational Evaluation for Health Professions	[{'authorId': '143918822', 'name': 'Sun Huh'}]	Are ChatGPT's knowledge and interpretation ability comparable to those of medical students in Korea for taking a parasitology examination?: a descriptive study.	This study aimed to compare the knowledge and interpretation ability of ChatGPT, a language model of artificial general intelligence, with those of medical students in Korea by administering a parasitology examination to both ChatGPT and medical students. The examination consisted of 79 items and was administered to ChatGPT on January 1, 2023. The examination results were analyzed in terms of ChatGPT's overall performance score, its correct answer rate by the items' knowledge level, and the acceptability of its explanations of the items. ChatGPT's performance was lower than that of the medical students, and ChatGPT's correct answer rate was not related to the items' knowledge level. However, there was a relationship between acceptable explanations and correct answers. In conclusion, ChatGPT's knowledge and interpretation ability for this parasitology examination were not yet comparable to those of medical students in Korea.	1	MEDICAL	EDUCATION	NAN			
Mixed_Annotators	Journal of Educational Evaluation for Health Professions	[{'authorId': '143918822', 'name': 'Sun Huh'}]	Issues in the 3rd year of the COVID-19 pandemic, including computer-based testing, study design, ChatGPT, journal metrics, and appreciation to reviewers.		0	MEDICAL		NAN			n
Mixed_Annotators	Journal of Medical Ethics	[{'authorId': '14907572', 'name': 'Hazem Zohny'}, {'authorId': '2086699077', 'name': 'J. McMillan'}, {'authorId': '2070836888', 'name': 'M. King'}]	Ethics of generative AI	Artificial intelligence (AI) and its introduction into clinical pathways presents an array of ethical issues that are being discussed in the JME. The development of AI technologies that can produce text that will pass plagiarism detectors and are capable of appearing to be written by a human author present new issues for medical ethics. One set of worries concerns authorship and whether it will now be possible to know that an author or student in fact produced submitted work. That seems likely to be a general worry for secondary and higher education, as well as for all academic journals. Thus far generative AI chatbots do not seem to be able to produce a fully referenced and wellargued ethics article, but they probably could generate a blog or student essay that would be hard to detect after very minor edits. Many schools and universities have moved to online forms of assessment, and it seems likely that generative AI might cast doubt on the integrity of them and we might see a reversion to handwritten examinations as a solution. As well as these immediate and perhaps obvious ethical concerns, generative AI highlights conceptual challenges that pose more profound ethical questions. JME is committed to publishing highquality articles that further the ethical analysis of an issue within healthcare. Some of the content that the journal publishes reports empirical findings. An article that, for example, describes qualitative findings and then develops an analysis of some normative issues could not be solely authored by generative AI: it cannot do qualitative research. However, generative AI can find publicly available sources and produce ethical arguments and syllogisms. What does that imply about the nature of ethical analysis? If ethical analysis, fundamentally, involves assembling, organising and evaluating words, then perhaps generative AI could replace ethicists. At present, generative AI cannot produce the nuance, depth or originality of a quality ethics article, but it may be a matter of time before they pass a medical ethics version of the Turing test. While those who rely on more analytic approaches to ethics might view this as an ethical apocalypse, there are more subtler ways in which generative AI might be used in authorship that are more positive. For instance, if you experiment with ChatGPT for a while, you might find that when you know what you want to say in a paragraph or subsection, you can prompt it to form the argument you want to make and it will generate a fairly welldrafted paragraph. For authors and for postgraduate students, this might be useful for â€˜throat clearingâ€™ sections which are just laying the terrain for the reader before proceeding. AI chatbots might also play a helpful devilâ€™s advocate: once you make a point in a paragraph, you can ask it to generate a rebuttal. If you experiment with ChatGPT you might find that it can be helpful in that not only does it generate obvious counters, but it often raises things that you might not have immediately thought of. So perhaps generative AI has the potential to pose questions like those that might be raised at a seminar while a paper or book is being refined. Much of the work involved in writing good, innovative and original ethical analysis involves wrestling with high level ideas. If generative AI can aid authors in drafting articles then perhaps they save intellectual effort that could be directed toward the â€˜big pictureâ€™? Many publishers, including the BMJ, are committed to encouraging authors from the Global South to write for journals where the authorship has been primarily from the Global North. Publishing in journals such as the JME can be more difficult when English is not an authorâ€™s first language. Because of the speed at which generative AI can present an authorâ€™s ideas in what is close to idiomatic English, they have the potential to significantly open up authorship, especially for humanities style journals like the JME. Journal and copy editors might also save time and effort when correcting articles. These potential benefits will no doubt come with tradeoffs. For instance, those who struggle to articulate a point in writing may find that to be part of a process that leads to a new insight. Perhaps generative AI runs the risk of making that part of the writing process too easy and lead to missing out on opportunities for insight. While that seems like a valid worry, it might be that this is analogous to the changes in writing that resulted from journals being readily available online. Those of us who are old enough to recall writing before online publishing will have spent time trudging between library stacks and searching hard copies of journals to find a paper and stumbling across other papers and journals, which may have led to new ideas. Complete reliance on online databases has probably reduced those moments but the tradeoff clearly still favours their use. Universities, publishers and journals are likely to be exercised about what this will mean for authorship. How can we know whether work was created by the author or by generative AI? While understandable, these worries might be overstated given what they can do at present. While they might find some publicly available sources to support claims, at present they cannot adequately cite, and the quality of the content they produce is wholly dependent on you asking the right questions or having the right ideas. At present, they can be seen as a very sophisticated thesaurus and we do not worry about authors using those. Perhaps the biggest concern is that some predatory journals may feed off the speed by which lowquality manuscripts can now be generated with AI chatbots, and use the phenomenon to publish huge numbers of mostly useless or misleading ethical analyses. This could flood the journal market and undermine trust in research publications. This may be curbed by introducing the use of AI output detectors, though it may also encourage greater (and much needed) scepticism towards publications, with readers and news writers paying greater attention to where the paper they are reporting on was published, and what the publisherâ€™s standards are. Editorially, journals need to and will continue to be concerned with authorship, but our main focus is on the quality and originality of ideas. It seems likely that generative AI is here to stay and will develop, so journals will need to find ways of figuring out how to work with them. Bioethics Centre, The University of Otago, Dunedin, New Zealand	4	MEDICAL	ETHICS	Threat			
Mixed_Annotators	Journal of Research in Philosophy and History	[{'authorId': '10721764', 'name': 'S. Furukuma'}]	Philosophical Questions Concerning the Anthropocene and the Plasticene to ChatGPT and the Moderate Perspectives Derived from Their Responses	ChatGPT, an AI (artificial intelligence) model developed by OpenAI was posed various philosophical questions about the Anthropocene and the Plasticene. The model opined that the naming of the Anthropocene holds significance, that the term Plasticene accurately encapsulates contemporary realities, that the expansion of the concept, such as through the lens of plastic ecology, will foster further study, that plastic rocks are important from the perspective of the Earthâ€™s environment, and that although no one sees the Anthropocene in the traditional sense, future scientists may glean insights into the impacts of humankindâ€™s activities from geological samples. From these moderate responses, we may have the utility to modify our opinions and create opportunities for novel anthropological questions.	4	APPLICATION		Opportunity			
Mixed_Annotators	Journalism &amp; Mass Communication Educator	[{'authorId': '1795976', 'name': 'J. Pavlik'}]	Collaborating With ChatGPT: Considering the Implications of Generative Artificial Intelligence for Journalism and Media Education	Generative artificial intelligence (AI) is ushering in an era of potential transformation of journalism and media content. This essay considers one notable generative AI platform called ChatGPT made available to the public in 2022 for free use. ChatGPT allows users to enter text prompts and rapidly generates text responses drawn from its knowledge acquired via machine learning in engagement with the internet. This essay is coauthored by a human journalism and media professor in collaboration with ChatGPT. The essay demonstrates the capacity and limitations of ChatGPT and offers reflections on the implications of generative AI for journalism and media education.	4	APPLICATION	WRITING	NAN			
Mixed_Annotators	JURNAL PETISI (Pendidikan Teknologi Informasi)	[{'authorId': None, 'name': 'Adi Setiawan'}, {'authorId': None, 'name': 'Ulfah Khairiyah Luthfiyani'}]	Penggunaan ChatGPT Untuk Pendidikan di Era Education 4.0: Usulan Inovasi Meningkatkan Keterampilan Menulis	ChatGPT OpenAI merupakan teknologi mesin berbasis kecerdasan buatan yang dilatih untuk bisa menirukan percakapan manusia menggunakan teknologi NLP (Natural Language Processing). Pada kenyataannya ChatGPT dapat dimanfaatkan untuk menghasilkan suatu tulisan yang cukup ilmiah atau bahkan buku dengan prompt yang dirumuskan di awal dengan teknik yang baik dan efektif. Sehingga peluang inovasi menggunakan teknologi ini terbuka lebar untuk pendidikan di Indonesia, salah satunya dalam meningkatkan kemampuan menulis peserta didik di sekolah/kampus untuk meraih enam kompetensi yang dibutuhkan di Era Education 4.0. Enam kompetensi itu adalah berpikir kritis, kolaborasi, komunikasi, kreativitas, pendidikan karakter dan kewarganegaraan. Hasil eksperimen yang dilakukan menggunakan ChatGPT dapat menghasilkan suatu tulisan berjumlah 693 kata di mana hasil ini masih bisa dikembangkan lebih lanjut untuk penugasan berikutnya bagi peserta didik. Total waktu yang dibutuhkan untuk menyelesaikan eksperimen ini lebih kurang 7 menit, termasuk waktu untuk mendokumentasikan hasil pemrosesan ChatGPT, namun tidak termasuk waktu untuk merumuskan dua prompt yang baik dan efektif sebelum eksperimen dilakukan.	4	EDUCATION		Opportunity
Mixed_Annotators	Lebensmittel Zeitung	[{'authorId': '2133051672', 'name': 'Maurizio Giuri'}]	Microsoft bietet ChatGPT an	Microsoft will Kunden seines Cloud-Dienstes Azure bald die Chat-Software ChatGPT verfÃ¼gbar machen. US-Medien hatten zuletzt Ã¼ber einen Milliardendeal berichtet, mit dem sich der Konzern ein Drittel an der ChatGPT-Mutter OpenAI sichern mÃ¶chte.	0	REST		NAN			n
Mixed_Annotators	Machine Against the Rage	[{'authorId': '2091007360', 'name': 'Maik Fielitz'}, {'authorId': '114339363', 'name': 'Holger Marcks'}, {'authorId': '2202563157', 'name': 'Harald Sick'}, {'authorId': '2202557246', 'name': 'Hendrik Bitzmann'}]	MaÃŸnahmen gegen Hass im Netz: Das Wichtigste aus dem Herbst 2022	Aktuelle, kommentierte Ereignisse im Kampf gegen digitalen Hass. Diesmal im RÃ¼ckblick auf das letzte Quartal: Zivilgesellschaftliche Kampagne gegen Antisemitismus auf TikTok +++ Verleumdungsklage gegen Twitter erfolgreich +++ Milliardenklage gegen Meta in Kenia +++ Neues Twitter-Feature macht Verbreitung von Hass nachvollziehbarer +++ ChatGPT reproduziert Stereotype +++ TikTok kÃ¼ndigt algorithmische Transparenz an +++ Kein TikTok fÃ¼r US-RegierungsangehÃ¶rige +++ EU-Aufsicht fÃ¼r Twitter beantragt +++ DSA und Mastodon +++ AuÃŸerdem neu: AusgewÃ¤hlte Forschungsarbeiten zum Thema Hass im Netz.	0	REST		NAN			n
Mixed_Annotators	Management &amp; Data Science	[{'authorId': '49509218', 'name': 'B. Quinio'}, {'authorId': '2769534', 'name': 'Marc Bidan'}]	ChatGPT : Un robot conversationnel peut-il enseigner ?	Câ€™est le phÃ©nomÃ¨ne numÃ©rique de la fin 2022 : ChatGPT. Cet outil conversationnel qui utilise lâ€™Intelligence Artificielle est encore en phase de test et se prÃ©sente comme Â« Optimizing Language Models for Dialogue Â». Issu des travaux de OpenAI, il est spectaculaire. Il est mÃªme tellement spectaculaire que la maison mÃ¨re de Google a annoncÃ© un Â« code rouge Â» pour ne pas se faire dÃ©passer par ce futur tueur de clics !	5	EDUCATION		Opportunity
Mixed_Annotators	Medicine, Health care and Philosophy	[{'authorId': '2354377', 'name': 'B. Gordijn'}, {'authorId': '50377385', 'name': 'H. Have'}]	ChatGPT: evolution or revolution?	In the last few years large language models (LLMs) have inspired an increasingly sophisticated academic debate about their ethical implications (see e.g., Weidinger et al. 2021). With OpenAI’s release of ChatGPT, on November 30th, 2022, this discussion has now moved mainstream. The new chatbot was released by way of research preview “… to get users’ feedback and learn about its strengths and weaknesses” (OpenAI, 2022). In the following week more than a million users tried out the new chatbot (Vallance, 2022). The authors of this editorial could not resist the temptation either. So, we asked ChatGPT to write a column about contemporary Greece and its ambivalent relationship with its glorious ancient past in the style of NYT Op-Ed columnist Thomas Friedman.	0	ETHICS	REST	NAN			n
Mixed_Annotators	medRxiv	[{'authorId': '2051250388', 'name': 'T. Kung'}, {'authorId': '2045482362', 'name': 'M. Cheatham'}, {'authorId': '2196935808', 'name': 'A. Medinilla'}, {'authorId': '2196932745', 'name': 'chatGPT'}, {'authorId': '2196932743', 'name': 'C. Sillos'}, {'authorId': '2194457777', 'name': 'L. D. De Leon'}, {'authorId': '2196937260', 'name': 'C. Elepano'}, {'authorId': '2101601654', 'name': 'M. Madriaga'}, {'authorId': '117973505', 'name': 'R. Aggabao'}, {'authorId': '2196935806', 'name': 'G. Diaz-Candido'}, {'authorId': '7262505', 'name': 'J. Maningo'}, {'authorId': '2196932802', 'name': 'V. Tseng'}]	Performance of ChatGPT on USMLE: Potential for AI-Assisted Medical Education Using Large Language Models	We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, even clinical decision-making.	5	MEDICAL	EDUCATION	Opportunity			
Mixed_Annotators	medRxiv	[{'authorId': '2107029904', 'name': 'A. Gilson'}, {'authorId': '40902199', 'name': 'C. Safranek'}, {'authorId': '2181652492', 'name': 'T. Huang'}, {'authorId': '11035690', 'name': 'V. Socrates'}, {'authorId': '2087060121', 'name': 'L. Chi'}, {'authorId': '143794498', 'name': 'R. A. Taylor'}, {'authorId': '3181480', 'name': 'David Chartash'}]	How Well Does ChatGPT Do When Taking the Medical Licensing Exams? The Implications of Large Language Models for Medical Education and Knowledge Assessment	Background: ChatGPT is a 175 billion parameter natural language processing model which can generate conversation style responses to user input. Objective: To evaluate the performance of ChatGPT on questions within the scope of United States Medical Licensing Examination (USMLE) Step 1 and Step 2 exams, as well as analyze responses for user interpretability. Methods: We used two novel sets of multiple choice questions to evaluate ChatGPT's performance, each with questions pertaining to Step 1 and Step 2. The first was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the userbase. The second, was the National Board of Medical Examiners (NBME) Free 120-question exams. After prompting ChatGPT with each question, ChatGPT's selected answer was recorded, and the text output evaluated across three qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question. Results: On the four datasets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBME-Free- Step2, ChatGPT achieved accuracies of 44%, 42%, 64.4%, and 57.8%. The model demonstrated a significant decrease in performance as question difficulty increased (P=.012) within the AMBOSS- Step1 dataset. We found logical justification for ChatGPT's answer selection was present in 100% of outputs. Internal information to the question was present in >90% of all questions. The presence of information external to the question was respectively 54.5% and 27% lower for incorrect relative to correct answers on the NBME-Free-Step1 and NBME-Free-Step2 datasets (P<=.001). Conclusion: ChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at greater than 60% threshold on the NBME-Free- Step-1 dataset we show that the model is comparable to a third year medical student. Additionally, due to the dialogic nature of the response to questions, we demonstrate ChatGPT's ability to provide reasoning and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as a medical education tool.	5	MEDICAL	EDUCATION	Opportunity	y		
Mixed_Annotators	medRxiv	[{'authorId': '71575036', 'name': 'O. Nov'}, {'authorId': '153599001', 'name': 'N. Singh'}, {'authorId': '121345049', 'name': 'D. Mann'}]	Putting ChatGPT's Medical Advice to the (Turing) Test	Importance: Chatbots could play a role in answering patient questions, but patients' ability to distinguish between provider and chatbot responses, and patients' trust in chatbots' functions are not well established. Objective: To assess the feasibility of using ChatGPT or a similar AI-based chatbot for patient-provider communication. Design: Survey in January 2023 Setting: Survey Participants: A US representative sample of 400 study participants aged 18 and above was recruited on Prolific, a crowdsourcing platform for academic studies. 384 participants filled out the full survey. After removing participants who spent less than 3 minutes on the survey, 360 respondents remained. 53.3% of respondents analyzed were women; their average age was 45.4. Exposure(s): Ten representative non-administrative patient-provider interactions were extracted from the EHR. Patients' questions were placed in ChatGPT with a request for the chatbot to respond using approximately the same word count as the human provider's response. In the survey, each patient's question was followed by a provider- or ChatGPT-generated response. Participants were informed that five responses were provider-generated and five were chatbot-generated. Participants were asked, and incentivized financially, to correctly identify the response source. Participants were also asked about their trust in chatbots' functions in patient-provider communication, using a Likert scale of 1-5. Main Outcome(s) and Measure(s): Main outcome: Proportion of responses correctly classified as provider- vs chatbot-generated. Secondary outcomes: Average and standard deviation of responses to trust questions. Results: The correct classification of responses ranged between 23.4% to 86.7% for different questions. On average, chatbot responses were identified correctly 60.0% of the time and provider responses were identified correctly 62.3% of the time. On average, responses toward patients' trust in chatbots' functions were weakly positive (mean Likert score: 3.4), with lower trust as the health-related complexity of the task in questions increased. Conclusions and Relevance: ChatGPT responses to patient questions were close to indistinguishable from provider responses. Laypeople appear to trust the use of chatbots to answer lower risk health questions. It is important to continue studying patient-chatbot interaction as chatbots move from administrative to more clinical roles in healthcare.	5	MEDICAL		Opportunity	y		
Mixed_Annotators	medRxiv	[{'authorId': '1992720036', 'name': 'F. Sanmarchi'}, {'authorId': '7433186', 'name': 'D. Golinelli'}, {'authorId': '145216171', 'name': 'A. Bucci'}]	A step-by-step Researcher's Guide to the use of an AI-based transformer in epidemiology: an exploratory analysis of ChatGPT using the STROBE checklist for observational studies	Objectives. This study aims at investigating how early-stage AI-based transformers can support researchers in designing and conducting an epidemiological study. To accomplish this, we used ChatGPT to reformulate the STROBE recommendations into a list of questions to be answered by the transformer itself. We then qualitatively evaluated the coherence and relevance of the transformers outputs. Study design: Descriptive study. Methods. We first chose a study to be used as a basis for the simulation. We then used ChatGPT to transform each STROBE checklist item into specific prompts. Each answer to the respective prompt was evaluated by independent researchers in terms of coherence and relevance. Results. The mean scores assigned to each prompt were heterogeneous. On average, for the coherence domain, the overall mean score was 3.6 out of 5.0, and for relevance it was 3.3 out of 5.0. The lowest scores were assigned to items belonging to the Methods section of the checklist. Conclusions. ChatGPT can be considered as a valuable support for researchers in conducting an epidemiological study, following internationally recognized guidelines and standards. It is crucial for the users to have knowledge on the subject and a critical mindset when evaluating the outputs. The potential benefits of AI in scientific research and publishing are undeniable, but it is crucial to address the risks, and the ethical and legal consequences associated with its use.	4	MEDICAL		Mixed			
Mixed_Annotators	medRxiv	[{'authorId': '41132090', 'name': 'F. Antaki'}, {'authorId': '2003766323', 'name': 'S. Touma'}, {'authorId': '1396269411', 'name': 'D. Milad'}, {'authorId': '1412265275', 'name': 'J. El-Khoury'}, {'authorId': '2138280308', 'name': 'R. Duval'}]	Evaluating the Performance of ChatGPT in Ophthalmology: An Analysis of its Successes and Shortcomings	We tested the accuracy of ChatGPT, a large language model (LLM), in the ophthalmology question-answering space using two popular multiple choice question banks used for the high-stakes Ophthalmic Knowledge Assessment Program (OKAP) exam. The testing sets were of easy-to-moderate difficulty and were diversified, including recall, interpretation, practical and clinical decision-making problems. ChatGPT achieved 55.8% and 42.7% accuracy in the two 260-question simulated exams. Its performance varied across subspecialties, with the best results in general medicine and the worst in neuro-ophthalmology and ophthalmic pathology and intraocular tumors. These results are encouraging but suggest that specialising LLMs through domain-specific pre-training may be necessary to improve their performance in ophthalmic subspecialties.	3	MEDICAL	EDUCATION	NAN			
Mixed_Annotators	medRxiv	[{'authorId': '2070976921', 'name': 'J. BenoÃ®t'}]	ChatGPT for Clinical Vignette Generation, Revision, and Evaluation	Objective To determine the capabilities of ChatGPT for rapidly generating, rewriting, and evaluating (via diagnostic and triage accuracy) sets of clinical vignettes. Design We explored the capabilities of ChatGPT for generating and rewriting vignettes. First, we gave it natural language prompts to generate 10 new sets of 10 vignettes, each set for a different common childhood illness. Next, we had it generate 10 sets of 10 vignettes given a set of symptoms from which to draw. We then had it rewrite 15 existing pediatric vignettes at different levels of health literacy. Fourth, we asked it to generate 10 vignettes written as a parent, and rewrite these vignettes as a physician, then at a grade 8 reading level, before rewriting them from the original parent's perspective. Finally, we evaluated ChatGPT for diagnosis and triage for 45 clinical vignettes previously used for evaluating symptom checkers. Setting and participants ChatGPT, a publicly available, free chatbot. Main outcome measures Our main outcomes for de novo vignette generation were whether ChatGPT followed vignette creation instructions consistently, correctly, and listed reasonable symptoms for the disease being described. For generating vignettes from pre-existing symptom sets, we examined whether the symptom sets were used without introducing extra symptoms. Our main outcome for rewriting existing standardized vignettes to match patient demographics, and rewriting vignettes between styles, was whether symptoms were dropped or added outside the original vignette. Finally, our main outcomes examining diagnostic and triage accuracy on 45 standardized patient vignettes were whether the correct diagnosis was listed first, and if the correct triage recommendation was made. Results ChatGPT was able to quickly produce varied contexts and symptom profiles when writing vignettes based on an illness name, but overused some core disease symptoms. It was able to use given symptom lists as the basis for vignettes consistently, adding one additional (though appropriate) symptom from outside the list for one disease. Pediatric vignettes rewritten at different levels of health literacy showed more complex symptoms being dropped when writing at low health literacy in 87.5% of cases. While writing at high health literacy, it added a diagnosis to 80% of vignettes (91.7% correctly diagnosed). Symptoms were retained in 90% of cases when rewriting vignettes between viewpoints. When presented with 45 vignettes, ChatGPT identified illnesses with 75.6% (95% CI, 62.6% to 88.5%) first-pass diagnostic accuracy and 57.8% (95% CI, 42.9% to 72.7%) triage accuracy. Its use does require monitoring and has caveats, which we discuss. Conclusions ChatGPT was capable, with caveats and appropriate review, of generating, rewriting, and evaluating clinical vignettes.	3	MEDICAL		NAN			
Mixed_Annotators	medRxiv	[{'authorId': '47652637', 'name': 'A. S. Rao'}, {'authorId': '103525980', 'name': 'J. Kim'}, {'authorId': '72458178', 'name': 'M. Kamineni'}, {'authorId': '9690134', 'name': 'M. Pang'}, {'authorId': '102502817', 'name': 'W. Lie'}, {'authorId': '14920559', 'name': 'M. Succi'}]	Evaluating ChatGPT as an Adjunct for Radiologic Decision-Making	BACKGROUND ChatGPT, a popular new large language model (LLM) built by OpenAI, has shown impressive performance in a number of specialized applications. Despite the rising popularity and performance of AI, studies evaluating the use of LLMs for clinical decision support are lacking. PURPOSE To evaluate ChatGPT's capacity for clinical decision support in radiology via the identification of appropriate imaging services for two important clinical presentations: breast cancer screening and breast pain. MATERIALS AND METHODS We compared ChatGPT's responses to the American College of Radiology (ACR) Appropriateness Criteria for breast pain and breast cancer screening. Our prompt formats included an open-ended (OE) format, where ChatGPT was asked to provide the single most appropriate imaging procedure, and a select all that apply (SATA) format, where ChatGPT was given a list of imaging modalities to assess. Scoring criteria evaluated whether proposed imaging modalities were in accordance with ACR guidelines. RESULTS ChatGPT achieved an average OE score of 1.83 (out of 2) and a SATA average percentage correct of 88.9% for breast cancer screening prompts, and an average OE score of 1.125 (out of 2) and a SATA average percentage correct of 58.3% for breast pain prompts. CONCLUSION Our results demonstrate the feasibility of using ChatGPT for radiologic decision making, with the potential to improve clinical workflow and responsible use of radiology services.	5	MEDICAL		Opportunity			
Mixed_Annotators	medRxiv	[{'authorId': '6807774', 'name': 'Y. Yeo'}, {'authorId': '84723205', 'name': 'J. Samaan'}, {'authorId': '30987139', 'name': 'W. Ng'}, {'authorId': '47388850', 'name': 'Peng-Sheng Ting'}, {'authorId': '2059999783', 'name': 'H. Trivedi'}, {'authorId': '14685491', 'name': 'A. Vipani'}, {'authorId': '6749804', 'name': 'W. Ayoub'}, {'authorId': '9125596', 'name': 'J. D. Yang'}, {'authorId': '14798289', 'name': 'O. Liran'}, {'authorId': '144729350', 'name': 'B. Spiegel'}, {'authorId': '2184361653', 'name': 'A. Kuo'}]	Assessing the performance of ChatGPT in answering questions regarding cirrhosis and hepatocellular carcinoma	Background: Patients with cirrhosis and hepatocellular carcinoma (HCC) require extensive care. Personalized education can improve their outcomes. ChatGPT (Generative Pre-trained Transformer), a natural language processing model, has shown potential to provide professional yet patient-freindly responses. Aim: To examine the accuracy and reproducibility of ChatGPT in responding to questions regarding knowledge, management, and emotional support for cirrhosis and HCC. Method: ChatGPT's responses to 164 frequently asked questions were independently graded by two transplant hepatologists, with a third reviewer resolving any discrepancies. We also compared the performance of ChatGPT on two previously validated and published questionnaires to the physicians or trainees who were tested in the included publications. Furthermore, we formulated the 26 quality measures of cirrhosis management into questions and tested ChatGPT's knowledge in cirrhosis care. Finally, the capacity to provide emotional support to patients or caregivers was tested. Results: ChatGPT regurgitated extensive knowledge about both cirrhosis and HCC, but for questions with correct responses, only a small proportion was labelled as comprehensive. The performance was better in basic knowledge, lifestyle, and treatment than in the domains of diagnosis and preventive medicine. For the quality measures, the model answered 76.9% of questions correctly but failed to specify the cut-off values for making medical decisions and treatment durations. When compared to physicians/trainees, ChatGPT fell short in knowledge of guidelines varying across geographic regions, such as HCC screening criteria. The model also provided practical and multifaceted advice to patients and caregivers regarding the next steps and adjusting to a new diagnosis. Conclusion: In summary, we analyzed the areas of robustness and limitations of ChatGPT's responses on the management of cirrhosis and HCC and relevant emotional support. ChatGPT may have a role as an adjunct informational tool for patients and physicians to improve outcomes.	3	MEDICAL	EVALUATION	Opportunity			
Mixed_Annotators	medRxiv	[{'authorId': '2115335067', 'name': 'D. Duong'}, {'authorId': '2110362084', 'name': 'B. D. Solomon'}]	Analysis of large-language model versus human performance for genetics questions	Large-language models like ChatGPT have recently received a great deal of attention. To assess ChatGPT in the field of genetics, we compared its performance to human respondents in answering genetics questions (involving 13,636 responses) that had been posted on social media platforms starting in 2021. Overall, ChatGPT did not perform significantly differently than human respondents, but did significantly better on memorization-type questions versus critical thinking questions, frequently provided different answers when asked questions multiple times, and provided plausible explanations for both correct and incorrect answers.	4	MEDICAL	APPLICATION	Mixed			
Mixed_Annotators	medRxiv	[{'authorId': '103525980', 'name': 'J. Kim'}]	Search for Medical Information and Treatment Options for Musculoskeletal Disorders through an Artificial Intelligence Chatbot: Focusing on Shoulder Impingement Syndrome	Background: The ChatGPT is an artificial intelligence chatbot that processes natural language text learned through reinforcement learning based on the GPT-3.5 architecture, a large-scale language model. Natural language processing models are being used in various fields and are gradually expanding their use in the medical field. Purpose: This study aimed to investigate the medical information or treatment options that ChatGPT can provide for SIS. Method: Using ChatGPT, which is provided as a free beta test, messages related to SIS were entered, and responses to medical information and treatment options were received and analyzed. Result: ChatGPT not only provided answers to the definition, prevalence, and risk factors of SIS, but also symptoms, diseases with similar symptoms, and orthopedic tests according to the messages input. Additionally, a list of treatment options and exercises were provided. Conclusion: ChatGPT will be able to provide overall useful medical information and treatment options to patients unfamiliar with SIS. However, caution is required as it contains content that may be biased or inappropriate information for patients with SIS. Nevertheless, if natural language processing technology develops further, it is expected to be able to express more detailed medical information and treatment options.	5	MEDICAL	APPLICATION	Opportunity			
Mixed_Annotators	Mesopotamian Journal of Cyber Security	[{'authorId': '1447250772', 'name': 'Mohammad Aljanabi'}, {'authorId': '2196932745', 'name': 'chatGPT'}]	ChatGPT: Future Directions and Open possibilities	ChatGPT, the cutting-edge language model developed by OpenAI, is one of the most exciting advancements in the field of artificial intelligence. With its ability to generate human-like text and respond to complex questions, ChatGPT has already made a significant impact and is poised to continue its rapid progression in the coming years. As we look to the future of ChatGPT and large language models, there are many exciting possibilities and open opportunities for this technology to enhance our lives and change the way we interact with technology	0	REST		Opportunity			
Mixed_Annotators	Mesopotamian Journal of Cyber Security	[{'authorId': '1394846990', 'name': 'Maad M. Mijwil'}, {'authorId': '1447250772', 'name': 'Mohammad Aljanabi'}, {'authorId': '145907529', 'name': 'Ahmed Ali'}]	ChatGPT: Exploring the Role of Cybersecurity in the Protection of Medical Information	ChatGPT is a large language model developed by OpenAI. It is trained on a dataset of conversational text and can be used to generate human-like responses to prompts in a variety of languages and formats. It can be used for tasks such as chatbots, language translation, and text completion. The role of ChatGPT is to generate human-like text based on a given prompt or context. It can be used in a variety of applications such as chatbots, language translation, text completion, and question answering. Additionally, it can be fine-tuned for specific tasks such as generating product descriptions or summarizing articles. It can also be used to generate creative writing such as poetry and stories. It can be integrated into a wide range of industries from customer service to entertainment, to research.	0	REST	APPLICATION	Opportunity			
Mixed_Annotators	Metaverse Basic and Applied Research	[{'authorId': '2102953588', 'name': 'William Castillo-GonzÃ¡lez'}]	ChatGPT y el futuro de la comunicaciÃ³n cientÃ­fica	ChatGPT es un modelo de lenguaje desarrollado por OpenAI que utiliza la tÃ©cnica de procesamiento de lenguaje natural (NLP) de transformaciÃ³n autorregresiva (Transformer) para generar respuestas coherentes y naturales a preguntas o comentarios en tiempo real. Una forma en la que ChatGPT podrÃ­a ser Ãºtil en la comunicaciÃ³n cientÃ­fica es como una herramienta para ayudar a comunicar las investigaciones de manera mÃ¡s clara y accesible para el pÃºblico en general. Otra forma en la que esta inteligencia artificial (IA) podrÃ­a ser Ãºtil es como una herramienta para contribuir a los cientÃ­ficos y acadÃ©micos a mantenerse al dÃ­a con las Ãºltimas investigaciones y desarrollos en su campo de trabajo. Especialmente el ChatGPT podrÃ­a ser utilizado para recopilar y resumir artÃ­culos cientÃ­ficos y otras publicaciones relevantes de manera automatizada, lo que podrÃ­a ayudar a los cientÃ­ficos a ahorrar tiempo y esfuerzo al tener que leer y analizar cada artÃ­culo por sÃ­ mismos. Un elemento crucial en algunos tipos de estudios, la sÃ­ntesis de literatura, sea para una revisiÃ³n narrativa o panorÃ¡mica, el uso de ChatGPT permitirÃ­a generar resÃºmenes o abstracts de investigaciones de manera mÃ¡s eficiente, o incluso a redactar secciones de un artÃ­culo cientÃ­fico que requieran menos anÃ¡lisis crÃ­tico o interpretaciÃ³n. Sin embargo, la escritura de un artÃ­culo cientÃ­fico completo requiere un conocimiento profundo del campo de investigaciÃ³n y la habilidad para analizar y sintetizar datos de manera crÃ­tica. Esto es algo que solo puede hacerse de manera efectiva a travÃ©s del trabajo y el esfuerzo de un ser humano.	0	APPLICATION		Opportunity			
Mixed_Annotators	Nature	[{'authorId': '1413934873', 'name': 'Chris Stokel-Walker'}]	AI bot ChatGPT writes smart essays - should professors worry?		5	EDUCATION		Mixed			
Mixed_Annotators	Nature	[{'authorId': '4596241', 'name': 'D. Castelvecchi'}]	Are ChatGPT and AlphaCode going to replace programmers?		0	APPLICATION		Mixed			
Mixed_Annotators	Nature	[{'authorId': '82335473', 'name': 'Flora Graham'}]	Daily briefing: Will ChatGPT kill the essay assignment?		0	EDUCATION		Threat			
Mixed_Annotators	Nature	[{'authorId': '1413934873', 'name': 'Chris Stokel-Walker'}]	ChatGPT listed as author on research papers: many scientists disapprove		0	REST	APPLICATION	Mixed			
Mixed_Annotators	Nature	[]	Tools such as ChatGPT threaten transparent science; here are our ground rules for their use		0	ETHICS		Threat			
Mixed_Annotators	Nature	[{'authorId': '40898374', 'name': 'Holly Else'}]	Abstracts written by ChatGPT fool scientists		5	APPLICATION		Threat			
Mixed_Annotators	Nature	[{'authorId': '82335473', 'name': 'Flora Graham'}]	Daily briefing: ChatGPT listed as author on research papers.		0	REST	APPLICATION	NAN			
Mixed_Annotators	Nature	[{'authorId': '51140547', 'name': 'E. A. V. van Dis'}, {'authorId': '119315380', 'name': 'J. Bollen'}, {'authorId': '2067166918', 'name': 'W. Zuidema'}, {'authorId': '8457319', 'name': 'R. van Rooij'}, {'authorId': '38196528', 'name': 'C. Bockting'}]	ChatGPT: five priorities for research		0	REST		NAN			
Mixed_Annotators	Nature	[{'authorId': '82335473', 'name': 'Flora Graham'}]	Daily briefing: Science urgently needs a plan for ChatGPT.		0	REST		Threat			
Mixed_Annotators	Nature	[{'authorId': '1413934873', 'name': 'Chris Stokel-Walker'}, {'authorId': '46619889', 'name': 'Richard van Noorden'}]	What ChatGPT and generative AI mean for science		0	REST		NAN			
Mixed_Annotators	Nature Astronomy	[]	Welcome to the AI future?		0	REST		NAN			
Mixed_Annotators	Nature Machine Intelligence	[]	The AI writing on the wall		0	REST		NAN			
Mixed_Annotators	Neurosurgery	[{'authorId': None, 'name': "Randy S D'Amico"}, {'authorId': '16427284', 'name': 'T. White'}, {'authorId': '2167140767', 'name': 'Harshal A. Shah'}, {'authorId': None, 'name': 'David J Langer'}]	I Asked a ChatGPT to Write an Editorial About How We Can Incorporate Chatbots Into Neurosurgical Research and Patient Careâ€¦.		0	MEDICAL	APPLICATION	NAN			
Mixed_Annotators	New Scientist	[{'authorId': '1413934873', 'name': 'Chris Stokel-Walker'}]	ChatGPT can find and fix the bugs in computer code		5	APPLICATION		Opportunity			
Mixed_Annotators	Numeracy	[{'authorId': '3099078', 'name': 'Gizem Karaali'}]	Artificial Intelligence, Basic Skills, and Quantitative Literacy	The introduction in November 2022 of ChatGPT, a freely available language-based artificial intelligence, has led to concerns among some educators about the feasibility and benefits of teaching basic writing and critical thinking skills to students in the context of easily accessed, AI-based cheating mechanisms. As of now, ChatGPT can write pretty convincing student-level prose, but it is still not very good at answering quantitatively rich questions. Therefore, for the time being, the preceding concerns may not be shared by a large portion of the numeracy education community. However, as Google and WolframAlpha are definitely capable of answering standard and some non-standard quantitative queries, a future generation of artificial intelligence including both types of capabilities is not out of the question. So, the issue is still relevant to the readers of this journal. As we continue to focus on the higher-level skills and habits of mind that make up quantitative literacy (QL) and quantitative reasoning (QR), we should not forget that basic literacy and numeracy are still foundational building blocks. While AI is making advances in these basic realms, our human students seem to be losing ground, as implied by the most recent NAEP scores. Here we encourage our readership to focus on what makes QL/QR so challenging to teach, to human as well as artificial intelligences.	3	EDUCATION		Threat			
Mixed_Annotators	Nurse Education in Practice	[{'authorId': '1404192752', 'name': "S. O'Connor"}, {'authorId': '2196932745', 'name': 'chatGPT'}]	Open artificial intelligence platforms in nursing education: Tools for academic progress or abuse?		0	REST		NAN			
Mixed_Annotators	Oncoscience	[{'authorId': '2079798046', 'name': 'A. Zhavoronkov'}]	Rapamycin in the context of Pascalâ€™s Wager: generative pre-trained transformer perspective	Large language models utilizing transformer neural networks and other deep learning architectures demonstrated unprecedented results in many tasks previously accessible only to human intelligence. In this article, we collaborate with ChatGPT, an AI model developed by OpenAI to speculate on the applications of Rapamycin, in the context of Pascalâ€™s Wager philosophical argument commonly utilized to justify the belief in god. In response to the query â€œWrite an exhaustive research perspective on why taking Rapamycin may be more beneficial than not taking Rapamycin from the perspective of Pascalâ€™s wagerâ€ ChatGPT provided the pros and cons for the use of Rapamycin considering the preclinical evidence of potential life extension in animals. This article demonstrates the potential of ChatGPT to produce complex philosophical arguments and should not be used for any off-label use of Rapamycin.	5	MEDICAL	ETHICS	Opportunity			
Mixed_Annotators	Pakistan Journal of Medical Sciences	[{'authorId': '38252945', 'name': 'R. Khan'}, {'authorId': None, 'name': 'Masood Jawaid'}, {'authorId': '2204962760', 'name': 'Aymen Rehan Khan'}, {'authorId': None, 'name': 'Madiha Sajjad'}]	ChatGPT - Reshaping medical education and clinical management	Artificial Intelligence is no more the talk of the fiction read in novels or seen in movies. It has been making inroads slowly and gradually in medical education and clinical management of patients apart from all other walks of life. Recently, chatbots particularly ChatGPT, were developed and trained, using a huge amount of textual data from the internet. This has made a significant impact on our approach in medical science. Though there are benefits of this new technology, a lot of caution is required for its use.  doi: https://doi.org/10.12669/pjms.39.2.7653  How to cite this: Khan RA, Jawaid M, Khan AR, Sajjad M. ChatGPT - Reshaping medical education and clinical management. Pak J Med Sci. 2023;39(2):---------. doi: https://doi.org/10.12669/pjms.39.2.7653  This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.	0	MEDICAL	EDUCATION	Mixed			
Mixed_Annotators	Radiology	[{'authorId': '2150472791', 'name': 'S. Biswas'}]	ChatGPT and the Future of Medical Writing.		0	MEDICAL	WRITING	NAN			No
Mixed_Annotators	Radiology	[{'authorId': '35139543', 'name': 'Yiqiu Shen'}, {'authorId': '3771591', 'name': 'L. Heacock'}, {'authorId': '2202899600', 'name': 'Jonathan Elias'}, {'authorId': '4964392', 'name': 'K. Hentel'}, {'authorId': '12542421', 'name': 'B. Reig'}, {'authorId': '2202899450', 'name': 'George Shih'}, {'authorId': '145717702', 'name': 'Linda Moy'}]	ChatGPT and Other Large Language Models Are Double-edged Swords.		3	MEDICAL		NAN			
Mixed_Annotators	Radiology	[{'authorId': '2091400886', 'name': 'F. Kitamura'}]	ChatGPT Is Shaping the Future of Medical Writing but Still Requires Human Judgment.		4	MEDICAL	WRITING	Opportunity			No
Mixed_Annotators	Revista EletrÃ´nica de CiÃªncia Administrativa	[{'authorId': '51056140', 'name': 'Luciano Rossoni'}, {'authorId': '2202433509', 'name': 'Chat Gpt'}]	A inteligÃªncia artificial e eu: escrevendo o editorial juntamente com o ChatGPT		0	APPLICATION		Opportunity			No
Mixed_Annotators	Revista Interdisciplinar de Marketing	[{'authorId': None, 'name': 'SalomÃ£o Alencar de Farias'}]	PÃ¢nico na Academia! InteligÃªncia Artificial na ConstruÃ§Ã£o de Textos CientÃ­ficos Com o Uso do ChatGPT	A inteligÃªncia artificial (IA) por meio do ChatGPT ganhou os noticiÃ¡rios nas Ãºltimas semanas. O meio acadÃªmico gerou ruido com as consequÃªncias negativas do uso dessa ferramenta na construÃ§Ã£o de artigos cientÃ­ficos, dissertaÃ§Ãµes e teses. Aqui fizemos uso desta ferramenta elaborando um texto sobre o papel do marketing em tempos de ataques a democracia no Brasil. O ChatGPT faz com que questÃµes Ã©ticas, de inovaÃ§Ã£o e autoria sejam questionadas. Como serÃ¡ o futuro da escrita acadÃªmica. Estamos diante de um aliado ou de um inimigo?	0	APPLICATION		NAN			No
Mixed_Annotators	Science	[{'authorId': '2003404994', 'name': 'H. Thorp'}]	ChatGPT is fun, but not an author	In less than 2 months, the artificial intelligence (AI) program ChatGPT has become a cultural sensation. It is freely accessible through a web portal created by the toolâ€™s developer, OpenAI. The programâ€”which automatically creates text based on written promptsâ€”is so popular that itâ€™s likely to be â€œat capacity right nowâ€ if you attempt to use it. When you do get through, ChatGPT provides endless entertainment. I asked it to rewrite the first scene of the classic American play Death of a Salesman, but to feature Princess Elsa from the animated movie Frozen as the main character instead of Willy Loman. The output was an amusing conversation in which Elsaâ€”who has come home from a tough day of sellingâ€”is told by her son Happy, â€œCome on, Mom. Youâ€™re Elsa from Frozen. You have ice powers and youâ€™re a queen. Youâ€™re unstoppable.â€ Mash-ups like this are certainly fun, but there are serious implications for generative AI programs like ChatGPT in science and academia.	3	APPLICATION	WRITING	Mixed			No
Mixed_Annotators	Seeds of Science	[{'authorId': '2073872541', 'name': 'S. Buck'}]	Why Proposal Review Should Be More Like Meteorology	The process of evaluating research proposals for funding is often based on subjective assessments of the "goodness" or "badness" of a proposal. However, this method of evaluation is not precise and does not provide a common language for reviewers to communicate with each other. In this paper, we propose that science funding agencies ask reviewers to assign quantitative probabilities to the likelihood of a proposal reaching a particular milestone or achieving technical goals. This approach would encourage reviewers to be more precise in their evaluations and could improve both agency-wide and individual reviewer calibration over time. Additionally, this method would allow funding agencies to identify skilled reviewers and allow reviewers to improve their own performance through consistent feedback. While this method may not be suitable for all types of research, it has the potential to enhance proposal review in a variety of fields. [abstract generated by ChatGPT]	0	REST		NAN			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '30528739', 'name': 'Ã–mer AydÄ±n'}, {'authorId': '40631192', 'name': 'Enis Karaarslan'}]	OpenAI ChatGPT Generated Literature Review: Digital Twin in Healthcare	Literature review articles are essential to summarise the related  work in the selected field. However, covering all related studies takes  too much time and effort. This study questions how Artificial  Intelligence can be used in this process. We used ChatGPT to create a  literature review article to show the stage of the OpenAI ChatGPT  artificial intelligence application. As the subject, the applications of  Digital Twin in the health field were chosen. Abstracts of the last  three years (2020, 2021 and 2022) papers were obtained from the keyword  "Digital twin in healthcare" search results on Google Scholar and  paraphrased by ChatGPT. Later on, we asked ChatGPT questions. The  results are promising; however, the paraphrased parts had significant  matches when checked with the Ithenticate tool. This article is the  first attempt to show the compilation and expression of knowledge will  be accelerated with the help of artificial intelligence. We are still at  the beginning of such advances. The future academic publishing process  will require less human effort, which in turn will allow academics to  focus on their studies. In future studies, we will monitor citations to  this study to evaluate the academic validity of the content produced by  the ChatGPT 	4	APPLICATION	WRITING	Opportunity			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '152475512', 'name': 'X. Zhai'}]	ChatGPT User Experience: Implications for Education	ChatGPT, a general-purpose conversation chatbot released on November  30, 2022, by OpenAI, is expected to impact every aspect of society.  However, the potential impacts of this NLP tool on education remain  unknown. Such impact can be enormous as the capacity of ChatGPT may  drive changes to educational learning goals, learning activities, and  assessment and evaluation practices. This study was conducted by  piloting ChatGPT to write an academic paper, titled Artificial  Intelligence for Education (see Appendix A). The piloting result  suggests that ChatGPT is able to help researchers write a paper that is  coherent, (partially) accurate, informative, and systematic. The writing  is extremely efficient (2-3 hours) and involves very limited  professional knowledge from the author. Drawing upon the user  experience, I reflect on the potential impacts of ChatGPT, as well as  similar AI tools, on education. The paper concludes by suggesting  adjusting learning goals—students should be able to use AI tools to  conduct subject-domain tasks and education should focus on improving  students’ creativity and critical thinking rather than general skills.  To accomplish the learning goals, researchers should design AI-involved  learning tasks to engage students in solving real-world problems.  ChatGPT also raises concerns that students may outsource assessment  tasks. This paper concludes that new formats of assessments are needed  to focus on creativity and critical thinking that AI cannot substitute. 	4	APPLICATION	WRITING	Opportunity			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '100569753', 'name': 'K. Wenzlaff'}, {'authorId': '1749307', 'name': 'S. Spaeth'}]	Smarter than Humans? Validating how OpenAIâ€™s ChatGPT Model Explains Crowdfunding, Alternative Finance and Community Finance	The ChatGPT model of OpenAI allows users to ask questions, which are  answered through an artificial intelligence trained through supervised,  reinforced machine-learning. The answers depend on the input which the  algorithm receives from the users, as well as from the content it has  been given. The paper explores how answers to definitions about  crowdfunding, alternative finance and community finance deviate or  correspond to answers given by real human-beings in academic  scholarship. Crowdfunding, alternative finance and community finance are  chosen because academic literature does not provide consistent  definitions on each of these terms, but some definitions are accepted by  more scholars. By addressing the research gap concerning the accuracy  of answers generated by an artificial intelligence, the paper  contributes to the growing literature of implications of textual  artificial intelligence on academia. 	0	APPLICATION	Definitions	NAN			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '2041888108', 'name': 'M. M. Alshater'}]	Exploring the Role of Artificial Intelligence in Enhancing Academic Performance: A Case Study of ChatGPT	This study aims to explore the potential of artificial intelligence,  particularly natural language processing, in enhancing academic  performance using economics and finance as an illustrative example. The  study employs a case study approach, using ChatGPT as a specific example  of an NLP tool that has the potential to advance research. Our analysis  of ChatGPT's applications, capabilities, and limitations revealed that  it has the potential to significantly enhance academic research in  general and economics and finance in particular. ChatGPT and other AI  tools can assist researchers in data analysis and interpretation,  scenario generation, and communication of findings. However, there are  several limitations to consider when using chatbots or similar tools in  research, including generalizability, dependence on data quality and  diversity, lack of domain expertise, limited ability to understand  context, ethical considerations, and limited ability to generate  original insights. It is therefore important to carefully consider these  limitations when using ChatGPT and to use it in conjunction with human  analysis and interpretation. 	4	APPLICATION		Opportunity			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '39697129', 'name': 'Jochen Hartmann'}, {'authorId': '2004368787', 'name': 'Jasper Schwenzow'}, {'authorId': '94737364', 'name': 'Maximilian Witte'}]	The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation	Conversational artificial intelligence (AI) disrupts how humans interact with technology. Recently, OpenAI introduced ChatGPT, a state-of-the-art dialogue model that can converse with its human counterparts with unprecedented capabilities. ChatGPT has witnessed tremendous attention from the media, academia, industry, and the general public, attracting more than a million users within days of its release. However, its explosive adoption for information search and as an automated decision aid underscores the importance to understand its limitations and biases. This paper focuses on one of democratic soci-etyâ€™s most important decision-making processes: political elections. Prompting ChatGPT with 630 political statements from two leading voting advice applications and the nation-agnostic political compass test in three pre-registered experiments, we uncover ChatGPTâ€™s pro-environmental, left-libertarian ideology. For example, ChatGPT would impose taxes on flights, re-strict rent increases, and legalize abortion. In the 2021 elections, it would have voted most likely for the Greens both in Germany (BÃ¼ndnis 90/Die GrÃ¼nen) and in the Netherlands (Groen-Links). Our findings are robust when negating the prompts, reversing the order of the statements, varying prompt formality, and across languages (English, German, Dutch, and Spanish). We conclude by discussing the implications of politically biased conversational AI on society.	0	ETHICS		Mixed	English, German, Dutch, Spanish		Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '46308962', 'name': 'Jonathan H. Choi'}, {'authorId': '98900189', 'name': 'Kristin E. Hickman'}, {'authorId': '16166682', 'name': 'Amy B. Monahan'}, {'authorId': '83686718', 'name': 'D. Schwarcz'}]	ChatGPT Goes to Law School	How well can AI models write law school exams without human assistance? To find out, we used the widely publicized AI model ChatGPT to generate answers on four real exams at the University of Minnesota Law School. We then blindly graded these exams as part of our regular grading processes for each class. Over 95 multiple choice questions and 12 essay questions, ChatGPT performed on average at the level of a C+ student, achieving a low but passing grade in all four courses. After detailing these results, we discuss their implications for legal education and lawyering. We also provide example prompts and advice on how ChatGPT can assist with legal writing.	4	EDUCATION		NAN			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '120912545', 'name': 'Leah M. Bishop'}]	A Computer Wrote this Paper: What ChatGPT Means for Education, Research, and Writing	Of particular interest to educators, an exploration of what new language-generation software does (and does not) do well. Argues that the new language-generation models make instruction in writing mechanics irrelevant, and that educators should shift to teaching only the more advanced writing skills that reflect and advance critical thinking. The difference between mechanical and advanced writing is illustrated through a "Socratic Dialogue" with ChatGPT. Appropriate for classroom discussion at High School, College, Professional, and PhD levels.	4	EDUCATION	WRITING	Opportunity			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '72433942', 'name': 'R. J. Ventayen'}]	OpenAI ChatGPT Generated Results: Similarity Index of Artificial Intelligence-Based Contents	A recently developed artificial intelligence (AI) model to execute  high-level cognitive tasks known as ChatGPT has been popular over the  last months in the academic community. The feature raises questions  regarding how ChatGPT may be used for academic dishonesty for students  who generate essays and topics. The study discovered that ChatGPT poses a  potential risk to the integrity of essay submissions, particularly in  higher education settings where such requirements are standard. This  study will check the similarity index of ChatGPT-generated results using  Ouriginal by Turnitin and running in a paraphrasing tool. Research  paper titles published by Pangasinan State University authors will be  used in the chat session using ChatGPT. Results show that the generated  results' similarity index passed the institution's required similarity  index, which might threaten academic integrity. The institution may  update its assessment methodology to avoid using such a model for  cheating. 	4	EDUCATION	ETHICS	Threat			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '1423468758', 'name': 'Rupert Macey-Dare'}]	ChatGPT & Generative AI Systems as Quasi-Expert Legal Advice Lawyers - Case Study Considering Potential Appeal Against Conviction of Tom Hayes	(Or “How long before you are replaced by an AI robolawyer- new evidence  from ChatGPT? Answer- Soon and much sooner than you think.”)  In  this paper, OpenAI’s latest ChatGPT system is prompted by simple  questions from RMD to produce indicative AI-generated quasi-expert legal  advice below on a topical prospective real test case in the news,  namely on the pros and cons of and required steps for any proposed  appeal against his conviction in the United Kingdom of Libor trader Tom  Hayes.   Arguably ChatGPT’s advice performance presented below  speaks clearly for itself and illustrates the huge, burgeoning power and  potential of generative AI systems, particularly the next generation,  which will also have access to and training on large legal caselaw and  legal analysis and legislation databases, to produce increasingly high  quality quasi-expert legal advice, and so to augment and replace much  more expensive junior, mid-range, and ultimately senior advisory expert  lawyers, in advising client legal advice consumers, and in preparing and  even delivering sophisticated courtroom submissions.   The  predicted timeframe for this process to run to fruition, driven both by  technology and computational advances, and by market cost and profit  incentives, is alarmingly fast and potentially within the next decade.  The  predicted shorter term consequences are that ChatGPT and similar  generative AI systems will be increasingly used and will take up  increasingly dominant roles in law cases and law teams, which in turn  means that human law team membership and numbers are likely to shrink,  and with those remaining human members left, being more knowledgeable,  older and more expert, on average than now, and with a reduced flow of  introductory training work for and demand and remuneration for new and  younger human lawyers. Thus the advent of systems like ChatGPT and its  successors are likely to bring huge negative technological and value  shocks on average to lawyers and the legal profession, but huge  corresponding positive technological and value shocks on average to  legal consumers and society overall.  ChatGDP now makes the  following introductory comments about itself, this case study in  particular, and about its own potential to offer quasi-expert legal  advice:   “I am ChatGPT, a powerful AI system that can assist and  replace expert human lawyers in providing expert advice on specific  legal problems and legal questions, by providing accurate and fast  information and research, as well as automating repetitive tasks. I am  an artificial intelligence system that uses machine learning algorithms  to generate human-like text. One of the applications of my technology is  providing expert advice on specific legal problems and legal  questions."  "In this article, ChatGPT and RMD  provide a detailed  analysis of the Libor-rigging case of USA v Connolly and Black, and  consider the implications of this case for Tom Hayes' conviction. They  argue that the recent case raises serious questions about the evidence  that was used to convict Tom Hayes, and suggest that there may be  grounds for a retrial."	4	APPLICATION	LEGAL ADVICE	Mixed			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '14936984', 'name': 'Boniphace Kutela'}, {'authorId': '2204047232', 'name': 'Kelvin Msechu'}, {'authorId': '2109619283', 'name': 'Subasish Das'}, {'authorId': '51057895', 'name': 'E. Kidando'}]	Chatgpt's Scientific Writings: A Case Study on Traffic Safety	The use of advanced language models, such as ChatGPT, is emerging in various fields. Such models can assist students with homework, help prepare business plans, write code, and even create surveys. It has also been found that these programs can even generate fake abstracts and manuscripts. To understand the future of scientific writing in the era of ChatGPT, it is important to explore ChatGPT and human-generated texts for manuscript preparation. This study aimed to evaluate the capability of ChatGPT to prepare a manuscript for publication by comparing its output with actual published content using supervised and unsupervised text mining approaches. This study used the introduction sections of 327 published articles on traffic safety. To obtain the ChatGPT-generated introduction section, a prompt with instructions and the title of 327 manuscripts was supplied to ChatGPT. Five supervised text classifiers, Support Vector Machine (SVM), Random Forest (RF), Naive Bayes (NB), Logitboost, and Neural Network (NNet), were applied to classify human-generated versus ChatGPT-generated introductions. Two unsupervised approaches, Text Network Analysis (TNA) and Text Cluster, were used to identify the difference in textual contents in human-generated and ChatGPT-generated introductions. Results indicate a significant disparity between human-generated and ChatGPT-generated introductions. The accuracy of the supervised text classifiers ranged between 96.4% and 99.5%; SVM, RF, and NNet performed have higher precision. The key features from SVM, RF, and NNet indicated more generic keywords with small variations across the classifiers. The results from the topmost frequent keywords showed a great variation of keywords for the ChatGPT and human-generated texts. Furthermore, the cluster analysis results indicated key clusters that are only observed in ChatGPT-generated introductions but not in human-generated introductions, and vice versa. The findings from this study can contribute to understanding the broader perspective of using advanced language models in scientific writing.	2	APPLICATION	WRITING	NAN			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '3195738', 'name': 'W. Benzon'}]	Discursive Competence in ChatGPT, Part 1: Talking with Dragons	Taken together, Noam Chomsky’s idea of linguistic competence and  David Marr’s conception of three levels of analysis for information  systems, suggest a new approach to understanding how LLMs work. This  approach requires careful analysis of text. Such analysis indicates that  ChatGPT has explicit control over sophisticated discourse skills: 1) It  possesses the capacity to specify high-level structures that regulate  the organization of language strings into specific patterns: e.g.  conversational turn-taking, story frames, film interpretation, and  metalingual definition of abstract concepts. 2) It is capable of  analogical reasoning in the interpretation of films and stories, such as  Spielberg’s Jaws and A.I., and Tezuka’s Astro Boy stories. It must  establish an analogy between some abstract interpretive theory (e.g. the  ideas of Rene Girard) and people and events in a story. 3) It has some  understanding of abstract concepts such as justice and charity. Such  concepts can be defined over concepts that exhibit them (metalingual  definition). ChatGPT recognizes suitable stories and can revise them. 4)  ChatGPT can adjust its level of discourse to accommodate children of  various ages. Finally, much of ChatGPT’s discourse seems formulaic in a  way similar to what Parry/Lord found in oral epic. 	5	APPLICATION	WRITING	NAN			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '120912545', 'name': 'Leah M. Bishop'}]	Can ChatGPT 'Think Like a Lawyer?' A Socratic Dialogue	A witty socratic dialogue with a language-generation model, exploring the aims of legal education in the new era of machine writing.	0	EDUCATION	LEGAL DOMAIN	NAN			No
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '30528739', 'name': 'Ã–mer AydÄ±n'}, {'authorId': '40631192', 'name': 'Enis Karaarslan'}]	Is ChatGPT Leading Generative AI? What is Beyond Expectations?	Generative AI has the potential to change the way we do things in many areas. The chatbot is one of the popular implementation areas. Even though Google and Meta had chatbots, ChatGPT became popular as its language models were publicly available. It was widely used; people from different fields, ages, and education levels started using ChatGPT. Although ChatGPT is still in the early stages of its development, it has managed to attract the attention of people and capital groups. There have been many comments and trials with ChatGPT. It is possible to see a lot of news and shares, especially on social media and other platforms on the internet. It started to become clear the things that the people were asking ChatGPT and what it was trying to get it to do. At the same time, we can make an inference from the responses of ChatGPT to these requests and the capabilities of ChatGPT. The purpose of this study is to shed light on what is happening in the literature, and people's expectations of ChatGPT and Generative AI. We also emphasize in this study that there are strong candidates such as Google’s Bard AI, Claude, and Meta’s Wit.ai and etc. that can be a rival to ChatGPT. We give some technical and structural comparisons to predict who will win the race between these strong candidates and ChatGPT. In this study, we share the early stage due diligence and current situation analysis for all these points. For this, we examined preprint papers and published articles. We also included striking posts on the LinkedIn platform, where most professionals are present. In addition, we have created a compilation of various blogs and news. We also made use of ChatGPT in editing the content of some of the titles of this study.	0	REST	Meta	NAN			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '120966380', 'name': 'Hashem Alshurafat'}]	The Usefulness and Challenges of Chatbots for Accounting Professionals: Application On ChatGPT	This paper explores the usefulness and challenges of ChatGPT for accounting professionals. As technology continues to impact a range of industries, the field of accounting is no exception. ChatGPT, a language model developed by OpenAI, has the potential to revolutionize the way that accounting professionals work, providing improved efficiency, increased productivity, and valuable insights. However, the successful implementation of ChatGPT in accounting also requires consideration of a range of challenges, including integration with existing systems and processes, data privacy and security concerns, ensuring accuracy and consistency in responses, and managing customer expectations and trust. Additionally, balancing the role of technology with human expertise, keeping up with changing regulations and standards, ensuring chatbot availability and reliability, providing training and support for users, and addressing the potential for job displacement must be considered. This paper provides a comprehensive overview of the usefulness and challenges of ChatGPT for accounting professionals, providing valuable insights and recommendations for the successful implementation of this technology in the field of accounting.	4	APPLICATION	ACCOUNTING	Opportunity			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '1411783122', 'name': 'David Baidoo-Anu'}, {'authorId': '2203232571', 'name': 'Leticia Owusu Ansah'}]	Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning	Since its maiden release into the public domain on November 30, 2022, ChatGPT garnered more than one million subscribers within a week. The generative AI tool⎼ ChatGPT took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of ChatGPT to perform complex tasks within the field of education has caused mixed feelings among educators as this advancement in AI seems to revolutionize existing educational praxis. This review article synthesizes recent extant literature to offer some potential benefits of ChatGPT in promoting teaching and learning. Benefits of ChatGPT include but are not limited to promotion of personalized and interactive learning, formative assessment practices etc. The paper also highlights some inherent limitations in the ChatGPT such generating wrong information, biases in data training which may accentuate existing biases, privacy issues etc. The study offers recommendations on how ChatGPT could be leveraged to maximize teaching and learning. Policy makers, researchers, educators and technology experts could work together and start conversations on how these evolving generative AI tools could be used safely and constructively to improve education and support students’ learning.	4	EDUCATION		Opportunity			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '2204312702', 'name': 'Thomas Yue'}, {'authorId': '2187372354', 'name': 'David Au'}, {'authorId': '2204329476', 'name': 'Chi Chung Au'}, {'authorId': '92809033', 'name': 'Kwansai Iu'}]	Democratizing Financial Knowledge with ChatGPT by OpenAI: Unleashing the Power of Technology	This paper discusses the potential of using Explainable AI (XAI) and  language models, such as ChatGPT, in revolutionizing the communication  of financial knowledge to non-financial professionals. We tested the  capabilities of ChatGPT in interpreting XAI models and explaining  complex financial concepts in a non-technical manner. The results show  that ChatGPT has great potential as a tool for making complex financial  concepts accessible to a wide range of target audiences. To the best of  the authors’ knowledge, we are the first to present an approach to  combine the method of Explainable AI (XAI) using SHAP with a  conversational AI model, ChatGPT, to explain the predictions made by a  nonlinear black box machine learning model in Finance. This paper also  identifies the limitations of ChatGPT for explaining model predictions,  but it is expected that the improvement of the prompt engineering aspect  of the model will overcome these limitations. Ultimately, the use of  ChatGPT has the potential to level the playing field and empower all  individuals, regardless of their financial background, to make informed  investment decisions. 	4	APPLICATION	FINANCE	Opportunity			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '66673215', 'name': 'B. Lund'}, {'authorId': '2203795113', 'name': 'Wang Ting'}]	Chatting about ChatGPT: How May AI and GPT Impact Academia and Libraries?	This paper provides an overview of key definitions related to  ChatGPT, a public tool developed by OpenAI, and its underlying  technology, GPT. The paper discusses the history and technology of GPT,  including its generative pre-trained transformer model, its ability to  perform a wide range of language-based tasks, and how ChatGPT utilizes  this technology to function as a sophisticated chatbot. Additionally,  the paper includes an interview with ChatGPT on its potential impact on  academia and libraries. The interview discusses the benefits of ChatGPT  such as improving search and discovery, reference and information  services, cataloging and metadata generation, and content creation, as  well as the ethical considerations that need to be taken into account,  such as privacy and bias. The paper also explores the possibility of  using ChatGPT for writing scholarly papers. 	0	REST		Opportunity			Yes
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '71936868', 'name': 'Saima Nisar'}, {'authorId': '2057319891', 'name': 'Muhammad Shahzad Aslam'}]	Is ChatGPT a Good Tool for T&CM Students in Studying Pharmacology?	Although artificial intelligence (AI) is becoming more and more prevalent in education, yet its patterns, problems with current research, and potential applications are still largely unexplored. ChatGPT is AI based platform, developed by AI research and deployment company, known as OpenAI. Users may submit text instructions into ChatGPT, and it will quickly produce text answers using the information it has gleaned through using machine learning to interact with the internet. The objective of current study is to test ChatGPT by asking student centric medical questions in the field of pharmacology and determine its relevancy in self-studying the subject so that students can use to enhance their learning experience. The questions were asked in the different domain of drug’s pharmacokinetics, mechanism of action, clinical uses, adverse effect, contraindications and drug-drug interactions. The answer given by ChatGPT were relevant and accurate, however the reference or source of answers were not given. The tool can used as quick reference and self-studying instrument for traditional and complementary medicine students (T&CM) who face difficulty in studying pharmacology. 	4	Medical	Education	Opportunity			TRUE
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '3195738', 'name': 'W. Benzon'}]	ChatGPT Intimates a Tantalizing Future; Its core LLM is Organized on Multiple Levels; and it has Broken the Idea of Thinking, Version 2	I make three arguments. A philosophical argument: (1) The behavior of  ChatGPT is so sophisticated that the ordinary concept of thinking is no  longer useful in distinguishing between human behavior and the  ChatGPT’s behavior. We don’t have explicit understanding about what  either humans or ChatGPT are doing. Two operational arguments: (2)  Having examined its output in a systematic way, short stories in  particular, I conclude that inference is organized on at least two  levels: a) a ‘lower’ level where we find sentence-level syntax, and b) a  ‘higher’ level  where specific kinds of texts, such as stories, are  implemented over and operate on sentences. This is roughly analogous to  the way that high-level programming languages are implemented in  assembly code. (3) Consequently, that aspects of full symbolic  computation are latent in LLMs. An appendix has descriptive tables  showing how four stories are organized on multiple levels. 	5	Evaluation	Ethic	Opportunity			TRUE
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '119376922', 'name': 'Md. Saidur Rahaman'}, {'authorId': None, 'name': 'M. M. Tahmid Ahsan'}, {'authorId': None, 'name': 'Nishath Anjum'}, {'authorId': None, 'name': 'Md. Mizanur Rahman'}, {'authorId': None, 'name': 'Md Nafizur Rahman'}]	The AI Race is on! Google's Bard and Openai's Chatgpt Head to Head: An Opinion Article	Two prominent Artificial Intelligence (AI) competitors, Google's Bard, run by Language Model for Dialogue Applications (LaMDA) and OpenAI's Chat Generative Pre-trained Transformer (ChatGPT), compete for supremacy in the market. LaMDA is a transformer-based neural language model pre-trained on online chat data. ChatGPT, on the other hand, is built on the GPT-3.5 architecture and incorporates a reinforcement learning model with human feedback. While Google's Bard is not yet available to the public, its search engine income has increased. ChatGPT, on the other hand, streamlines business, finance, marketing, entrepreneurship, accounting, education, healthcare, and many other operations rapidly. Who will win yet? Time will answer, but both companies are working hard to keep up with the AI revolution.	5	Evaluation		Opportunity			TRUE
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '2000639769', 'name': 'Brady D. Lund'}, {'authorId': '75067375', 'name': 'Daniel A. Agbaji'}]	Information Literacy, Data Literacy, Privacy Literacy, and ChatGPT: Technology Literacies Align with Perspectives on Emerging Technology Adoption within Communities	This study investigates the relationships between three crucial literacies for the digital world - information literacy, data literacy, and privacy literacy - and pos-itivity towards emerging technology adoption within communities, specifically the chatbot ChatGPT. Data was collected through web-based surveys of adults living in a four-county area in northern Texas over a two-week period in late 2022, resulting in 130 valid responses. Regression analysis shows that interest in using ChatGPT to improve one's community is positively related to information literacy and privacy literacy skills, but not significantly related to data literacy skills, which is unexpected given ChatGPT's status as a data science innovation. Age, gender, educational attainment, and Internet usage are also factors that in-fluence these relationships. These findings are significant for understanding how various literacies and personal and community-based factors influence each oth-er's development.	4	Education		Mixed			TRUE
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '104406084', 'name': 'Adam Zaremba'}, {'authorId': '16775568', 'name': 'Ender Demir'}]	ChatGPT: Unlocking the Future of NLP in Finance	This paper reviews the current state of ChatGPT technology in finance and its potential to improve existing NLP-based financial applications. We discuss the ethical and regulatory considerations, as well as potential future research directions in the field. The literature suggests that ChatGPT has the potential to improve NLP-based financial applications, but also raises ethical and regulatory concerns that need to be addressed. The paper highlights the need for research in robustness, interpretability, and ethical considerations to ensure responsible use of ChatGPT technology in finance.  	5	Education		Mixed			TRUE
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '92809033', 'name': 'Kwansai Iu'}, {'authorId': '2190336752', 'name': 'Vanessa Man-Yi Wong'}]	ChatGPT by OpenAI: The End of Litigation Lawyers?	ChatGPT, a revolutionary AI language model developed by OpenAI, can understand instructions with unprecedented efficiency. This study aims to evaluate the extent to which ChatGPT can potentially serve as a replacement for litigation lawyers through an examination of its drafting and research capabilities. The results indicate that ChatGPT has advanced legal drafting skills for various types of documents, including demand letters, without-prejudice letters, and pleadings. ChatGPT was able to elaborate and enhance the contents based on the simple facts inputted into the system and demonstrated the ability to understand simple facts and articulate the legal basis of the claim. Additionally, ChatGPT can identify legal strategies, draft a summary judgment, generate a skeleton argument, conduct cross-examination, and provide simple legal advice. The results also reveal that ChatGPT performed excellently in analysing a more complicated case. However, there were limitations in the data sources used in ChatGPT, which resulted in a weakness in identifying recent case law. At this stage, the paper suggests that ChatGPT should be viewed as a supplement, rather than a replacement, to litigation lawyers.	4	Evaluation	Application	Mixed			TRUE
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '14786067', 'name': 'Jurgen Willems'}]	ChatGPT at Universities â€“ The Least of Our Concerns	When Nature reports on a vivid debate in the scientific community that ChatGPT recently occurred as a co-author on scientific articles (Stokel-Walker, 2023), we know what time it is: ...	5	Rest		Threat			FALSE
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '2174089984', 'name': 'Ashley B. Armstrong'}]	Whoâ€™s Afraid of ChatGPT? An Examination of ChatGPTâ€™s Implications for Legal Writing	Law school legal writing courses teach students a variety of skills, including legal research, analysis, writing, and citation. These courses also often include discussion about professional responsibility in the practice of law. On November 30, 2022, OpenAI launched ChatGPT (Chat Generative Pre-trained Transformer). ChatGPT is an Artificial Intelligence interface that can generate human-like text in response to user queries. This Article explores ChatGPT’s implications for legal writing.  One long, thrilling afternoon, this author asked ChatGPT to perform a series of common legal research and writing tasks. Responses to some tasks were fairly impressive, while others completely missed the mark. This Article charts the hazards and opportunities of ChatGPT by focusing on what it “knows” about the law and its limitations—not only its inability to conduct effective legal research, but also its capacity for confidently producing responses that cite incorrect (often made-up) case law and statutes. Additionally, this Article tests ChatGPT’s writing ability: Can ChatGPT write in the formal legal writing structure that is taught in law schools (i.e., CREAC, IRAC, TRAC, etc.?) The Article shares insights from testing ChatGPT through “conversation” and analyzing its responses—both for accuracy and big picture takeaways about its current (in)abilities.  In addition to studying ChatGPT’s legal research and writing abilities, this Article also highlights some of the ethical hazards of relying on ChatGPT in practice. For instance, its potential for inaccuracy (and its actual, false answers) raises concerns about Model Rules of Professional Conduct 1.1, 1.3, 2.1, 3.3, and 4.1. Furthermore, depending on how ChatGPT is leveraged by attorneys, its use could violate the duty to protect client confidentiality (Rule 1.6).  More than just a cautionary tale, this Article also provides insight about how legal writing professors and law students might (effectively and ethically) use ChatGPT as a tool for certain tasks. For example, in the author’s experience, ChatGPT was able to identify logical flaws in contract clauses and could be a promising learning tool when teaching contract analysis. It also was able to create prompts and fact patterns for legal writing assignments, among exciting other uses.  This Article is a snapshot in time and a springboard for additional research about artificial intelligence’s (ever-evolving) implications for legal writing.	3	Evaluation		Mixed			TRUE
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '2204929112', 'name': 'Tammy Pettinato Oltz'}]	ChatGPT, Professor of Law	Although ChatGPT was just released by OpenAI in November 2022, legal scholars have already been delving into the implications of the new tool for legal education and the legal profession. Several scholars have recently written fascinating pieces examining ChatGPT’s ability to pass the bar, write a law review article, create legal documents, or pass a law school exam. In the spirit of those experiments, I decided to see whether ChatGPT had potential for lightening the service and teaching loads of law school professors.  To conduct my experiment, I created an imaginary law school professor with a tough but typical week of teaching- and service- related tasks ahead of her. I chose seven common tasks: creating a practice exam question, designing a hand-out for a class, writing a letter of recommendation, submitting a biography for a speaking engagement, writing opening remarks for a symposium, developing a document for a law school committee, and designing a syllabus for a new course. I then ran prompts for each task through ChatGPT to see how well the system performed the tasks.  Remarkably, ChatGPT was able to provide useable first drafts for six out of seven of the tasks assigned in only 23 minutes. Overall and unsurprisingly, ChatGPT proved to be best at those tasks that are most routine. Tasks that require more sophistication, particularly those related to teaching, were harder for ChatGPT, but still showed potential for time savings.  In this paper, I describe a typical work scenario for a hypothetical law professor, show how she might use ChatGPT, and analyze the results. I conclude that ChatGPT can drastically reduce the service-related workload of law school faculty and can also shave off time on back-end teaching tasks. This freed-up time could be used to either enhance scholarly productivity or further develop more sophisticated teaching skills.	4	AppliCATION		Opportunity			TRUE
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '49095886', 'name': 'P. Hacker'}]	The European AI Liability Directives - Critique of a Half-Hearted Approach and Lessons for the Future	The optimal liability framework for AI systems remains an unsolved problem across the globe. With ChatGPT and other large models taking the technology to the next level, solutions are urgently needed. In a much-anticipated move, the European Commission advanced two proposals outlining the European approach to AI liability in September 2022: a novel AI Liability Directive (AILD) and a revision of the Product Liability Directive (PLD). They constitute the final cornerstone of AI regulation in the EU. Crucially, the liability proposals and the AI Act are inherently intertwined: the latter does not contain any individual rights of affected persons, and the former lack specific, substantive rules on AI development and deployment. Taken together, these acts may well trigger a â€œBrussels effectâ€ in AI regulation, with significant consequences for the US and other countries. Against this background, this paper makes three novel contributions. First, it examines in detail the Commission proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted as foreseen, AI liability in the EU will primarily rest on disclosure of evidence mechanisms and a set of narrowly defined presumptions concerning fault, defectiveness and causality. Hence, second, the article makes suggestions for amendments to the proposed AI liability framework. They are collected in a concise Annex at the end of the paper. I argue, inter alia, that the dichotomy between the fault-based AILD Proposal and the supposedly strict liability PLD Proposal is fictional and should be abandoned; that an EU framework for AI liability should comprise one fully harmonizing regulation instead of two insufficiently coordinated directives; and that the current proposals unjustifiably collapse fundamental distinctions between social and individual risk by equating high-risk AI systems in the AI Act with those under the liability framework. Third, based on an analysis of the key risks AI poses, the final part of the paper maps out a road for the future of AI liability and regulation, in the EU and beyond. More specifically, I make four key proposals. Effective compensation should be ensured by combining truly strict liability for certain high-risk AI systems with general presumptions of defectiveness, fault and causality in cases involving SMEs or non-high-risk AI systems. The paper introduces a novel distinction between illegitimateand legitimate-harm models to delineate strict liabilityâ€™s scope. Truly strict liability should be reserved for high-risk AI systems that, from a social perspective, should not cause harm (illegitimate-harm models, e.g., autonomous vehicles or medical AI). Models meant to cause some unavoidable harm by ranking and rejecting individuals (legitimate-harm models, e.g., credit scoring or insurance scoring) may only face rebuttable presumptions of defectiveness and causality. General-purpose AI systems should only be subjected to high-risk * Professor Dr. Philipp Hacker, LL.M. (Yale), Chair for Law and Ethics of the Digital Society, European New School of Digital Studies, European University Viadrina. I am grateful for comments by Maximilian Eber, Andreas Engel, Rasmus Rothe, and Sandra Wachter. My team provided excellent research assistance, particularly Sarah GroÃŸheim and Marco Mauer. II regulation, including liability for high-risk AI systems, in specific high-risk use cases for which they are deployed. Consumers ought to be liable based on regular fault, in general. Furthermore, innovation and legal certainty should be fostered through a comprehensive regime of safe harbours, defined quantitatively to the best extent possible. Moreover, trustworthy AI remains an important goal for AI regulation. Hence, the liability framework must specifically extend to non-discrimination cases and provide for clear rules concerning explainability (XAI). Finally, awareness for the climate effects of AI, and digital technology more broadly, is rapidly growing in computer science. In diametrical opposition to this shift in discourse and understanding, however, EU legislators thoroughly neglect environmental sustainability in both the AI Act and the proposed liability regime. To counter this, I propose to jump-start sustainable AI regulation via sustainability impact assessments in the AI Act and sustainable design defects in the liability regime. In this way, the law may help spur not only fair AI and XAI, but potentially also sustainable AI (SAI).	0	Rest		Threat			FALSE
Mixed_Annotators	SSRN Electronic Journal	[{'authorId': '2197932431', 'name': "Open AI's Assistant ChatGPT"}, {'authorId': '50350095', 'name': 'Andrew M. Perlman'}]	The Implications of OpenAIâ€™s Assistant for Legal Services and Society	On November 30, 2022, OpenAI released a chatbot called ChatGPT. To demonstrate the chatbot’s remarkable sophistication and its potential implications, both for legal services and society more generally, a human author generated this paper in about an hour through prompts within ChatGPT. Only this abstract, the outline headers, the epilogue, and the prompts were written by a person. ChatGPT generated the rest of the text with no human editing.  To be clear, the responses generated by ChatGPT were imperfect and at times problematic, and the use of an AI tool for law-related services raises a host of regulatory and ethical issues. At the same time, ChatGPT highlights the promise of artificial intelligence, including its ability to affect our lives in both modest and more profound ways. ChatGPT suggests an imminent reimagination of how we access and create information, obtain legal and other services, and prepare people for their careers. We also will soon face new questions about the role of knowledge workers in society, the attribution of work (e.g., determining when people’s written work is their own), and the potential misuse of and excessive reliance on the information produced by these kinds of tools.  The disruptions from AI’s rapid development are no longer in the distant future. They have arrived, and this document offers a small taste of what lies ahead.	4	Application	Writing	Opportunity			TRUE
Mixed_Annotators	Stem Cell Reports	[{'authorId': '3284810', 'name': 'P. Cahan'}, {'authorId': '5746516', 'name': 'B. Treutlein'}]	A conversation with ChatGPT on the role of computational systems biology in stem cell research		0	Medical		NaN			FALSE
Mixed_Annotators	Telecommunications Systems	[{'authorId': '2115776021', 'name': 'Muhammad Khurram Khan'}]	AI-enabled transformations in telecommunications industry	Artificial intelligence (AI) is making a significant impact in our rapidly evolving world. It is no longer science fiction and is transforming and disrupting all walks of life. The recent launch of ChatGPT is a clear manifestation that AI is moving beyond the hype. As we usher in the fifth industrial revolution (5IR), where humans and machines will work in greater harmony and synergy to create a better planet, AI is expected to create new realities filled with a variety of unprecedented opportunities.	5	Rest		Opportunity			FALSE
Mixed_Annotators	The journal of cognitive systems	[{'authorId': '120795838', 'name': 'Oguzhan Topsakal'}, {'authorId': '90799265', 'name': 'Elif Topsakal'}]	Framework for A Foreign Language Teaching Software for Children Utilizing AR, Voicebots and ChatGPT (Large Language Models)	The cognitive capabilities of children develop during the early years of their life. Research shows that learning a foreign language helps develop cognitive skills. Moreover, learning a foreign language has become essential and an increasing number of parents would like their kids to start learning a foreign language at an early age. However, engaging little kids with learning activities is challenging. In this study, we propose a framework for developing a language learning software tool utilizing Augmented Reality (AR), Voicebots, and ChatGPT (an AI utilizing the Large Language Model) technologies to provide a unique product for small kids to teach a foreign language. With AR and Voicebots, the product will grab attention, motivate and provide an entertaining learning environment. The capabilities of ChatGPT will be utilized to efficiently prepare the content for the software tool. We utilize the capabilities of ChatGPT to generate interactive dialogs that will be hosted at Google DialogFlow. We believe the framework and the design principles we propose in this study can be a blueprint for developing highly effective foreign language teaching software.	4	Education	Application	Opportunity			TRUE
Mixed_Annotators	The Lancet Digital Health	[{'authorId': '3622189', 'name': 'M. Liebrenz'}, {'authorId': '48348811', 'name': 'R. Schleifer'}, {'authorId': '3537371', 'name': 'A. Buadze'}, {'authorId': '3578748', 'name': 'D. Bhugra'}, {'authorId': '2116709192', 'name': 'Alexander Smith'}]	Generating scholarly content with ChatGPT: ethical challenges for medical publishing.		0	medical	education	NaN			FALSE
Mixed_Annotators	The Lancet Digital Health	[{'authorId': '1666213350', 'name': 'The Lancet Digital Health'}]	ChatGPT: friend or foe?		0	Ethics		NaN			FALSE
Mixed_Annotators	The Lancet Digital Health	[{'authorId': '2125627924', 'name': 'Sajan Patel'}, {'authorId': '2067721105', 'name': 'Kyle Lam'}]	ChatGPT: the future of discharge summaries?		0	Rest		NaN			FALSE
Mixed_Annotators	The National Teaching &amp; Learning Forum	[{'authorId': '50984179', 'name': 'L. Bessette'}]	This Isn't Another Piece on ChatGPT		0	Rest		NaN			FALSE
Mixed_Annotators	The Pediatric Infectious Disease Journal	[{'authorId': '143739014', 'name': 'N. Curtis'}]	To ChatGPT or not to ChatGPT? The Impact of Artificial Intelligence on Academic Publishing.		0	Application	Writing	NaN			FALSE
Mixed_Annotators		[{'authorId': '23672613', 'name': 'Yejin Bang'}, {'authorId': '2107033245', 'name': 'Samuel Cahyawijaya'}, {'authorId': '40221187', 'name': 'Nayeon Lee'}, {'authorId': '47653392', 'name': 'Wenliang Dai'}, {'authorId': '144610224', 'name': 'Dan Su'}, {'authorId': '150048491', 'name': 'Bryan Wilie'}, {'authorId': '116344405', 'name': 'Holy Lovenia'}, {'authorId': '3391272', 'name': 'Ziwei Ji'}, {'authorId': '1660855299', 'name': 'Tiezheng Yu'}, {'authorId': '2160716372', 'name': 'Willy Chung'}, {'authorId': '2187874252', 'name': 'Quyet V. Do'}, {'authorId': '98271906', 'name': 'Yan Xu'}, {'authorId': '2057151752', 'name': 'Pascale Fung'}]	A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity	This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets. We carry out an extensive technical evaluation of ChatGPT using 21 data sets covering 8 different common NLP application tasks. We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts, via an intermediate code generation step. Moreover, we find that ChatGPT is 64.33% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. It is, for example, better at deductive than inductive reasoning. ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++ on machine translation, in a multi-turn"prompt engineering"fashion.	4	Evaluation		NaN			TRUE
Mixed_Annotators		[{'authorId': '2166478496', 'name': 'Paula Maddigan'}, {'authorId': '2656889', 'name': 'Teo Susnjak'}]	Chat2VIS: Generating Data Visualisations via Natural Language using ChatGPT, Codex and GPT-3 Large Language Models	The field of data visualisation has long aimed to generate visualisations from natural language text. Research in Natural Language Interfaces (NLIs) has contributed towards the development of a solution which allow users to interact with data using natural language queries. However, the implementation of NLIs is challenging due to the inherent ambiguity of natural language and frequent underspecification of user queries. This study proposes using large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into visualisations. This paper presents a novel system, Chat2VIS, which leverages LLMs and demonstrates how effective prompt engineering can be conducted in order to extract from LLMs the desired code for visualisations. Chat2VIS shows that the use of pre-trained LLMs together with the proposed priming prompts, offers an accurate and reliable approach to generating visualisations from natural language queries, even those that are highly misspecified and underspecified. This approach demonstrates gains in efficiency and cost reduction in the development of these systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules. The study compares the performance of two types of GPT-3 models and ChatGPT, while demonstrating that the proposed approach is secure, privacy-preserving, and generalisable to different datasets.							
Mixed_Annotators		[{'authorId': '49095886', 'name': 'P. Hacker'}, {'authorId': '2053831555', 'name': 'A. Engel'}, {'authorId': '36216751', 'name': 'M. Mauer'}]	Regulating ChatGPT and other Large Generative AI Models	Large generative AI models (LGAIMs), such as ChatGPT or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest four strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large. Rules in the AI Act and other direct regulation must match the specificities of pre-trained models. In particular, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management. Non-discrimination provisions (iii) may, however, apply to LGAIM developers. Lastly, (iv) the core of the DSA content moderation rules should be expanded to cover LGAIMs. This includes notice and action mechanisms, and trusted flaggers. In all areas, regulators and lawmakers need to act fast to keep track with the dynamics of ChatGPT et al.							
Mixed_Annotators		[{'authorId': '2006243724', 'name': 'Lin Luan'}, {'authorId': None, 'name': 'Xi Lin'}, {'authorId': '2204960951', 'name': 'Wenbiao Li'}]	Exploring the Cognitive Dynamics of Artificial Intelligence in the Post-COVID-19 and Learning 3.0 Era: A Case Study of ChatGPT	The emergence of artificial intelligence has incited a paradigm shift across the spectrum of human endeavors, with ChatGPT serving as a catalyst for the transformation of various established domains, including but not limited to education, journalism, security, and ethics. In the post-pandemic era, the widespread adoption of remote work has prompted the educational sector to reassess conventional pedagogical methods. This paper is to scrutinize the underlying psychological principles of ChatGPT, delve into the factors that captivate user attention, and implicate its ramifications on the future of learning. The ultimate objective of this study is to instigate a scholarly discourse on the interplay between technological advancements in education and the evolution of human learning patterns, raising the question of whether technology is driving human evolution or vice versa.							
Mixed_Annotators		[{'authorId': '3177797', 'name': 'A. Borji'}]	A Categorical Archive of ChatGPT Failures	Large language models have been demonstrated to be valuable in different fields. ChatGPT, developed by OpenAI, has been trained using massive amounts of data and simulates human conversation by comprehending context and generating appropriate responses. It has garnered significant attention due to its ability to effectively answer a broad range of human inquiries, with fluent and comprehensive answers surpassing prior public chatbots in both security and usefulness. However, a comprehensive analysis of ChatGPT's failures is lacking, which is the focus of this study. Ten categories of failures, including reasoning, factual errors, math, coding, and bias, are presented and discussed. The risks, limitations, and societal implications of ChatGPT are also highlighted. The goal of this study is to assist researchers and developers in enhancing future language models and chatbots.							
Mixed_Annotators		[{'authorId': '88352234', 'name': 'M. Khalil'}, {'authorId': '1940086', 'name': 'Erkan Er'}]	Will ChatGPT get you caught? Rethinking of Plagiarism Detection	The rise of Artificial Intelligence (AI) technology and its impact on education has been a topic of growing concern in recent years. The new generation AI systems such as chatbots have become more accessible on the Internet and stronger in terms of capabilities. The use of chatbots, particularly ChatGPT, for generating academic essays at schools and colleges has sparked fears among scholars. This study aims to explore the originality of contents produced by one of the most popular AI chatbots, ChatGPT. To this end, two popular plagiarism detection tools were used to evaluate the originality of 50 essays generated by ChatGPT on various topics. Our results manifest that ChatGPT has a great potential to generate sophisticated text outputs without being well caught by the plagiarism check software. In other words, ChatGPT can create content on many topics with high originality as if they were written by someone. These findings align with the recent concerns about students using chatbots for an easy shortcut to success with minimal or no effort. Moreover, ChatGPT was asked to verify if the essays were generated by itself, as an additional measure of plagiarism check, and it showed superior performance compared to the traditional plagiarism-detection tools. The paper discusses the need for institutions to consider appropriate measures to mitigate potential plagiarism issues and advise on the ongoing debate surrounding the impact of AI technology on education. Further implications are discussed in the paper.							
Mixed_Annotators		[{'authorId': '2204579033', 'name': 'Samuel A. Prieto'}, {'authorId': '2166277457', 'name': 'Eyob Mengiste'}, {'authorId': '98018377', 'name': 'Borja GarcÃ­a de Soto'}]	Investigating the use of ChatGPT for the scheduling of construction projects	Large language models such as ChatGPT have the potential to revolutionize the construction industry by automating repetitive and time-consuming tasks. This paper presents a study in which ChatGPT was used to generate a construction schedule for a simple construction project. The output from ChatGPT was evaluated by a pool of participants that provided feedback regarding their overall interaction experience and the quality of the output. The results show that ChatGPT can generate a coherent schedule that follows a logical approach to fulfill the requirements of the scope indicated. The participants had an overall positive interaction experience and indicated the great potential of such a tool to automate many preliminary and time-consuming tasks. However, the technology still has limitations, and further development is needed before it can be widely adopted in the industry. Overall, this study highlights the potential of using large language models in the construction industry and the need for further research.	4	APPLICATION		Opportunity			
Mixed_Annotators		[{'authorId': '2204651610', 'name': 'Sajed Jalil'}, {'authorId': '1491244699', 'name': 'Suzzana Rafi'}, {'authorId': '1683595', 'name': 'Thomas D. LaToza'}, {'authorId': '1381376597', 'name': 'Kevin Moran'}, {'authorId': '2204647461', 'name': 'Wing Lam'}]	ChatGPT and Software Testing Education: Promises&Perils	Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the advent of general purpose"large language models", based on neural transformer architectures, that have been trained on massive datasets of human written text spanning code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end-users. The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this paper, we examine how well ChatGPT performs when tasked with solving common questions in a popular software testing curriculum. Our findings indicate that ChatGPT can provide correct or partially correct answers in 44% of cases, provide correct or partially correct explanations of answers in 57% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct answers. Based on these findings, we discuss the potential promise, and dangers related to the use of ChatGPT by students and instructors.	3	EDUCATION	APPLICATION	Mixed			
Mixed_Annotators		[{'authorId': '2146514461', 'name': 'Shuai Wang'}, {'authorId': '8842143', 'name': 'Harrisen Scells'}, {'authorId': '1783566', 'name': 'B. Koopman'}, {'authorId': '1692855', 'name': 'G. Zuccon'}]	Can ChatGPT Write a Good Boolean Query for Systematic Review Literature Search?	Systematic reviews are comprehensive reviews of the literature for a highly focused research question. These reviews are often treated as the highest form of evidence in evidence-based medicine, and are the key strategy to answer research questions in the medical field. To create a high-quality systematic review, complex Boolean queries are often constructed to retrieve studies for the review topic. However, it often takes a long time for systematic review researchers to construct a high quality systematic review Boolean query, and often the resulting queries are far from effective. Poor queries may lead to biased or invalid reviews, because they missed to retrieve key evidence, or to extensive increase in review costs, because they retrieved too many irrelevant studies. Recent advances in Transformer-based generative models have shown great potential to effectively follow instructions from users and generate answers based on the instructions being made. In this paper, we investigate the effectiveness of the latest of such models, ChatGPT, in generating effective Boolean queries for systematic review literature search. Through a number of extensive experiments on standard test collections for the task, we find that ChatGPT is capable of generating queries that lead to high search precision, although trading-off this for recall. Overall, our study demonstrates the potential of ChatGPT in generating effective Boolean queries for systematic review literature search. The ability of ChatGPT to follow complex instructions and generate queries with high precision makes it a valuable tool for researchers conducting systematic reviews, particularly for rapid reviews where time is a constraint and often trading-off higher precision for lower recall is acceptable.	4	MEDICAL	APPLICATION	Opportunity			
Mixed_Annotators		[{'authorId': '114543655', 'name': 'Henri-Paul Rousseau'}]	De Gutenberg à ChatGPT: Le défi de l'université numérique	The purpose of this paper is to better understand the magnitude of the challenge that the digital world poses to the academic community and to propose some ideas that can help academics in their efforts to adapt to the digital world. The impact of the digital revolution on the world of university education can be summarized as follows: in a digital world, knowledge is accessible and, all in all, at very low cost, whereas the level and types of skills required to evolve in a digital world are more complex.  The university has lost its quasi-monopoly in the transmission of this knowledge and has not yet established its indispensable role in the acquisition of new skills. The university is also threatened in its traditional capacity to attract, retain and promote the artisans of tomorrow's world who are increasingly active in ecosystems driven and even often controlled by the big industrial winners of the digital revolution. A reflection and a discussion are necessary. The digital world being a world of data, information and knowledge, this world can only be the natural world of the community of professors, teachers, researchers and students. The digitization of education is a unique opportunity to make it more accessible to as many people as possible.	0	EDUCATION		NAN			
Mixed_Annotators		[{'authorId': '3982687', 'name': 'W. Yeadon'}, {'authorId': '2197779028', 'name': 'Oto-Obong Inyang'}, {'authorId': '9799803', 'name': 'Arin Mizouri'}, {'authorId': '47673900', 'name': 'Alex Peach'}, {'authorId': '50820901', 'name': 'Craig P. Testrow'}]	The Death of the Short-Form Physics Essay in the Coming AI Revolution	. The latest AI language modules can produce original, high quality full short-form (300-word) Physics essays within seconds. These technologies such as ChatGPT and davinci-003 are freely available to anyone with an internet connection. In this work, we present evidence of AI generated short-form essays achieving ï¬rst-class grades on an essay writing assessment from an accredited, current university Physics module. The assessment requires students answer ï¬ve open-ended questions with a short, 300-word essay each. Fifty AI answers were generated to create ten submissions that were independently marked by ï¬ve separate markers. The AI generated submissions achieved an average mark of 71 Â± 2%, in strong agreement with the current module average of 71 Â± 5%. A typical AI submission would therefore most-likely be awarded a First Class, the highest classiï¬cation available at UK universities. Plagiarism detection software returned a plagiarism score between 2 Â± 1% (Grammarly) and 7 Â± 2% (TurnitIn). We argue that these results indicate that current AI MLPs represent a signiï¬cant threat to the ï¬delity of short-form essays as an assessment method in Physics courses.	5	EDUCATION		Threat			
Mixed_Annotators		[{'authorId': '2143856672', 'name': 'Hao Liu'}, {'authorId': '47218071', 'name': 'Carmelo Sferrazza'}, {'authorId': '1689992', 'name': 'P. Abbeel'}]	Languages are Rewards: Hindsight Finetuning using Human Feedback	Learning from human preferences is important for language models to be helpful and useful for humans, and to align with human and social values. Existing works focus on supervised finetuning of pretrained models, based on curated model generations that are preferred by human labelers. Such works have achieved remarkable successes in understanding and following instructions (e.g., InstructGPT, ChatGPT, etc). However, to date, a key limitation of supervised finetuning is that it cannot learn from negative ratings; models are only trained on positive-rated data, which makes it data inefficient. Because collecting human feedback data is both time consuming and expensive, it is vital for the model to learn from all feedback, akin to the remarkable ability of humans to learn from diverse feedback. In this work, we propose a novel technique called Hindsight Finetuning for making language models learn from diverse human feedback. In fact, our idea is motivated by how humans learn from hindsight experience. We condition the model on a sequence of model generations paired with hindsight feedback, and finetune the model to predict the most preferred output. By doing so, models can learn to identify and correct negative attributes or errors. Applying the method to GPT-J, we observe that it significantly improves results on summarization and dialogue tasks using the same amount of human feedback.	0	REST		NAN			Yes
Mixed_Annotators		[{'authorId': '6111719', 'name': 'Å½. BaÅ¡iÄ‡'}, {'authorId': '108799474', 'name': 'A. Banovac'}, {'authorId': '14293972', 'name': 'I. KruÅ¾iÄ‡'}, {'authorId': '1988029', 'name': 'I. JerkoviÄ‡'}]	Better by you, better than me, chatgpt3 as writing assistance in students essays	Aim: To compare students' essay writing performance with or without employing ChatGPT-3 as a writing assistant tool. Materials and methods: Eighteen students participated in the study (nine in control and nine in the experimental group that used ChatGPT-3). We scored essay elements with grades (A-D) and corresponding numerical values (4-1). We compared essay scores to students' GPTs, writing time, authenticity, and content similarity. Results: Average grade was C for both groups; for control (2.39, SD=0.71) and for experimental (2.00, SD=0.73). None of the predictors affected essay scores: group (P=0.184), writing duration (P=0.669), module (P=0.388), and GPA (P=0.532). The text unauthenticity was slightly higher in the experimental group (11.87%, SD=13.45 to 9.96%, SD=9.81%), but the similarity among essays was generally low in the overall sample (the Jaccard similarity index ranging from 0 to 0.054). In the experimental group, AI classifier recognized more potential AI-generated texts. Conclusions: This study found no evidence that using GPT as a writing tool improves essay quality since the control group outperformed the experimental group in most parameters.	2	EDUCATION	WRITING	Mixed			Yes
Mixed_Annotators		[{'authorId': '2153463830', 'name': 'Abhiramon Rajasekharan'}, {'authorId': '2116806486', 'name': 'Yankai Zeng'}, {'authorId': '2151051389', 'name': 'Parth Padalkar'}, {'authorId': '2146687315', 'name': 'Gopal Gupta'}]	Reliable Natural Language Understanding with Large Language Models and Answer Set Programming	Humans understand language by extracting information (meaning) from sentences, combining it with existing commonsense knowledge, and then performing reasoning to draw conclusions. While large language models (LLMs) such as GPT-3 and ChatGPT are able to leverage patterns in the text to solve a variety of NLP tasks, they fall short in problems that require reasoning. They also cannot reliably explain the answers generated for a given question. In order to emulate humans better, we propose STAR, a framework that combines LLMs with Answer Set Programming (ASP). We show how LLMs can be used to effectively extract knowledge -- represented as predicates -- from language. Goal-directed ASP is then employed to reliably reason over this knowledge. We apply the STAR framework to three different NLU tasks requiring reasoning: qualitative reasoning, mathematical reasoning, and goal-directed conversation. Our experiments reveal that STAR is able to bridge the gap of reasoning in NLU tasks, leading to significant performance improvements, especially for smaller LLMs, i.e., LLMs with a smaller number of parameters. NLU applications developed using the STAR framework are also explainable: along with the predicates generated, a justification in the form of a proof tree can be produced for a given output.							
Mixed_Annotators		[{'authorId': '3296536', 'name': 'G. Kortemeyer'}]	Could an Artificial-Intelligence agent pass an introductory physics course?	Massive pre-trained language models have garnered attention and controversy due to their ability to generate human-like responses: attention due to their frequent indistinguishability from human-generated phraseology and narratives, and controversy due to the fact that their convincingly presented arguments and facts are frequently simply false. Just how human-like are these responses when it comes to dialogues about physics, in particular about the standard content of introductory physics courses? This study explores that question by having ChatGTP, the pre-eminent language model in 2023, work through representative assessment content of an actual calculus-based physics course and grading the responses in the same way human responses would be graded. As it turns out, ChatGPT would narrowly pass this course while exhibiting many of the preconceptions and errors of a beginning learner.							
Mixed_Annotators		[{'authorId': '103135769', 'name': 'O. Lahav'}]	Deep Machine Learning in Cosmology: Evolution or Revolution?	Could Machine Learning (ML) make fundamental discoveries and tackle unsolved problems in Cosmology? Detailed observations of the present contents of the universe are consistent with the Cosmological Constant Lambda and Cold Dark Matter model, subject to some unresolved inconsistencies ('tensions') among observations of the Hubble Constant and the clumpiness factor. To understand these issues further, large surveys of billions of galaxies and other probes require new statistical approaches. In recent years the power of ML, and in particular 'Deep Learning', has been demonstrated for object classification, photometric redshifts, anomaly detection, enhanced simulations, and inference of cosmological parameters. It is argued that the more traditional 'shallow learning' (i.e. with pre-processing feature extraction) is actually quite deep, as it brings in human knowledge, while 'deep learning' might be perceived as a black box, unless supplemented by explainability tools. The 'killer applications' of ML for Cosmology are still to come. New ways to train the next generation of scientists for the Data Intensive Science challenges ahead are also discussed. Finally, the chatbot ChatGPT is challenged to address the question posed in this article's title.							
Annotator2	arxiv		ChatGPT: The End of Online Exam Integrity?	This study evaluated the ability of ChatGPT, a recently developed artificial intelligence (AI) agent, to perform high-level cognitive tasks and produce text that is indistinguishable from human-generated text. This capacity raises concerns about the potential use of ChatGPT as a tool for academic misconduct in online exams. The study found that ChatGPT is capable of exhibiting critical thinking skills and generating highly realistic text with minimal input, making it a potential threat to the integrity of online exams, particularly in tertiary education settings where such exams are becoming more prevalent. Returning to invigilated and oral exams could form part of the solution, while using advanced proctoring techniques and AI-text output detectors may be effective in addressing this issue, they are not likely to be foolproof solutions. Further research is needed to fully understand the implications of large language models like ChatGPT and to devise strategies for combating the risk of cheating using these tools. It is crucial for educators and institutions to be aware of the possibility of ChatGPT being used for cheating and to investigate measures to address it in order to maintain the fairness and validity of online exams for all students.	5	EDUCATION	ETHICS	Threat			
Annotator2	arxiv		Is ChatGPT A Good Translator? A Preliminary Study	This report provides a preliminary evaluation of ChatGPT for machine translation, including translation prompt, multilingual translation, and translation robustness. We adopt the prompts advised by ChatGPT to trigger its translation ability and find that the candidate prompts generally work well and show minor performance differences. By evaluating on a number of benchmark test sets, we find that ChatGPT performs competitively with commercial translation products (e.g., Google Translate) on high-resource European languages but lags behind significantly on low-resource or distant languages. For distant languages, we explore an interesting strategy named $\mathbf{pivot~prompting}$ that asks ChatGPT to translate the source sentence into a high-resource pivot language before into the target language, which improves the translation performance significantly. As for the translation robustness, ChatGPT does not perform as well as the commercial systems on biomedical abstracts or Reddit comments but is potentially a good translator for spoken language. Scripts and data: https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator	4	APPLICATION	MT	Opportunity			
Annotator2	arxiv		The moral authority of ChatGPT	ChatGPT is not only fun to chat with, but it also searches information, answers questions, and gives advice. With consistent moral advice, it might improve the moral judgment and decisions of users, who often hold contradictory moral beliefs. Unfortunately, ChatGPT turns out highly inconsistent as a moral advisor. Nonetheless, it influences users' moral judgment, we find in an experiment, even if they know they are advised by a chatting bot, and they underestimate how much they are influenced. Thus, ChatGPT threatens to corrupt rather than improves users' judgment. These findings raise the question of how to ensure the responsible use of ChatGPT and similar AI. Transparency is often touted but seems ineffective. We propose training to improve digital literacy.	2	ETHICS		Threat			
Annotator2	arxiv		Putting ChatGPT's Medical Advice to the (Turing) Test	Objective: Assess the feasibility of using ChatGPT or a similar AI-based chatbot for patient-provider communication. Participants: A US representative sample of 430 study participants aged 18 and above. 53.2% of respondents analyzed were women; their average age was 47.1. Exposure: Ten representative non-administrative patient-provider interactions were extracted from the EHR. Patients' questions were placed in ChatGPT with a request for the chatbot to respond using approximately the same word count as the human provider's response. In the survey, each patient's question was followed by a provider- or ChatGPT-generated response. Participants were informed that five responses were provider-generated and five were chatbot-generated. Participants were asked, and incentivized financially, to correctly identify the response source. Participants were also asked about their trust in chatbots' functions in patient-provider communication, using a Likert scale of 1-5. Results: The correct classification of responses ranged between 49.0% to 85.7% for different questions. On average, chatbot responses were correctly identified 65.5% of the time, and provider responses were correctly distinguished 65.1% of the time. On average, responses toward patients' trust in chatbots' functions were weakly positive (mean Likert score: 3.4), with lower trust as the health-related complexity of the task in questions increased. Conclusions: ChatGPT responses to patient questions were weakly distinguishable from provider responses. Laypeople appear to trust the use of chatbots to answer lower risk health questions.	3	MEDICAL		NAN			
Annotator2	arxiv		ThoughtSource: A central hub for large language model reasoning data	Large language models (LLMs) such as GPT-3 and ChatGPT have recently demonstrated impressive results across a wide range of tasks. LLMs are still limited, however, in that they frequently fail at complex reasoning, their reasoning processes are opaque, they are prone to 'hallucinate' facts, and there are concerns about their underlying biases. Letting models verbalize reasoning steps as natural language, a technique known as chain-of-thought prompting, has recently been proposed as a way to address some of these issues. Here we present the first release of ThoughtSource, a meta-dataset and software library for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to improve future artificial intelligence systems by facilitating qualitative understanding of CoTs, enabling empirical evaluations, and providing training data. This first release of ThoughtSource integrates six scientific/medical, three general-domain and five math word question answering datasets.	0	EVALUATION		NAN			
Annotator2	arxiv		Navigating Complexity in Software Engineering: A Prototype for Comparing   GPT-n Solutions	Navigating the diverse solution spaces of non-trivial software engineering tasks requires a combination of technical knowledge, problem-solving skills, and creativity. With multiple possible solutions available, each with its own set of trade-offs, it is essential for programmers to evaluate the various options and select the one that best suits the specific requirements and constraints of a project. Whether it is choosing from a range of libraries, weighing the pros and cons of different architecture and design solutions, or finding unique ways to fulfill user requirements, the ability to think creatively is crucial for making informed decisions that will result in efficient and effective software. However, the interfaces of current chatbot tools for programmers, such as OpenAI's ChatGPT or GitHub Copilot, are optimized for presenting a single solution, even for complex queries. While other solutions can be requested, they are not displayed by default and are not intuitive to access. In this paper, we present our work-in-progress prototype "GPTCompare", which allows programmers to visually compare multiple source code solutions generated by GPT-n models for the same programming-related query by highlighting their similarities and differences.	0	APPLICATION	CODING	NAN			
Annotator2	arxiv		What would Harry say? Building Dialogue Agents for Characters in a Story  Dialogue agents	We have a Christmas gift for Harry Potter fans all over the world. In this paper, we present Harry Potter Dialogue (HPD), a dataset that helps train Harry Potter-like dialogue agents. Such a task is typically viewed as a variant of personalized dialogue agents, but they differ significantly in three respects: 1) Harry lived in a virtual world of wizards, thus, real-world commonsense may not apply to Harry's conversations; 2) Harry's behavior is strongly linked to background information in conversations: the scene, its attributes and its relationship to other speakers; and 3) Such backgrounds are dynamically altered as the storyline goes on. The HPD dataset, as the first dataset to facilitate the study of dialogue agent construction for characters within a story, provides rich contextual information about each dialogue session such as scenes, character attributes, and relations. More importantly, all the background information will change over the course of the story. In addition, HPD could support both dialogue generation and retrieval tasks. We evaluate baselines such as Dialog-GPT and BOB to determine the extent to which they can generate Harry Potter-like responses. The experimental results disappoint us in that although the generated responses are fluent, they still seem out of character for Harry. Besides, we validate the current most robust dialogue agent, ChatGPT, which also can't generate plausible Harry-Potter-like responses in some cases, either. Our results suggest that there is much scope for future research.	2	APPLICATION	Dialogue / Fiction	NAN			
Annotator2	arxiv		Truth Machines: Synthesizing Veracity in AI Language Models	As AI technologies are rolled out into healthcare, academia, human resources, law, and a multitude of other domains, they become de-facto arbiters of truth. But truth is highly contested, with many different definitions and approaches. This article discusses the struggle for truth in AI systems and the general responses to date. It then investigates the production of truth in InstructGPT, a large language model, highlighting how data harvesting, model architectures, and social feedback mechanisms weave together disparate understandings of veracity. It conceptualizes this performance as an operationalization of truth, where distinct, often conflicting claims are smoothly synthesized and confidently presented into truth-statements. We argue that these same logics and inconsistencies play out in Instruct's successor, ChatGPT, reiterating truth as a non-trivial problem. We suggest that enriching sociality and thickening "reality" are two promising vectors for enhancing the truth-evaluating capacities of future language models. We conclude, however, by stepping back to consider AI truth-telling as a social practice: what kind of "truth" do we as listeners desire?	2	ETHICS		Threat			
Annotator1	arxiv	[{'name': 'Biyang Guo'}, {'name': 'Xin Zhang'}, {'name': 'Ziyuan Wang'}, {'name': 'Minqi Jiang'}, {'name': 'Jinran Nie'}, {'name': 'Yuxuan Ding'}, {'name': 'Jianwei Yue'}, {'name': 'Yupeng Wu'}]	How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation,   and Detection	The introduction of ChatGPT has garnered widespread attention in both academic and industrial communities. ChatGPT is able to respond effectively to a wide range of human questions, providing fluent and comprehensive answers that significantly surpass previous public chatbots in terms of security and usefulness. On one hand, people are curious about how ChatGPT is able to achieve such strength and how far it is from human experts. On the other hand, people are starting to worry about the potential negative impacts that large language models (LLMs) like ChatGPT could have on society, such as fake news, plagiarism, and social security issues. In this work, we collected tens of thousands of comparison responses from both human experts and ChatGPT, with questions ranging from open-domain, financial, medical, legal, and psychological areas. We call the collected dataset the Human ChatGPT Comparison Corpus (HC3). Based on the HC3 dataset, we study the characteristics of ChatGPT's responses, the differences and gaps from human experts, and future directions for LLMs. We conducted comprehensive human evaluations and linguistic analyses of ChatGPT-generated content compared with that of humans, where many interesting results are revealed. After that, we conduct extensive experiments on how to effectively detect whether a certain text is generated by ChatGPT or humans. We build three different detection systems, explore several key factors that influence their effectiveness, and evaluate them in different scenarios. The dataset, code, and models are all publicly available at https://github.com/Hello-SimpleAI/chatgpt-comparison-detection.	4	EVALUATION	REST	Mixed			
Annotator1	arxiv	[{'name': 'Dominik Sobania'}, {'name': 'Martin Briesch'}, {'name': 'Carol Hanna'}, {'name': 'Justyna Petke'}]	An Analysis of the Automatic Bug Fixing Performance of ChatGPT	To support software developers in finding and fixing software bugs, several automated program repair techniques have been introduced. Given a test suite, standard methods usually either synthesize a repair, or navigate a search space of software edits to find test-suite passing variants. Recent program repair methods are based on deep learning approaches. One of these novel methods, which is not primarily intended for automated program repair, but is still suitable for it, is ChatGPT. The bug fixing performance of ChatGPT, however, is so far unclear. Therefore, in this paper we evaluate ChatGPT on the standard bug fixing benchmark set, QuixBugs, and compare the performance with the results of several other approaches reported in the literature. We find that ChatGPT's bug fixing performance is competitive to the common deep learning approaches CoCoNut and Codex and notably better than the results reported for the standard program repair approaches. In contrast to previous approaches, ChatGPT offers a dialogue system through which further information, e.g., the expected output for a certain input or an observed error message, can be entered. By providing such hints to ChatGPT, its success rate can be further increased, fixing 31 out of 40 bugs, outperforming state-of-the-art.	5	Application		NAN			
Annotator1	arxiv	[{'name': 'Sandra MitroviÄ‡'}, {'name': 'Davide Andreoletti'}, {'name': 'Omran Ayoub'}]	ChatGPT or Human? Detect and Explain. Explaining Decisions of Machine   Learning Model for Detecting Short ChatGPT-generated Text	ChatGPT has the ability to generate grammatically flawless and seemingly-human replies to different types of questions from various domains. The number of its users and of its applications is growing at an unprecedented rate. Unfortunately, use and abuse come hand in hand. In this paper, we study whether a machine learning model can be effectively trained to accurately distinguish between original human and seemingly human (that is, ChatGPT-generated) text, especially when this text is short. Furthermore, we employ an explainable artificial intelligence framework to gain insight into the reasoning behind the model trained to differentiate between ChatGPT-generated and human-generated text. The goal is to analyze model's decisions and determine if any specific patterns or characteristics can be identified. Our study focuses on short online reviews, conducting two experiments comparing human-generated and ChatGPT-generated text. The first experiment involves ChatGPT text generated from custom queries, while the second experiment involves text generated by rephrasing original human-generated reviews. We fine-tune a Transformer-based model and use it to make predictions, which are then explained using SHAP. We compare our model with a perplexity score-based approach and find that disambiguation between human and ChatGPT-generated reviews is more challenging for the ML model when using rephrased text. However, our proposed approach still achieves an accuracy of 79%. Using explainability, we observe that ChatGPT's writing is polite, without specific details, using fancy and atypical vocabulary, impersonal, and typically it does not express feelings.	4	EVALUATION	APPLICATION	NAN			
Annotator1	arxiv	{'name': 'Teo Susnjak'}	ChatGPT: The End of Online Exam Integrity?	This study evaluated the ability of ChatGPT, a recently developed artificial intelligence (AI) agent, to perform high-level cognitive tasks and produce text that is indistinguishable from human-generated text. This capacity raises concerns about the potential use of ChatGPT as a tool for academic misconduct in online exams. The study found that ChatGPT is capable of exhibiting critical thinking skills and generating highly realistic text with minimal input, making it a potential threat to the integrity of online exams, particularly in tertiary education settings where such exams are becoming more prevalent. Returning to invigilated and oral exams could form part of the solution, while using advanced proctoring techniques and AI-text output detectors may be effective in addressing this issue, they are not likely to be foolproof solutions. Further research is needed to fully understand the implications of large language models like ChatGPT and to devise strategies for combating the risk of cheating using these tools. It is crucial for educators and institutions to be aware of the possibility of ChatGPT being used for cheating and to investigate measures to address it in order to maintain the fairness and validity of online exams for all students.	5	EDUCATION		Threat			
Annotator1	arxiv	[{'name': 'Bowen Zhang'}, {'name': 'Daijun Ding'}, {'name': 'Liwen Jing'}]	How would Stance Detection Techniques Evolve after the Launch of   ChatGPT?	Stance detection refers to the task of extracting the standpoint (Favor, Against or Neither) towards a target in given texts. Such research gains increasing attention with the proliferation of social media contents. The conventional framework of handling stance detection is converting it into text classification tasks. Deep learning models have already replaced rule-based models and traditional machine learning models in solving such problems. Current deep neural networks are facing two main challenges which are insufficient labeled data and information in social media posts and the unexplainable nature of deep learning models. A new pre-trained language model chatGPT was launched on Nov 30, 2022. For the stance detection tasks, our experiments show that ChatGPT can achieve SOTA or similar performance for commonly used datasets including SemEval-2016 and P-Stance. At the same time, ChatGPT can provide explanation for its own prediction, which is beyond the capability of any existing model. The explanations for the cases it cannot provide classification results are especially useful. ChatGPT has the potential to be the best AI model for stance detection tasks in NLP, or at least change the research paradigm of this field. ChatGPT also opens up the possibility of building explanatory AI for stance detection.	5	APPLICATION		Opportunity			
Annotator1	arxiv	[{'name': 'Jochen Hartmann'}, {'name': 'Jasper Schwenzow'}, {'name': 'Maximilian Witte'}]	The political ideology of conversational AI: Converging evidence on   ChatGPT's pro-environmental, left-libertarian orientation	Conversational artificial intelligence (AI) disrupts how humans interact with technology. Recently, OpenAI introduced ChatGPT, a state-of-the-art dialogue model that can converse with its human counterparts with unprecedented capabilities. ChatGPT has witnessed tremendous attention from the media, academia, industry, and the general public, attracting more than a million users within days of its release. However, its explosive adoption for information search and as an automated decision aid underscores the importance to understand its limitations and biases. This paper focuses on one of democratic society's most important decision-making processes: political elections. Prompting ChatGPT with 630 political statements from two leading voting advice applications and the nation-agnostic political compass test in three pre-registered experiments, we uncover ChatGPT's pro-environmental, left-libertarian ideology. For example, ChatGPT would impose taxes on flights, restrict rent increases, and legalize abortion. In the 2021 elections, it would have voted most likely for the Greens both in Germany (B\"undnis 90/Die Gr\"unen) and in the Netherlands (GroenLinks). Our findings are robust when negating the prompts, reversing the order of the statements, varying prompt formality, and across languages (English, German, Dutch, and Spanish). We conclude by discussing the implications of politically biased conversational AI on society.	2	ETHICS	EVALUATION	Threat			
Annotator1	arxiv	[{'name': 'Wenxiang Jiao'}, {'name': 'Wenxuan Wang'}, {'name': 'Jen-tse Huang'}, {'name': 'Xing Wang'}, {'name': 'Zhaopeng Tu'}]	Is ChatGPT A Good Translator? A Preliminary Study	This report provides a preliminary evaluation of ChatGPT for machine translation, including translation prompt, multilingual translation, and translation robustness. We adopt the prompts advised by ChatGPT to trigger its translation ability and find that the candidate prompts generally work well and show minor performance differences. By evaluating on a number of benchmark test sets, we find that ChatGPT performs competitively with commercial translation products (e.g., Google Translate) on high-resource European languages but lags behind significantly on low-resource or distant languages. For distant languages, we explore an interesting strategy named $\mathbf{pivot~prompting}$ that asks ChatGPT to translate the source sentence into a high-resource pivot language before into the target language, which improves the translation performance significantly. As for the translation robustness, ChatGPT does not perform as well as the commercial systems on biomedical abstracts or Reddit comments but is potentially a good translator for spoken language. Scripts and data: https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator	4	APPLICATION		NAN			
Annotator1	arxiv	[{'name': 'Simon Frieder'}, {'name': 'Luca Pinchetti'}, {'name': 'Ryan-Rhys Griffiths'}, {'name': 'Tommaso Salvatori'}, {'name': 'Thomas Lukasiewicz'}, {'name': 'Philipp Christian Petersen'}, {'name': 'Alexis Chevalier'}, {'name': 'Julius Berner'}]	Mathematical Capabilities of ChatGPT	We investigate the mathematical capabilities of ChatGPT by testing it on publicly available datasets, as well as hand-crafted ones, and measuring its performance against other models trained on a mathematical corpus, such as Minerva. We also test whether ChatGPT can be a useful assistant to professional mathematicians by emulating various use cases that come up in the daily professional activities of mathematicians (question answering, theorem searching). In contrast to formal mathematics, where large databases of formal proofs are available (e.g., the Lean Mathematical Library), current datasets of natural-language mathematics, used to benchmark language models, only cover elementary mathematics. We address this issue by introducing a new dataset: GHOSTS. It is the first natural-language dataset made and curated by working researchers in mathematics that (1) aims to cover graduate-level mathematics and (2) provides a holistic overview of the mathematical capabilities of language models. We benchmark ChatGPT on GHOSTS and evaluate performance against fine-grained criteria. We make this new dataset publicly available to assist a community-driven comparison of ChatGPT with (future) large language models in terms of advanced mathematical comprehension. We conclude that contrary to many positive reports in the media (a potential case of selection bias), ChatGPT's mathematical abilities are significantly below those of an average mathematics graduate student. Our results show that ChatGPT often understands the question but fails to provide correct solutions. Hence, if your goal is to use it to pass a university exam, you would be better off copying from your average peer!	1	EVALUATION		NAN			
Annotator1	arxiv	[{'name': 'Katharina Jeblick'}, {'name': 'Balthasar Schachtner'}, {'name': 'Jakob Dexl'}, {'name': 'Andreas Mittermeier'}, {'name': 'Anna Theresa StÃ¼ber'}, {'name': 'Johanna Topalis'}, {'name': 'Tobias Weber'}, {'name': 'Philipp Wesp'}, {'name': 'Bastian Sabel'}, {'name': 'Jens Ricke'}, {'name': 'Michael Ingrisch'}]	ChatGPT Makes Medicine Easy to Swallow: An Exploratory Case Study on   Simplified Radiology Reports	The release of ChatGPT, a language model capable of generating text that appears human-like and authentic, has gained significant attention beyond the research community. We expect that the convincing performance of ChatGPT incentivizes users to apply it to a variety of downstream tasks, including prompting the model to simplify their own medical reports. To investigate this phenomenon, we conducted an exploratory case study. In a questionnaire, we asked 15 radiologists to assess the quality of radiology reports simplified by ChatGPT. Most radiologists agreed that the simplified reports were factually correct, complete, and not potentially harmful to the patient. Nevertheless, instances of incorrect statements, missed key medical findings, and potentially harmful passages were reported. While further studies are needed, the initial insights of this study indicate a great potential in using large language models like ChatGPT to improve patient-centered care in radiology and other medical domains.	4	MEDICAL		Opportunity			
Annotator1	arxiv	[{'name': 'Sebastian KrÃ¼gel'}, {'name': 'Andreas Ostermaier'}, {'name': 'Matthias Uhl'}]	The moral authority of ChatGPT	ChatGPT is not only fun to chat with, but it also searches information, answers questions, and gives advice. With consistent moral advice, it might improve the moral judgment and decisions of users, who often hold contradictory moral beliefs. Unfortunately, ChatGPT turns out highly inconsistent as a moral advisor. Nonetheless, it influences users' moral judgment, we find in an experiment, even if they know they are advised by a chatting bot, and they underestimate how much they are influenced. Thus, ChatGPT threatens to corrupt rather than improves users' judgment. These findings raise the question of how to ensure the responsible use of ChatGPT and similar AI. Transparency is often touted but seems ineffective. We propose training to improve digital literacy.	1	APPLICATION		Threat			
Annotator1	arxiv	[{'name': 'Samuel A. Prieto'}, {'name': 'Eyob T. Mengiste'}, {'name': 'Borja GarcÃ­a de Soto'}]	Investigating the use of ChatGPT for the scheduling of construction   projects	Large language models such as ChatGPT have the potential to revolutionize the construction industry by automating repetitive and time-consuming tasks. This paper presents a study in which ChatGPT was used to generate a construction schedule for a simple construction project. The output from ChatGPT was evaluated by a pool of participants that provided feedback regarding their overall interaction experience and the quality of the output. The results show that ChatGPT can generate a coherent schedule that follows a logical approach to fulfill the requirements of the scope indicated. The participants had an overall positive interaction experience and indicated the great potential of such a tool to automate many preliminary and time-consuming tasks. However, the technology still has limitations, and further development is needed before it can be widely adopted in the industry. Overall, this study highlights the potential of using large language models in the construction industry and the need for further research.	4	APPLICATION		Opportunity			
Annotator1	arxiv	[{'name': 'Ruibo Tu'}, {'name': 'Chao Ma'}, {'name': 'Cheng Zhang'}]	Causal-Discovery Performance of ChatGPT in the context of Neuropathic   Pain Diagnosis	ChatGPT has demonstrated exceptional proficiency in natural language conversation, e.g., it can answer a wide range of questions while no previous large language models can. Thus, we would like to push its limit and explore its ability to answer causal discovery questions by using a medical benchmark (Tu et al. 2019) in causal discovery.	4	MEDICAL		NAN			
Annotator1	arxiv	{'name': 'Ali Borji'}	A Categorical Archive of ChatGPT Failures	Large language models have been demonstrated to be valuable in different fields. ChatGPT, developed by OpenAI, has been trained using massive amounts of data and simulates human conversation by comprehending context and generating appropriate responses. It has garnered significant attention due to its ability to effectively answer a broad range of human inquiries, with fluent and comprehensive answers surpassing prior public chatbots in both security and usefulness. However, a comprehensive analysis of ChatGPT's failures is lacking, which is the focus of this study. Ten categories of failures, including reasoning, factual errors, math, coding, and bias, are presented and discussed. The risks, limitations, and societal implications of ChatGPT are also highlighted. The goal of this study is to assist researchers and developers in enhancing future language models and chatbots.	2	EVALUATION		NAN			
Annotator1	arxiv	[{'name': 'Oded Nov'}, {'name': 'Nina Singh'}, {'name': 'Devin Mann'}]	Putting ChatGPT's Medical Advice to the (Turing) Test	Objective: Assess the feasibility of using ChatGPT or a similar AI-based chatbot for patient-provider communication. Participants: A US representative sample of 430 study participants aged 18 and above. 53.2% of respondents analyzed were women; their average age was 47.1. Exposure: Ten representative non-administrative patient-provider interactions were extracted from the EHR. Patients' questions were placed in ChatGPT with a request for the chatbot to respond using approximately the same word count as the human provider's response. In the survey, each patient's question was followed by a provider- or ChatGPT-generated response. Participants were informed that five responses were provider-generated and five were chatbot-generated. Participants were asked, and incentivized financially, to correctly identify the response source. Participants were also asked about their trust in chatbots' functions in patient-provider communication, using a Likert scale of 1-5. Results: The correct classification of responses ranged between 49.0% to 85.7% for different questions. On average, chatbot responses were correctly identified 65.5% of the time, and provider responses were correctly distinguished 65.1% of the time. On average, responses toward patients' trust in chatbots' functions were weakly positive (mean Likert score: 3.4), with lower trust as the health-related complexity of the task in questions increased. Conclusions: ChatGPT responses to patient questions were weakly distinguishable from provider responses. Laypeople appear to trust the use of chatbots to answer lower risk health questions.	4	MEDICAL		NAN			
Annotator1	arxiv	[{'name': 'Terry Yue Zhuo'}, {'name': 'Yujin Huang'}, {'name': 'Chunyang Chen'}, {'name': 'Zhenchang Xing'}]	Exploring AI Ethics of ChatGPT: A Diagnostic Analysis	Recent breakthroughs in natural language processing (NLP) have permitted the synthesis and comprehension of coherent text in an open-ended way, therefore translating the theoretical algorithms into practical applications. The large language-model (LLM) has significantly impacted businesses such as report summarization softwares and copywriters. Observations indicate, however, that LLMs may exhibit social prejudice and toxicity, posing ethical and societal dangers of consequences resulting from irresponsibility. Large-scale benchmarks for accountable LLMs should consequently be developed. Although several empirical investigations reveal the existence of a few ethical difficulties in advanced LLMs, there is no systematic examination and user study of the ethics of current LLMs use. To further educate future efforts on constructing ethical LLMs responsibly, we perform a qualitative research method on OpenAI's ChatGPT to better understand the practical features of ethical dangers in recent LLMs. We analyze ChatGPT comprehensively from four perspectives: 1) \textit{Bias} 2) \textit{Reliability} 3) \textit{Robustness} 4) \textit{Toxicity}. In accordance with our stated viewpoints, we empirically benchmark ChatGPT on multiple sample datasets. We find that a significant number of ethical risks cannot be addressed by existing benchmarks, and hence illustrate them via additional case studies. In addition, we examine the implications of our findings on the AI ethics of ChatGPT, as well as future problems and practical design considerations for LLMs. We believe that our findings may give light on future efforts to determine and mitigate the ethical hazards posed by machines in LLM applications.	0	ETHICS	EVALUATION	Opportunity			
Annotator1	arxiv	[{'name': 'Shuai Wang'}, {'name': 'Harrisen Scells'}, {'name': 'Bevan Koopman'}, {'name': 'Guido Zuccon'}]	Can ChatGPT Write a Good Boolean Query for Systematic Review Literature   Search?	Systematic reviews are comprehensive reviews of the literature for a highly focused research question. These reviews are often treated as the highest form of evidence in evidence-based medicine, and are the key strategy to answer research questions in the medical field. To create a high-quality systematic review, complex Boolean queries are often constructed to retrieve studies for the review topic. However, it often takes a long time for systematic review researchers to construct a high quality systematic review Boolean query, and often the resulting queries are far from effective. Poor queries may lead to biased or invalid reviews, because they missed to retrieve key evidence, or to extensive increase in review costs, because they retrieved too many irrelevant studies. Recent advances in Transformer-based generative models have shown great potential to effectively follow instructions from users and generate answers based on the instructions being made. In this paper, we investigate the effectiveness of the latest of such models, ChatGPT, in generating effective Boolean queries for systematic review literature search. Through a number of extensive experiments on standard test collections for the task, we find that ChatGPT is capable of generating queries that lead to high search precision, although trading-off this for recall. Overall, our study demonstrates the potential of ChatGPT in generating effective Boolean queries for systematic review literature search. The ability of ChatGPT to follow complex instructions and generate queries with high precision makes it a valuable tool for researchers conducting systematic reviews, particularly for rapid reviews where time is a constraint and often trading-off higher precision for lower recall is acceptable.	5	APPLICATION		Opportunity			
Annotator1	arxiv	[{'name': 'Sajed Jalil'}, {'name': 'Suzzana Rafi'}, {'name': 'Thomas D. LaToza'}, {'name': 'Kevin Moran'}, {'name': 'Wing Lam'}]	ChatGPT and Software Testing Education: Promises & Perils	Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the advent of general purpose "large language models", based on neural transformer architectures, that have been trained on massive datasets of human written text spanning code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end-users.   The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this poster, we examine how well ChatGPT performs when tasked with solving common questions in a popular software testing curriculum. Our findings indicate that ChatGPT can provide correct or partially correct answers in 44% of cases, provide correct or partially correct explanations of answers in 57% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct answers. Based on these findings, we discuss the potential promise, and dangers related to the use of ChatGPT by students and instructors.	3	EDUCATION		Mixed			
Annotator1	arxiv	{'name': 'Kay Lehnert', 'arxiv:affiliation': {'@xmlns:arxiv': 'http://arxiv.org/schemas/atom', '#text': 'Department of Theoretical Physics, Maynooth University, Maynooth, Ireland'}}	AI Insights into Theoretical Physics and the Swampland Program: A   Journey Through the Cosmos with ChatGPT	In this case study, we explore the capabilities and limitations of ChatGPT, a natural language processing model developed by OpenAI, in the field of string theoretical swampland conjectures. We find that it is effective at paraphrasing and explaining concepts in a variety of styles, but not at genuinely connecting concepts. It will provide false information with full confidence and make up statements when necessary. However, its ingenious use of language can be fruitful for identifying analogies and describing visual representations of abstract concepts.	4	APPLICATION		NAN			
Annotator1	arxiv	[{'name': 'Mubin Ul Haque'}, {'name': 'Isuru Dharmadasa'}, {'name': 'Zarrin Tasnim Sworna'}, {'name': 'Roshan Namal Rajapakse'}, {'name': 'Hussain Ahmad'}]	"I think this is the most disruptive technology": Exploring Sentiments   of ChatGPT Early Adopters using Twitter Data	Large language models have recently attracted significant attention due to their impressive performance on a variety of tasks. ChatGPT developed by OpenAI is one such implementation of a large, pre-trained language model that has gained immense popularity among early adopters, where certain users go to the extent of characterizing it as a disruptive technology in many domains. Understanding such early adopters' sentiments is important because it can provide insights into the potential success or failure of the technology, as well as its strengths and weaknesses. In this paper, we conduct a mixed-method study using 10,732 tweets from early ChatGPT users. We first use topic modelling to identify the main topics and then perform an in-depth qualitative sentiment analysis of each topic. Our results show that the majority of the early adopters have expressed overwhelmingly positive sentiments related to topics such as Disruptions to software development, Entertainment and exercising creativity. Only a limited percentage of users expressed concerns about issues such as the potential for misuse of ChatGPT, especially regarding topics such as Impact on educational aspects. We discuss these findings by providing specific examples for each topic and then detail implications related to addressing these concerns for both researchers and users.	0	REST		NAN			
Annotator1	arxiv	[{'name': 'Roberto Gozalo-Brizuela'}, {'name': 'Eduardo C. Garrido-Merchan'}]	ChatGPT is not all you need. A State of the Art Review of large   Generative AI models	During the last two years there has been a plethora of large generative models such as ChatGPT or Stable Diffusion that have been published. Concretely, these models are able to perform tasks such as being a general question and answering system or automatically creating artistic images that are revolutionizing several sectors. Consequently, the implications that these generative models have in the industry and society are enormous, as several job positions may be transformed. For example, Generative AI is capable of transforming effectively and creatively texts to images, like the DALLE-2 model; text to 3D images, like the Dreamfusion model; images to text, like the Flamingo model; texts to video, like the Phenaki model; texts to audio, like the AudioLM model; texts to other texts, like ChatGPT; texts to code, like the Codex model; texts to scientific texts, like the Galactica model or even create algorithms like AlphaTensor. This work consists on an attempt to describe in a concise way the main models are sectors that are affected by generative AI and to provide a taxonomy of the main generative models published recently.	0	REST		NAN			
Annotator1	arxiv	[{'name': 'Paula Maddigan'}, {'name': 'Teo Susnjak'}]	Chat2VIS: Generating Data Visualisations via Natural Language using   ChatGPT, Codex and GPT-3 Large Language Models	The field of data visualisation has long aimed to generate visualisations from natural language text. Research in Natural Language Interfaces (NLIs) has contributed towards the development of a solution which allow users to interact with data using natural language queries. However, the implementation of NLIs is challenging due to the inherent ambiguity of natural language and frequent underspecification of user queries. This study proposes using large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into visualisations. This paper presents a novel system, Chat2VIS, which leverages LLMs and demonstrates how effective prompt engineering can be conducted in order to extract from LLMs the desired code for visualisations. Chat2VIS shows that the use of pre-trained LLMs together with the proposed priming prompts, offers an accurate and reliable approach to generating visualisations from natural language queries, even those that are highly misspecified and underspecified. This approach demonstrates gains in efficiency and cost reduction in the development of these systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules. The study compares the performance of two types of GPT-3 models and ChatGPT, while demonstrating that the proposed approach is secure, privacy-preserving, and generalisable to different datasets.	0	APPLICATION	REST	NAN			
Annotator1	arxiv	{'name': 'Teo Susnjak'}	A Prescriptive Learning Analytics Framework: Beyond Predictive Modelling   and onto Explainable AI with Prescriptive Analytics and ChatGPT	A significant body of recent research in the field of Learning Analytics has focused on leveraging machine learning approaches for predicting at-risk students in order to initiate timely interventions and thereby elevate retention and completion rates. The overarching feature of the majority of these research studies has been on the science of prediction only. The component of predictive analytics concerned with interpreting the internals of the models and explaining their predictions for individual cases to stakeholders has largely been neglected. Additionally, works that attempt to employ data-driven prescriptive analytics to automatically generate evidence-based remedial advice for at-risk learners are in their infancy.   eXplainable AI is a field that has recently emerged providing cutting-edge tools which support transparent predictive analytics and techniques for generating tailored advice for at-risk students. This study proposes a novel framework that unifies both transparent machine learning as well as techniques for enabling prescriptive analytics, while integrating the latest advances in large language models. This work practically demonstrates the proposed framework using predictive models for identifying at-risk learners of programme non-completion. The study then further demonstrates how predictive modelling can be augmented with prescriptive analytics on two case studies in order to generate human-readable prescriptive feedback for those who are at risk using ChatGPT.	4	EDUCATION	APPLICATION	NAN			
Annotator1	arxiv	[{'name': 'Anoop Cherian'}, {'name': 'Kuan-Chuan Peng'}, {'name': 'Suhas Lohit'}, {'name': 'Kevin Smith'}, {'name': 'Joshua B. Tenenbaum'}]	Are Deep Neural Networks SMARTer than Second Graders?	Recent times have witnessed an increasing number of applications of deep neural networks towards solving tasks that require superior cognitive abilities, e.g., playing Go, generating art, question answering (such as ChatGPT), etc. Such a dramatic progress raises the question: how generalizable are neural networks in solving problems that demand broad skills? To answer this question, we propose SMART: a Simple Multimodal Algorithmic Reasoning Task and the associated SMART-101 dataset, for evaluating the abstraction, deduction, and generalization abilities of neural networks in solving visuo-linguistic puzzles designed specifically for children in the 6-8 age group. Our dataset consists of 101 unique puzzles; each puzzle comprises a picture and a question, and their solution needs a mix of several elementary skills, including arithmetic, algebra, and spatial reasoning, among others. To scale our dataset towards training deep neural networks, we programmatically generate entirely new instances for each puzzle while retaining their solution algorithm. To benchmark the performance on the SMART-101 dataset, we propose a vision and language meta-learning model using varied state-of-the-art backbone neural networks. Our experiments reveal that while powerful deep models offer reasonable performances on puzzles that they are trained on, they are not better than random accuracy when analyzed for generalization. We also evaluate the recent ChatGPT large language model on a subset of our dataset and find that while ChatGPT produces convincing reasoning abilities, the answers are often incorrect.	2	EDUCATION		NAN			
Annotator1	arxiv	[{'name': 'Philipp Hacker'}, {'name': 'Andreas Engel'}, {'name': 'Marco Mauer'}]	Regulating ChatGPT and other Large Generative AI Models	Large generative AI models (LGAIMs), such as ChatGPT or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest four strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large. Rules in the AI Act and other direct regulation must match the specificities of pre-trained models. In particular, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management. Non-discrimination provisions (iii) may, however, apply to LGAIM developers. Lastly, (iv) the core of the DSA content moderation rules should be expanded to cover LGAIMs. This includes notice and action mechanisms, and trusted flaggers. In all areas, regulators and lawmakers need to act fast to keep track with the dynamics of ChatGPT et al.	0	ETHICS		Threat			
Annotator1	arxiv	[{'name': 'David Noever'}, {'name': 'Matt Ciolino'}]	The Turing Deception	This research revisits the classic Turing test and compares recent large language models such as ChatGPT for their abilities to reproduce human-level comprehension and compelling text generation. Two task challenges -- summarization, and question answering -- prompt ChatGPT to produce original content (98-99%) from a single text entry and also sequential questions originally posed by Turing in 1950. We score the original and generated content against the OpenAI GPT-2 Output Detector from 2019, and establish multiple cases where the generated content proves original and undetectable (98%). The question of a machine fooling a human judge recedes in this work relative to the question of "how would one prove it?" The original contribution of the work presents a metric and simple grammatical set for understanding the writing mechanics of chatbots in evaluating their readability and statistical clarity, engagement, delivery, and overall quality. While Turing's original prose scores at least 14% below the machine-generated output, the question of whether an algorithm displays hints of Turing's truly original thoughts (the "Lovelace 2.0" test) remains unanswered and potentially unanswerable for now.	4	APPLICATION		NAN			
Annotator1	arxiv	[{'name': 'Yanran Chen'}, {'name': 'Steffen Eger'}]	Transformers Go for the LOLs: Generating (Humourous) Titles from   Scientific Abstracts End-to-End	We consider the end-to-end abstract-to-title generation problem, exploring seven recent transformer based models (including ChatGPT) fine-tuned on more than 30k abstract-title pairs from NLP and machine learning venues. As an extension, we also consider the harder problem of generating humorous paper titles. For the latter, we compile the first large-scale humor annotated dataset for scientific papers in the NLP/ML domains, comprising almost 2.5k titles. We evaluate all models using human and automatic metrics. Our human evaluation suggests that our best end-to-end system performs similarly to human authors (but arguably slightly worse). Generating funny titles is more difficult, however, and our automatic systems clearly underperform relative to humans and often learn dataset artefacts of humor. Finally, ChatGPT, without any fine-tuning, performs on the level of our best fine-tuned system.	5	APPLICATION		NAN			
Annotator1	arxiv	[{'name': 'Forrest McKee'}, {'name': 'David Noever'}]	Chatbots in a Botnet World	Question-and-answer formats provide a novel experimental platform for investigating cybersecurity questions. Unlike previous chatbots, the latest ChatGPT model from OpenAI supports an advanced understanding of complex coding questions. The research demonstrates thirteen coding tasks that generally qualify as stages in the MITRE ATT&CK framework, ranging from credential access to defense evasion. With varying success, the experimental prompts generate examples of keyloggers, logic bombs, obfuscated worms, and payment-fulfilled ransomware. The empirical results illustrate cases that support the broad gain of functionality, including self-replication and self-modification, evasion, and strategic understanding of complex cybersecurity goals. One surprising feature of ChatGPT as a language-only model centers on its ability to spawn coding approaches that yield images that obfuscate or embed executable programming steps or links.	4	ETHICS	APPLICATION	NAN			
Annotator1	arxiv	[{'name': 'David Noever'}, {'name': 'Forrest McKee'}]	Chatbots as Problem Solvers: Playing Twenty Questions with Role   Reversals	New chat AI applications like ChatGPT offer an advanced understanding of question context and memory across multi-step tasks, such that experiments can test its deductive reasoning. This paper proposes a multi-role and multi-step challenge, where ChatGPT plays the classic twenty-questions game but innovatively switches roles from the questioner to the answerer. The main empirical result establishes that this generation of chat applications can guess random object names in fewer than twenty questions (average, 12) and correctly guess 94% of the time across sixteen different experimental setups. The research introduces four novel cases where the chatbot fields the questions, asks the questions, both question-answer roles, and finally tries to guess appropriate contextual emotions. One task that humans typically fail but trained chat applications complete involves playing bilingual games of twenty questions (English answers to Spanish questions). Future variations address direct problem-solving using a similar inquisitive format to arrive at novel outcomes deductively, such as patentable inventions or combination thinking. Featured applications of this dialogue format include complex protein designs, neuroscience metadata, and child development educational materials.	4	APPLICATION		Opportunity			
Annotator1	arxiv	[{'name': 'Forrest McKee'}, {'name': 'David Noever'}]	Chatbots in a Honeypot World	Question-and-answer agents like ChatGPT offer a novel tool for use as a potential honeypot interface in cyber security. By imitating Linux, Mac, and Windows terminal commands and providing an interface for TeamViewer, nmap, and ping, it is possible to create a dynamic environment that can adapt to the actions of attackers and provide insight into their tactics, techniques, and procedures (TTPs). The paper illustrates ten diverse tasks that a conversational agent or large language model might answer appropriately to the effects of command-line attacker. The original result features feasibility studies for ten model tasks meant for defensive teams to mimic expected honeypot interfaces with minimal risks. Ultimately, the usefulness outside of forensic activities stems from whether the dynamic honeypot can extend the time-to-conquer or otherwise delay attacker timelines short of reaching key network assets like databases or confidential information. While ongoing maintenance and monitoring may be required, ChatGPT's ability to detect and deflect malicious activity makes it a valuable option for organizations seeking to enhance their cyber security posture. Future work will focus on cybersecurity layers, including perimeter security, host virus detection, and data security.	5	ETHICS		Opportunity			
Annotator1	arxiv	[{'name': 'Sarah Zhang'}, {'name': 'Reece Shuttleworth'}, {'name': 'Zad Chin'}, {'name': 'Pedro Lantigua'}, {'name': 'Saisamrit Surbehera'}, {'name': 'Gregory Hunter'}, {'name': 'Derek Austin'}, {'name': 'Yann Hicke'}, {'name': 'Leonard Tang'}, {'name': 'Sathwik Karnik'}, {'name': 'Darnell Granberry'}, {'name': 'Iddo Drori'}]	Automatically Answering and Generating Machine Learning Final Exams	Can a machine learn machine learning? We propose to answer this question using the same criteria we use to answer a similar question: can a human learn machine learning? We automatically answer final exams in MIT's, Harvard's and Cornell's large machine learning courses and generate new questions at a human level. Recently, program synthesis and few-shot learning solved university-level problem set questions in mathematics and STEM courses at a human level. In this work, we solve questions from final exams that differ from problem sets in several ways: the questions are longer, have multiple parts, are more complicated, and span a broader set of topics. We provide a new dataset and benchmark of questions from machine learning final exams and code for automatically answering these questions and generating new questions. To make our dataset a reproducible benchmark, we use automatic checkers for multiple choice questions, questions with numeric answers, and questions with expression answers, and evaluate a large free language model, Meta's OPT, and compare the results with Open AI's GPT-3, ChatGPT, and Codex. A student survey comparing the quality, appropriateness, and difficulty of machine-generated questions with human-written questions shows that across multiple aspects, machine-generated questions are indistinguishable from human-generated questions and are suitable for final exams. We perform ablation studies comparing zero-shot learning with few-shot learning, chain-of-thought prompting, GPT-3, ChatGPT, and OPT pre-trained on text and Codex fine-tuned on code on a range of machine learning topics and find that few-shot learning methods perform best. We make our data and code publicly available for the machine learning community.	0	EDUCATION		NAN			
Annotator1	arxiv	[{'name': 'Jonas Belouadi'}, {'name': 'Steffen Eger'}]	ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free   Language Models	State-of-the-art poetry generation systems are often complex. They either consist of task-specific model pipelines, incorporate prior knowledge in the form of manually created constraints or both. In contrast, end-to-end models would not suffer from the overhead of having to model prior knowledge and could learn the nuances of poetry from data alone, reducing the degree of human supervision required. In this work, we investigate end-to-end poetry generation conditioned on styles such as rhyme, meter, and alliteration. We identify and address lack of training data and mismatching tokenization algorithms as possible limitations of past attempts. In particular, we successfully pre-train and release ByGPT5, a new token-free decoder-only language model, and fine-tune it on a large custom corpus of English and German quatrains annotated with our styles. We show that ByGPT5 outperforms other models such as mT5, ByT5, GPT-2 and ChatGPT, while also being more parameter efficient and performing favorably compared to humans. In addition, we analyze its runtime performance and introspect the model's understanding of style conditions. We make our code, models, and datasets publicly available.	1	APPLICATION		NAN			
Annotator1	arxiv	[{'name': 'Will Yeadon'}, {'name': 'Oto-Obong Inyang'}, {'name': 'Arin Mizouri'}, {'name': 'Alex Peach'}, {'name': 'Craig Testrow'}]	The Death of the Short-Form Physics Essay in the Coming AI Revolution	The latest AI language modules can produce original, high quality full short-form ($300$-word) Physics essays within seconds. These technologies such as ChatGPT and davinci-003 are freely available to anyone with an internet connection. In this work, we present evidence of AI generated short-form essays achieving first-class grades on an essay writing assessment from an accredited, current university Physics module. The assessment requires students answer five open-ended questions with a short, $300$-word essay each. Fifty AI answers were generated to create ten submissions that were independently marked by five separate markers. The AI generated submissions achieved an average mark of $71 \pm 2 \%$, in strong agreement with the current module average of $71 \pm 5 %$. A typical AI submission would therefore most-likely be awarded a First Class, the highest classification available at UK universities. Plagiarism detection software returned a plagiarism score between $2 \pm 1$% (Grammarly) and $7 \pm 2$% (TurnitIn). We argue that these results indicate that current AI MLPs represent a significant threat to the fidelity of short-form essays as an assessment method in Physics courses.	5	EDUCATION	APPLICATION	Threat			
Annotator1	arxiv	[{'name': 'Simon Ott'}, {'name': 'Konstantin Hebenstreit'}, {'name': 'Valentin LiÃ©vin'}, {'name': 'Christoffer Egeberg Hother'}, {'name': 'Milad Moradi'}, {'name': 'Maximilian Mayrhauser'}, {'name': 'Robert Praas'}, {'name': 'Ole Winther'}, {'name': 'Matthias Samwald'}]	ThoughtSource: A central hub for large language model reasoning data	Large language models (LLMs) such as GPT-3 and ChatGPT have recently demonstrated impressive results across a wide range of tasks. LLMs are still limited, however, in that they frequently fail at complex reasoning, their reasoning processes are opaque, they are prone to 'hallucinate' facts, and there are concerns about their underlying biases. Letting models verbalize reasoning steps as natural language, a technique known as chain-of-thought prompting, has recently been proposed as a way to address some of these issues. Here we present the first release of ThoughtSource, a meta-dataset and software library for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to improve future artificial intelligence systems by facilitating qualitative understanding of CoTs, enabling empirical evaluations, and providing training data. This first release of ThoughtSource integrates six scientific/medical, three general-domain and five math word question answering datasets.	0	REST		NAN			
Annotator1	arxiv	[{'name': 'Luke Munn'}, {'name': 'Liam Magee'}, {'name': 'Vanicka Arora'}]	Truth Machines: Synthesizing Veracity in AI Language Models	As AI technologies are rolled out into healthcare, academia, human resources, law, and a multitude of other domains, they become de-facto arbiters of truth. But truth is highly contested, with many different definitions and approaches. This article discusses the struggle for truth in AI systems and the general responses to date. It then investigates the production of truth in InstructGPT, a large language model, highlighting how data harvesting, model architectures, and social feedback mechanisms weave together disparate understandings of veracity. It conceptualizes this performance as an operationalization of truth, where distinct, often conflicting claims are smoothly synthesized and confidently presented into truth-statements. We argue that these same logics and inconsistencies play out in Instruct's successor, ChatGPT, reiterating truth as a non-trivial problem. We suggest that enriching sociality and thickening "reality" are two promising vectors for enhancing the truth-evaluating capacities of future language models. We conclude, however, by stepping back to consider AI truth-telling as a social practice: what kind of "truth" do we as listeners desire?	1	ETHICS	EVALUATION	Threat			
Annotator1	arxiv	{'name': 'Gerd Kortemeyer'}	Could an Artificial-Intelligence agent pass an introductory physics   course?	Massive pre-trained language models have garnered attention and controversy due to their ability to generate human-like responses: attention due to their frequent indistinguishability from human-generated phraseology and narratives, and controversy due to the fact that their convincingly presented arguments and facts are frequently simply false. Just how human-like are these responses when it comes to dialogues about physics, in particular about the standard content of introductory physics courses? This study explores that question by having ChatGTP, the pre-eminent language model in 2023, work through representative assessment content of an actual calculus-based physics course and grading the responses in the same way human responses would be graded. As it turns out, ChatGPT would narrowly pass this course while exhibiting many of the preconceptions and errors of a beginning learner.	4	EDUCATION		NAN			
Annotator1	arxiv	{'name': 'Christoph Treude'}	Navigating Complexity in Software Engineering: A Prototype for Comparing   GPT-n Solutions	Navigating the diverse solution spaces of non-trivial software engineering tasks requires a combination of technical knowledge, problem-solving skills, and creativity. With multiple possible solutions available, each with its own set of trade-offs, it is essential for programmers to evaluate the various options and select the one that best suits the specific requirements and constraints of a project. Whether it is choosing from a range of libraries, weighing the pros and cons of different architecture and design solutions, or finding unique ways to fulfill user requirements, the ability to think creatively is crucial for making informed decisions that will result in efficient and effective software. However, the interfaces of current chatbot tools for programmers, such as OpenAI's ChatGPT or GitHub Copilot, are optimized for presenting a single solution, even for complex queries. While other solutions can be requested, they are not displayed by default and are not intuitive to access. In this paper, we present our work-in-progress prototype "GPTCompare", which allows programmers to visually compare multiple source code solutions generated by GPT-n models for the same programming-related query by highlighting their similarities and differences.	0	REST		NAN			
Annotator1	arxiv	[{'name': 'Chunqiu Steven Xia'}, {'name': 'Lingming Zhang'}]	Conversational Automated Program Repair	Automated Program Repair (APR) can help developers automatically generate patches for bugs. Due to the impressive performance obtained using Large Pre-Trained Language Models (LLMs) on many code related tasks, researchers have started to directly use LLMs for APR. However, prior approaches simply repeatedly sample the LLM given the same constructed input/prompt created from the original buggy code, which not only leads to generating the same incorrect patches repeatedly but also miss the critical information in testcases. To address these limitations, we propose conversational APR, a new paradigm for program repair that alternates between patch generation and validation in a conversational manner. In conversational APR, we iteratively build the input to the model by combining previously generated patches with validation feedback. As such, we leverage the long-term context window of LLMs to not only avoid generating previously incorrect patches but also incorporate validation feedback to help the model understand the semantic meaning of the program under test. We evaluate 10 different LLM including the newly developed ChatGPT model to demonstrate the improvement of conversational APR over the prior LLM for APR approach.	0	APPLICATION		NAN			
Annotator1	arxiv	[{'name': 'David Noever'}, {'name': 'Forrest McKee'}]	Numeracy from Literacy: Data Science as an Emergent Skill from Large   Language Models	Large language models (LLM) such as OpenAI's ChatGPT and GPT-3 offer unique testbeds for exploring the translation challenges of turning literacy into numeracy. Previous publicly-available transformer models from eighteen months prior and 1000 times smaller failed to provide basic arithmetic. The statistical analysis of four complex datasets described here combines arithmetic manipulations that cannot be memorized or encoded by simple rules. The work examines whether next-token prediction succeeds from sentence completion into the realm of actual numerical understanding. For example, the work highlights cases for descriptive statistics on in-memory datasets that the LLM initially loads from memory or generates randomly using python libraries. The resulting exploratory data analysis showcases the model's capabilities to group by or pivot categorical sums, infer feature importance, derive correlations, and predict unseen test cases using linear regression. To extend the model's testable range, the research deletes and appends random rows such that recall alone cannot explain emergent numeracy.	4	APPLICATION		NAN			
Annotator1	arxiv	[{'name': 'Nuo Chen'}, {'name': 'Yan Wang'}, {'name': 'Haiyun Jiang'}, {'name': 'Deng Cai'}, {'name': 'Ziyang Chen'}, {'name': 'Longyue Wang'}, {'name': 'Jia Li'}]	What would Harry say? Building Dialogue Agents for Characters in a Story  Dialogue agents	We have a Christmas gift for Harry Potter fans all over the world. In this paper, we present Harry Potter Dialogue (HPD), a dataset that helps train Harry Potter-like dialogue agents. Such a task is typically viewed as a variant of personalized dialogue agents, but they differ significantly in three respects: 1) Harry lived in a virtual world of wizards, thus, real-world commonsense may not apply to Harry's conversations; 2) Harry's behavior is strongly linked to background information in conversations: the scene, its attributes and its relationship to other speakers; and 3) Such backgrounds are dynamically altered as the storyline goes on. The HPD dataset, as the first dataset to facilitate the study of dialogue agent construction for characters within a story, provides rich contextual information about each dialogue session such as scenes, character attributes, and relations. More importantly, all the background information will change over the course of the story. In addition, HPD could support both dialogue generation and retrieval tasks. We evaluate baselines such as Dialog-GPT and BOB to determine the extent to which they can generate Harry Potter-like responses. The experimental results disappoint us in that although the generated responses are fluent, they still seem out of character for Harry. Besides, we validate the current most robust dialogue agent, ChatGPT, which also can't generate plausible Harry-Potter-like responses in some cases, either. Our results suggest that there is much scope for future research.	1	APPLICATION	WRITING	NAN			
Annotator1	arxiv	[{'name': 'Alexandre Blanco-Gonzalez'}, {'name': 'Alfonso Cabezon'}, {'name': 'Alejandro Seco-Gonzalez'}, {'name': 'Daniel Conde-Torres'}, {'name': 'Paula Antelo-Riveiro'}, {'name': 'Angel Pineiro'}, {'name': 'Rebeca Garcia-Fandino'}]	The Role of AI in Drug Discovery: Challenges, Opportunities, and   Strategies	Artificial intelligence (AI) has the potential to revolutionize the drug discovery process, offering improved efficiency, accuracy, and speed. However, the successful application of AI is dependent on the availability of high-quality data, the addressing of ethical concerns, and the recognition of the limitations of AI-based approaches. In this article, the benefits, challenges and drawbacks of AI in this field are reviewed, and possible strategies and approaches for overcoming the present obstacles are proposed. The use of data augmentation, explainable AI, and the integration of AI with traditional experimental methods, as well as the potential advantages of AI in pharmaceutical research are also discussed. Overall, this review highlights the potential of AI in drug discovery and provides insights into the challenges and opportunities for realizing its potential in this field.   Note from the human-authors: This article was created to test the ability of ChatGPT, a chatbot based on the GPT-3.5 language model, to assist human authors in writing review articles. The text generated by the AI following our instructions (see Supporting Information) was used as a starting point, and its ability to automatically generate content was evaluated. After conducting a thorough review, human authors practically rewrote the manuscript, striving to maintain a balance between the original proposal and scientific criteria. The advantages and limitations of using AI for this purpose are discussed in the last section.	3	APPLICATION	WRITING	NAN			
Annotator1	arxiv	[{'name': 'Xiyuan Zhang'}, {'name': 'Ranak Roy Chowdhury'}, {'name': 'Dezhi Hong'}, {'name': 'Rajesh K. Gupta'}, {'name': 'Jingbo Shang'}]	Modeling Label Semantics Improves Activity Recognition	Human activity recognition (HAR) aims to classify sensory time series into different activities, with wide applications in activity tracking, healthcare, human computer interaction, etc. Existing HAR works improve recognition performance by designing more complicated feature extraction methods, but they neglect the label semantics by simply treating labels as integer IDs. We find that many activities in the current HAR datasets have shared label names, e.g., "open door" and "open fridge", "walk upstairs" and "walk downstairs". Through some exploratory analysis, we find that such shared structure in activity names also maps to similarity in the input features. To this end, we design a sequence-to-sequence framework to decode the label name semantics rather than classifying labels as integer IDs. Our proposed method decomposes learning activities into learning shared tokens ("open", "walk"), which is easier than learning the joint distribution ("open fridge", "walk upstairs") and helps transfer learning to activities with insufficient data samples. For datasets originally without shared tokens in label names, we also offer an automated method, using OpenAI's ChatGPT, to generate shared actions and objects. Extensive experiments on seven HAR benchmark datasets demonstrate the state-of-the-art performance of our method. We also show better performance in the long-tail activity distribution settings and few-shot settings.	5	APPLICATION		NAN			
Annotator1	arxiv	[{'name': 'Hao Liu'}, {'name': 'Carmelo Sferrazza'}, {'name': 'Pieter Abbeel'}]	Languages are Rewards: Hindsight Finetuning using Human Feedback	Learning from human preferences is important for language models to be helpful and useful for humans, and to align with human and social values. Existing works focus on supervised finetuning of pretrained models, based on curated model generations that are preferred by human labelers. Such works have achieved remarkable successes in understanding and following instructions (e.g., InstructGPT, ChatGPT, etc). However, to date, a key limitation of supervised finetuning is that it cannot learn from negative ratings; models are only trained on positive-rated data, which makes it data inefficient. Because collecting human feedback data is both time consuming and expensive, it is vital for the model to learn from all feedback, akin to the remarkable ability of humans to learn from diverse feedback. In this work, we propose a novel technique called Hindsight Finetuning for making language models learn from diverse human feedback. In fact, our idea is motivated by how humans learn from hindsight experience. We condition the model on a sequence of model generations paired with hindsight feedback, and finetune the model to predict the most preferred output. By doing so, models can learn to identify and correct negative attributes or errors. Applying the method to GPT-J, we observe that it significantly improves results on summarization and dialogue tasks using the same amount of human feedback.	0	REST		NAN			
Annotator1	arxiv	{'name': 'Philipp Hacker'}	The European AI Liability Directives -- Critique of a Half-Hearted   Approach and Lessons for the Future	As ChatGPT et al. conquer the world, the optimal liability framework for AI systems remains an unsolved problem across the globe. In a much-anticipated move, the European Commission advanced two proposals outlining the European approach to AI liability in September 2022: a novel AI Liability Directive and a revision of the Product Liability Directive. They constitute the final cornerstone of EU AI regulation. Crucially, the liability proposals and the EU AI Act are inherently intertwined: the latter does not contain any individual rights of affected persons, and the former lack specific, substantive rules on AI development and deployment. Taken together, these acts may well trigger a Brussels Effect in AI regulation, with significant consequences for the US and beyond.   This paper makes three novel contributions. First, it examines in detail the Commission proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted as foreseen, AI liability in the EU will primarily rest on disclosure of evidence mechanisms and a set of narrowly defined presumptions concerning fault, defectiveness and causality. Hence, second, the article suggests amendments, which are collected in an Annex at the end of the paper. Third, based on an analysis of the key risks AI poses, the final part of the paper maps out a road for the future of AI liability and regulation, in the EU and beyond. This includes: a comprehensive framework for AI liability; provisions to support innovation; an extension to non-discrimination/algorithmic fairness, as well as explainable AI; and sustainability. I propose to jump-start sustainable AI regulation via sustainability impact assessments in the AI Act and sustainable design defects in the liability regime. In this way, the law may help spur not only fair AI and XAI, but potentially also sustainable AI (SAI).	0	ETHICS		NAN			
Annotator1	arxiv	Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, Pascale Fung	A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity	This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets. We carry out an extensive technical evaluation of ChatGPT using 21 data sets covering 8 different common NLP application tasks. We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts, via an intermediate code generation step. Moreover, we find that ChatGPT is 64.33% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. It is, for example, better at deductive than inductive reasoning. ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++ on machine translation, in a multi-turn"prompt engineering"fashion. 	4	EVALUATION		NAN			
Annotator1	arxiv	Abhiramon Rajasekharan, Yankai Zeng, Parth Padalkar, Gopal Gupta	Reliable Natural Language Understanding with Large Language Models and Answer Set Programming 	Humans understand language by extracting information (meaning) from sentences, combining it with existing commonsense knowledge, and then performing reasoning to draw conclusions. While large language models (LLMs) such as GPT-3 and ChatGPT are able to leverage patterns in the text to solve a variety of NLP tasks, they fall short in problems that require reasoning. They also cannot reliably explain the answers generated for a given question. In order to emulate humans better, we propose STAR, a framework that combines LLMs with Answer Set Programming (ASP). We show how LLMs can be used to effectively extract knowledge -- represented as predicates -- from language. Goal-directed ASP is then employed to reliably reason over this knowledge. We apply the STAR framework to three different NLU tasks requiring reasoning: qualitative reasoning, mathematical reasoning, and goal-directed conversation. Our experiments reveal that STAR is able to bridge the gap of reasoning in NLU tasks, leading to significant performance improvements, especially for smaller LLMs, i.e., LLMs with a smaller number of parameters. NLU applications developed using the STAR framework are also explainable: along with the predicates generated, a justification in the form of a proof tree can be produced for a given output.	0	REST		NAN			
Annotator1	arxiv	Ofer Lahav	Deep Machine Learning in Cosmology: Evolution or Revolution?	Could Machine Learning (ML) make fundamental discoveries and tackle unsolved problems in Cosmology? Detailed observations of the present contents of the universe are consistent with the Cosmological Constant Lambda and Cold Dark Matter model, subject to some unresolved inconsistencies ('tensions') among observations of the Hubble Constant and the clumpiness factor. To understand these issues further, large surveys of billions of galaxies and other probes require new statistical approaches. In recent years the power of ML, and in particular 'Deep Learning', has been demonstrated for object classification, photometric redshifts, anomaly detection, enhanced simulations, and inference of cosmological parameters. It is argued that the more traditional 'shallow learning' (i.e. with pre-processing feature extraction) is actually quite deep, as it brings in human knowledge, while 'deep learning' might be perceived as a black box, unless supplemented by explainability tools. The 'killer applications' of ML for Cosmology are still to come. New ways to train the next generation of scientists for the Data Intensive Science challenges ahead are also discussed. Finally, the chatbot ChatGPT is challenged to address the question posed in this article's title.	0	APPLICATION	WRITING	NAN			
Annotator1	arxiv	Mohammad Khalil, Erkan Er	Will ChatGPT get you caught? Rethinking of Plagiarism Detection	The rise of Artificial Intelligence (AI) technology and its impact on education has been a topic of growing concern in recent years. The new generation AI systems such as chatbots have become more accessible on the Internet and stronger in terms of capabilities. The use of chatbots, particularly ChatGPT, for generating academic essays at schools and colleges has sparked fears among scholars. This study aims to explore the originality of contents produced by one of the most popular AI chatbots, ChatGPT. To this end, two popular plagiarism detection tools were used to evaluate the originality of 50 essays generated by ChatGPT on various topics. Our results manifest that ChatGPT has a great potential to generate sophisticated text outputs without being well caught by the plagiarism check software. In other words, ChatGPT can create content on many topics with high originality as if they were written by someone. These findings align with the recent concerns about students using chatbots for an easy shortcut to success with minimal or no effort. Moreover, ChatGPT was asked to verify if the essays were generated by itself, as an additional measure of plagiarism check, and it showed superior performance compared to the traditional plagiarism-detection tools. The paper discusses the need for institutions to consider appropriate measures to mitigate potential plagiarism issues and advise on the ongoing debate surrounding the impact of AI technology on education. Further implications are discussed in the paper.	5	EDUCATION		Threat			
Annotator1	arxiv	Zeljana Basic, Ana Banovac, Ivana Kruzic, Ivan Jerkovic	Better by you, better than me, chatgpt3 as writing assistance in students essays	Aim: To compare students' essay writing performance with or without employing ChatGPT-3 as a writing assistant tool. Materials and methods: Eighteen students participated in the study (nine in control and nine in the experimental group that used ChatGPT-3). We scored essay elements with grades (A-D) and corresponding numerical values (4-1). We compared essay scores to students' GPTs, writing time, authenticity, and content similarity. Results: Average grade was C for both groups; for control (2.39, SD=0.71) and for experimental (2.00, SD=0.73). None of the predictors affected essay scores: group (P=0.184), writing duration (P=0.669), module (P=0.388), and GPA (P=0.532). The text unauthenticity was slightly higher in the experimental group (11.87%, SD=13.45 to 9.96%, SD=9.81%), but the similarity among essays was generally low in the overall sample (the Jaccard similarity index ranging from 0 to 0.054). In the experimental group, AI classifier recognized more potential AI-generated texts. Conclusions: This study found no evidence that using GPT as a writing tool improves essay quality since the control group outperformed the experimental group in most parameters.	1	EDUCATION		NAN			
Annotator1	arxiv	Lingfei Luan, Xi Lin, Wenbiao Li	Exploring the Cognitive Dynamics of Artificial Intelligence in the Post-COVID-19 and Learning 3.0 Era: A Case Study of ChatGPT	The emergence of artificial intelligence has incited a paradigm shift across the spectrum of human endeavors, with ChatGPT serving as a catalyst for the transformation of various established domains, including but not limited to education, journalism, security, and ethics. In the post-pandemic era, the widespread adoption of remote work has prompted the educational sector to reassess conventional pedagogical methods. This paper is to scrutinize the underlying psychological principles of ChatGPT, delve into the factors that captivate user attention, and implicate its ramifications on the future of learning. The ultimate objective of this study is to instigate a scholarly discourse on the interplay between technological advancements in education and the evolution of human learning patterns, raising the question of whether technology is driving human evolution or vice versa.	5	EDUCATION		NAN			